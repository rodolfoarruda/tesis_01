Scopus
EXPORT DATE: 12 May 2021

@ARTICLE{Jia2021179,
author={Jia, S. and Jiang, S. and Lin, Z. and Li, N. and Xu, M. and Yu, S.},
title={A survey: Deep learning for hyperspectral image classification with few labeled samples},
journal={Neurocomputing},
year={2021},
volume={448},
pages={179-204},
doi={10.1016/j.neucom.2021.03.035},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104293528&doi=10.1016%2fj.neucom.2021.03.035&partnerID=40&md5=45ee4152aa9baf7bdacfc766a17e8d7b},
affiliation={College of Computer Science and Software Engineering, Shenzhen University, China; Department of Computer Science and Engineering, Southern University of Science and Technology, China; SZU Branch, Shenzhen Institute of Artificial Intelligence and Robotics for Society, China},
abstract={With the rapid development of deep learning technology and improvement in computing capability, deep learning has been widely used in the field of hyperspectral image (HSI) classification. In general, deep learning models often contain many trainable parameters and require a massive number of labeled samples to achieve optimal performance. However, in regard to HSI classification, a large number of labeled samples is generally difficult to acquire due to the difficulty and time-consuming nature of manual labeling. Therefore, many research works focus on building a deep learning model for HSI classification with few labeled samples. In this article, we concentrate on this topic and provide a systematic review of the relevant literature. Specifically, the contributions of this paper are twofold. First, the research progress of related methods is categorized according to the learning paradigm, including transfer learning, active learning and few-shot learning. Second, a number of experiments with various state-of-the-art approaches has been carried out, and the results are summarized to reveal the potential research directions. More importantly, it is notable that although there is a vast gap between deep learning models (that usually need sufficient labeled samples) and the HSI scenario with few labeled samples, the issues of small-sample sets can be well characterized by fusion of deep learning methods and related techniques, such as transfer learning and a lightweight model. For reproducibility, the source codes of the methods assessed in the paper can be found at https://github.com/ShuGuoJ/HSI-Classification.git. © 2021 The Author(s)},
author_keywords={Deep learning;  Few-shot learning;  Hyperspectral image classification;  Transfer learning},
keywords={Deep learning;  Hyperspectral imaging;  Spectroscopy, Computing capability;  Deep learning;  Few-shot learning;  Hyperspectral image classification;  Learning models;  Learning technology;  Manual labeling;  Optimal performance;  Systematic Review;  Transfer learning, Image classification, article;  deep learning;  human;  reproducibility;  systematic review;  transfer of learning},
funding_details={JCYJ20180305124802421, JCYJ20180305125902403},
funding_details={National Natural Science Foundation of ChinaNational Natural Science Foundation of China, NSFC, 41971300, 61901278, 61976144},
funding_details={Department of Education of Guangdong ProvinceDepartment of Education of Guangdong Province, DEGP, 2020ZDZX3045},
funding_details={National Key Research and Development Program of ChinaNational Key Research and Development Program of China, NKRDPC, 2020AAA0140002},
funding_text 1={The work is supported by the National Natural Science Foundation of China (Grant No. 41971300, 61901278 and 61976144), the National Key Research and Development Program of China (Grant No. 2020AAA0140002), the Program for Young Changjiang Scholars, the Key Project of Department of Education of Guangdong Province (Grant No. 2020ZDZX3045) and the Shenzhen Scientific Research and Development Funding Program under (Grant No. JCYJ20180305124802421 and JCYJ20180305125902403).},
references={Teke, M., Deveci, H., Haliloğlu, O., Gürbüz, S., Sakarya, U., A short survey of hyperspectral remote sensing applications in agriculture (2013), pp. 171-176. , 2013 6th International Conference on Recent Advances in Space Technologies (RAST), IEEE; Strachan, I., Pattey, E., Boisvert, J., Impact of nitrogen and environmental conditions on corn as detected by hyperspectral reflectance (2002) Remote Sens. Environ., 80 (2), pp. 213-224; Bannari, A., Pacheco, A., Staenz, K., McNairn, H., Omari, K., Estimating and mapping crop residues cover on agricultural lands using hyperspectral and ikonos data (2006) Remote Sens. Environ., 104 (4), pp. 447-459; Sabine, C., Robert, M., Thomas, S., Manuel, R., Paula, E., Marta, P., Alicia, P., Potential of hyperspectral imagery for the spatial assessment of soil erosion stages in agricultural semi-arid spain at different scales (2014), pp. 2918-2921. , 2014 IEEE Geoscience and Remote Sensing Symposium, IEEE; Kuflik, P., Rotman, S., Band selection for gas detection in hyperspectral images (2012), pp. 1-4. , 2012 IEEE 27th Convention of Electrical and Electronics Engineers in Israel doi: 10.1109/EEEI.2012.6376973; Foudan, S., Menas, K., Tarek, E., Richard, G., Ruixin, Y., Hyperspectral image analysis for oil spill detection (2001), pp. 5-9. , Summaries of NASA/JPL Airborne Earth Science Workshop, Pasadena, CA; Mohamad, A., Sea water chlorophyll-a estimation using hyperspectral images and supervised artificial neural network (2014) Ecol. Inf., 24, pp. 60-68; Sylvain, J., Mireille, G., A novel maximum likelihood based method for mapping depth and water quality from hyperspectral remote-sensing data (2014) Remote Sens. Environ., 147, pp. 121-132; Jänicke, C., Okujeni, A., Cooper, S., Clark, M., Hostert, P., van der Linden, S., Brightness gradient-corrected hyperspectral image mosaics for fractional vegetation cover mapping in northern california (2020) Remote Sens. Lett., 11 (1), pp. 1-10; Li, J., Pang, Y., Li, Z., Jia, W., Tree species classification of airborne hyperspectral image in cloud shadow area (2018) International Symposium of Space Optical Instrument and Application, pp. 389-398. , Springer; Du, Z., Jeong, M., Kong, S., Band selection of hyperspectral images for automatic detection of poultry skin tumors (2007) IEEE Trans. Autom. Sci. Eng., 4 (3), pp. 332-339; Li, S., Song, W., Fang, L., Chen, Y., Benediktsson, J., (2019), pp. 1-20. , Deep learning for hyperspectral image classification: an overview, IEEE Trans. Geosci. Remote Sens. PP (99); Plaza, A., Plaza, J., Martin, G., (2009), pp. 1-6. , Incorporation of spatial constraints into spectral mixture analysis of remotely sensed hyperspectral data, Machine Learning for Signal Processing.mlsp.ieee International Workshop on; Melgani, F., Bruzzone, L., Classification of hyperspectral remote sensing images with support vector machines (2004) IEEE Trans. Geosci. Remote Sens., 42 (8), pp. 1778-1790; Zhong, Y., Zhang, L., An adaptive artificial immune network for supervised classification of multi-hyperspectral remote sensing imagery (2011) IEEE Trans. Geosci. Remote Sens., 50 (3), pp. 894-909; Li, J., Bioucas-Dias, J., Plaza, A., Semisupervised hyperspectral image classification using soft sparse multinomial logistic regression (2012) IEEE Geosci. Remote Sens. Lett., 10 (2), pp. 318-322; Licciardi, G., Marpu, P., Chanussot, J., Benediktsson, J., Linear versus nonlinear pca for the classification of hyperspectral data based on the extended morphological profiles (2011) IEEE Geosci. Remote Sens. Lett., 9 (3), pp. 447-451; Villa, A., Chanussot, J., Jutten, C., Benediktsson, J., Moussaoui, S., On the use of ICA for hyperspectral image analysis (2009), 4. , Proc. Geoscience and Remote Sensing Symp., 2009 IEEE Int., IGARSS 2009, pp. IV–97. doi:10.1109/IGARSS.2009.5417363; Zhang, C., Zheng, Y., Hyperspectral remote sensing image classification based on combined SVM and LDA (2014) SPIE Asia Pac. Remote Sens., p. 92632P; He, L., Li, J., Plaza, A., Li, Y., (2016), Discriminative low-rank Gabor filtering for spectral-spatial hyperspectral image classification, IEEE Trans. Geosci. Remote Sens. PP (99) 1–15. doi:10.1109/TGRS.2016.2623742; Mura, M.D., Benediktsson, J.A., Waske, B., Bruzzone, L., Extended profiles with morphological attribute filters for the analysis of hyperspectral data (2010) Int. J. Remote Sens., 31 (22), pp. 5975-5991; Falco, N., Atli Benediktsson, J., Bruzzone, L., Spectral and spatial classification of hyperspectral images based on ICA and reduced morphological attribute profiles (2015) IEEE Trans. Geosci. Remote Sens., 53 (11), pp. 6223-6240; Dalla Mura, M., Villa, A., Atli Benediktsson, J., Chanussot, J., Bruzzone, L., Classification of hyperspectral images by using extended morphological attribute profiles and independent component analysis (2011) IEEE Geosci. Remote Sens. Lett., 8 (3), pp. 542-546; Jia, S., Shen, L., Li, Q., Gabor feature-based collaborative representation for hyperspectral imagery classification (2015) IEEE Trans. Geosci. Remote Sens., 53 (2), pp. 1118-1129; Qian, Y., Ye, M., Zhou, J., Hyperspectral image classification based on structured sparse logistic regression and three-dimensional wavelet texture features (2013) IEEE Trans. Geosci. Remote Sens., 51 (4), pp. 2276-2291; Li, W., Chen, C., Su, H., Du, Q., Local binary patterns and extreme learning machine for hyperspectral imagery classification (2015) IEEE Trans. Geosci. Remote Sens., 53 (7), pp. 3681-3693; Ghamisi, P., Dalla Mura, M., Atli Benediktsson, J., A survey on spectral–spatial classification techniques based on attribute profiles (2015) IEEE Trans. Geosci. Remote Sens., 53 (5), pp. 2335-2353; Yu, S., Jia, S., Xu, C., Convolutional neural networks for hyperspectral image classification (2017) Neurocomputing, 219, pp. 88-98; Paoletti, M., Haut, J., Plaza, J., Plaza, A., Deep learning classifiers for hyperspectral imaging: a review (2019) ISPRS J. Photogramm. Remote Sens., 158 (Dec.), pp. 279-317; Hinton, G., Salakhutdinov, R., Reducing the dimensionality of data with neural networks (2006) Science, 313 (5786), pp. 504-507; Coates, A., Ng, A., Lee, H., An analysis of single-layer networks in unsupervised feature learning (2011) J. Mach. Learn. Res., 15, pp. 215-223; Zeng, N., Zhang, H., Song, B., Liu, W., Li, Y., Dobaie, A., Facial expression recognition via learning deep sparse autoencoders (2018) Neurocomputing, 273, pp. 643-649; Vincent, P., Larochelle, H., Bengio, Y., Manzagol, P., Extracting and composing robust features with denoising autoencoders (2008), pp. 1096-1103. , International Conference on Machine Learning; Windrim, L., Ramakrishnan, R., Melkumyan, A., Murphy, R., Chlingaryan, A., Unsupervised feature-learning for hyperspectral data with autoencoders (2019) Remote Sens., 11 (7), p. 864; Chen, Y., Lin, Z., Zhao, X., Wang, G., Gu, Y., Deep learning-based classification of hyperspectral data (2014) IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens., 7 (6), pp. 2094-2107; Ghasem, A., Farhad, S., Peter, R., Spectral–spatial feature learning for hyperspectral imagery classification using deep stacked sparse autoencoder (2017) J. Appl. Remote Sens., 11 (4); Xing, C., Ma, L., Yang, X., Stacked denoise autoencoder based feature extraction and classification for hyperspectral images (2016) J. Sens.; Yue, J., Mao, S., Li, M., A deep learning framework for hyperspectral image classification using spatial pyramid pooling (2016) Remote Sens. Lett., 7 (9), pp. 875-884; Hao, S., Wang, W., Ye, Y., Nie, T., Lorenzo, B., Two-stream deep architecture for hyperspectral image classification (2017) IEEE Trans. Geosci. Remote Sens., 56 (4), pp. 2349-2361; Sun, X., Zhou, F., Dong, J., Gao, F., Mu, Q., Wang, X., Encoding spectral and spatial context information for hyperspectral image classification (2017) IEEE Geosci. Remote Sens. Lett., 14 (12), pp. 2250-2254; Mei, S., Ji, J., Geng, Y., Zhang, Z., Li, X., Du, Q., Unsupervised spatial–spectral feature learning by 3d convolutional autoencoder for hyperspectral classification (2019) IEEE Trans. Geosci. Remote Sens., 57 (9), pp. 6808-6820; Zhao, C., Wan, X., Zhao, G., Cui, B., Liu, W., Qi, B., Spectral-spatial classification of hyperspectral imagery based on stacked sparse autoencoder and random forest (2017) Eur. J. Remote Sens., 50 (1), pp. 47-63; Wan, X., Zhao, C., Wang, Y., Liu, W., Stacked sparse autoencoder in hyperspectral data classification using spectral-spatial, higher order statistics and multifractal spectrum features (2017) Infrared Phys. Technol., 86, pp. 77-89; Wang, C., Zhang, P., Zhang, Y., Zhang, L., Wei, W., A multi-label hyperspectral image classification method with deep learning features (2016) Proceedings of the International Conference on Internet Multimedia Computing and Service, pp. 127-131; Li, J., Lorenzo, B., Liu, S., Deep feature representation for hyperspectral image classification (2015), pp. 4951-4954. , 2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS), IEEE; Atif, M., Tao, L., Efficient deep auto-encoder learning for the classification of hyperspectral images (2016), pp. 44-51. , 2016 International Conference on Virtual Reality and Visualization (ICVRV), IEEE; Liu, Y., Cao, G., Sun, Q., Mel, S., Hyperspectral classification via learnt features (2015), pp. 2591-2595. , 2015 IEEE International Conference on Image Processing (ICIP), IEEE; Lee, H., Heesung, K., Going deeper with contextual cnn for hyperspectral image classification (2017) IEEE Trans. Image Process., 26 (10), pp. 4843-4855; Leng, J., Li, T., Bai, G., Dong, Q., Dong, H., Cube-cnn-svm: a novel hyperspectral image classification method (2016), pp. 1027-1034. , 2016 IEEE 28th International Conference on Tools with Artificial Intelligence (ICTAI), IEEE; Zhang, H., Li, Y., Zhang, Y., Shen, Q., Spectral-spatial classification of hyperspectral imagery using a dual-channel convolutional neural network (2017) Remote Sens. Lett., 8 (5), pp. 438-447; Aptoula, E., Ozdemir, M., Yanikoglu, B., Deep learning with attribute profiles for hyperspectral image classification (2016) IEEE Geosci. Remote Sens. Lett., 13 (12), pp. 1970-1974; Zhao, W., Li, S., Li, A., Zhang, B., Li, Y., Hyperspectral images classification with convolutional neural network and textural feature using limited training samples (2019) Remote Sens. Lett., 10 (5), pp. 449-458; Yu, C., Zhao, M., Song, M., Wang, Y., Li, F., Han, R., Chang, C., Hyperspectral image classification method based on cnn architecture embedding with hashing semantic feature (2019) IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., 12 (6), pp. 1866-1881; Qing, C., Ruan, J., Xu, X., Ren, J., Zabalza, J., Spatial-spectral classification of hyperspectral images: a deep learning framework with markov random fields based modelling (2018) IET Image Proc., 13 (2), pp. 235-245; Zhong, Z., Li, J., Luo, Z., Chapman, M., Spectral-spatial residual network for hyperspectral image classification: a 3-d deep learning framework (2017) IEEE Trans. Geosci. Remote Sens., 56 (2), pp. 847-858; Liu, B., Yu, X., Zhang, P., Tan, X., Wang, R., Zhi, L., Spectral–spatial classification of hyperspectral image using three-dimensional convolution network (2018) J. Appl. Remote Sens., 12 (1); Fang, B., Li, Y., Zhang, H., Chan, J., Collaborative learning of lightweight convolutional neural network and deep clustering for hyperspectral image semi-supervised classification with limited training samples (2020) ISPRS J. Photogramm. Remote Sens., 161, pp. 164-178; Mou, L., Ghamisi, P., Zhu, X., Unsupervised spectral–spatial feature learning via deep residual conv–deconv network for hyperspectral image classification (2017) IEEE Trans. Geosci. Remote Sens., 56 (1), pp. 391-406; Sellami, A., Farah, M., Farah, I., Solaiman, B., Hyperspectral imagery classification based on semi-supervised 3-d deep neural network and adaptive band selection (2019) Expert Syst. Appl., 129, pp. 246-259; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016), pp. 770-778. , Proc. IEEE Conf. Comput. Vis. Pattern Recognit; Paoletti, M., Haut, J., Fernandez-Beltran, R., Plaza, J., Plaza, A., Pla, F., Deep pyramidal residual networks for spectral–spatial hyperspectral image classification (2018) IEEE Trans. Geosci. Remote Sens., 57 (2), pp. 740-754; Ma, X., Fu, A., Wang, J., Wang, H., Yin, B., Hyperspectral image classification based on deep deconvolution network with skip architecture (2018) IEEE Trans. Geosci. Remote Sens., 56 (8), pp. 4781-4791; Paoletti, M., Haut, J., Plaza, J., Plaza, A., Deep&dense convolutional neural network for hyperspectral image classification (2018) Remote Sens., 10 (9), p. 1454; Wang, W., Dou, S., Jiang, Z., Sun, L., A fast dense spectral–spatial convolution network framework for hyperspectral images classification (2018) Remote Sens., 10 (7), p. 1068; Haut, J., Paoletti, M., Plaza, J., Plaza, A., Li, J., Visual attention-driven hyperspectral image classification (2019) IEEE Trans. Geosci. Remote Sens., 57 (10), pp. 8065-8080; Xiong, Z., Yuan, Y., Wang, Q., Ai-net: attention inception neural networks for hyperspectral image classification (2018), pp. 2647-2650. , IGARSS 2018-2018 IEEE International Geoscience and Remote Sensing Symposium, IEEE; Feng, Q., Zhu, D., Yang, J., Li, B., Multisource hyperspectral and lidar data fusion for urban land-use mapping based on a modified two-branch convolutional neural network (2019) ISPRS Int. J. Geo-Inf., 8 (1), p. 28; Xu, X., Li, W., Ran, Q., Du, Q., Gao, L., Zhang, B., Multisource remote sensing data classification based on convolutional neural network (2017) IEEE Trans. Geosci. Remote Sens., 56 (2), pp. 937-949; Li, H., Pedram, G., Uwe, S., Zhu, X., Hyperspectral and lidar fusion using deep three-stream convolutional neural networks (2018) Remote Sens., 10 (10), p. 1649; Li, W., Chen, C., Zhang, M., Li, H., Du, Q., Data augmentation for hyperspectral image classification with deep cnn (2018) IEEE Geosci. Remote Sens. Lett., 16 (4), pp. 593-597; Wei, W., Zhang, J., Zhang, L., Tian, C., Zhang, Y., Deep cube-pair network for hyperspectral imagery classification (2018) Remote Sens., 10 (5), p. 783; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput., 9 (8), pp. 1735-1780; Kyunghyun, C., Bart, V., Caglar, G., Dzmitry, B., Fethi, B., Holger, S., Yoshua, B., Learning phrase representations using rnn encoder-decoder for statistical machine translation, arXiv preprint arXiv:1406.1078; Mou, L., Ghamisi, P., Zhu, X., Deep recurrent neural networks for hyperspectral image classification (2017) IEEE Trans. Geosci. Remote Sens., 55 (7), pp. 3639-3655; Liu, B., Yu, X., Yu, A., Zhang, P., Wan, G., Spectral-spatial classification of hyperspectral imagery based on recurrent neural networks (2018) Remote Sens. Lett., 9 (12), pp. 1118-1127; Zhou, F., Hang, R., Liu, Q., Yuan, X., Hyperspectral image classification using spectral-spatial lstms (2019) Neurocomputing, 328, pp. 39-47; Andong, M., M, F.A., Wang, Z., Yin, Z., (2019), Hyperspectral image classification using similarity measurements-based deep recurrent neural networks, Remote Sens. 11 (2) 194; Zhang, X., Sun, Y., Jiang, K., Li, C., Jiao, L., Zhou, H., Spatial sequential recurrent neural network for hyperspectral image classification (2018) IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., 11 (11), pp. 4141-4155; Pan, E., Mei, X., Wang, Q., Ma, Y., Ma, J., Spectral-spatial classification for hyperspectral image based on a single gru (2020) Neurocomputing, 387, pp. 150-160; Wu, H., Saurabh, P., Semi-supervised deep learning using pseudo labels for hyperspectral image classification (2017) IEEE Trans. Image Process., 27 (3), pp. 1259-1270; Wu, H., Saurabh, P., Convolutional recurrent neural networks forhyperspectral data classification (2017) Remote Sens., 9 (3), p. 298; Hao, S., Wang, W., Mathieu, S., Geometry-aware deep recurrent neural networks for hyperspectral image classification, IEEE Trans. Geosci. Remote Sens; Shi, C., Chi-Man, P., Multi-scale hierarchical recurrent neural networks for hyperspectral image classification (2018) Neurocomputing, 294, pp. 82-93; Pan, S., Yang, Q., A survey on transfer learning (2010) IEEE Trans. Knowl. Data Eng., 22 (10), pp. 1345-1359; Yang, J., Zhao, Y., Chan, J., Yi, C., Hyperspectral image classification using two-channel deep convolutional neural network (2016), pp. 5079-5082. , 2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS), IEEE; Yang, J., Zhao, Y., Chan, J., Learning and transferring deep joint spectral–spatial features for hyperspectral classification (2017) IEEE Trans. Geosci. Remote Sens., 55 (8), pp. 4729-4742; Lin, L., Chen, C., Yang, J., Zhang, S., Deep transfer hsi classification method based on information measure and optimal neighborhood noise reduction (2019) Electronics, 8 (10), p. 1112; Zhang, H., Li, Y., Jiang, Y., Wang, P., Shen, Q., Shen, C., Hyperspectral classification based on lightweight 3-d-cnn with transfer learning (2019) IEEE Trans. Geosci. Remote Sens., 57 (8), pp. 5813-5828; Jiang, Y., Li, Y., Zhang, H., Hyperspectral image classification based on 3-d separable resnet and transfer learning (2019) IEEE Geosci. Remote Sens. Lett., 16 (12), pp. 1949-1953; Deng, C., Xue, Y., Liu, X., Li, C., Tao, D., Active transfer learning network: a unified deep joint spectral–spatial feature learning model for hyperspectral image classification (2018) IEEE Trans. Geosci. Remote Sens., 57 (3), pp. 1741-1754; Ghifary, M., Kleijn, W., Zhang, M., Domain adaptive neural networks for object recognition (2014), pp. 898-904. , Pacific Rim International Conference on Artificial Intelligence, Springer; Tzeng, E., Hoffman, J., Zhang, N., Saenko, K., Darrell, T., Deep domain confusion: maximizing for domain invariance, arXiv preprint arXiv:1412.3474; Wang, Z., Du, B., Shi, Q., Tu, W., Domain adaptation with discriminative distribution and manifold embedding for hyperspectral image classification (2019) IEEE Geosci. Remote Sens. Lett., 16 (7), pp. 1155-1159; Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V., Domain-adversarial training of neural networks (2016) J. Mach. Learn. Res., 17 (1), pp. 2030-2096; Elshamli, A., Taylor, G., Berg, A., Areibi, S., Domain adaptation using representation learning for the classification of remote sensing images (2017) IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens., 10 (9), pp. 4198-4209; Settles, B., (2009), Active learning literature survey, Tech. rep., University of Wisconsin-Madison Department of Computer Sciences; Haut, J., Paoletti, M., Plaza, J., Li, J., Plaza, A., Active learning with convolutional neural networks for hyperspectral image classification using a new bayesian approach (2018) IEEE Trans. Geosci. Remote Sens., 56 (11), pp. 6440-6461; Liu, P., Zhang, H., Eom, K., Active deep learning for classification of hyperspectral images (2016) IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens., 10 (2), pp. 712-724; Li, J., Active learning for hyperspectral image classification with a stacked autoencoders based neural network (2015), pp. 1-4. , 2015 7th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS), IEEE; Sun, Y., Li, J., Wang, W., Antonio, P., Chen, Z., Active learning based autoencoder for hyperspectral imagery classification (2016), pp. 469-472. , 2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS), IEEE; Cao, X., Yao, J., Xu, Z., Meng, D., Hyperspectral image classification with convolutional neural network and active learning, IEEE Trans. Geosci. Remote Sens; Deng, C., Xue, Y., Liu, X., Li, C., Tao, D., Active transfer learning network: a unified deep joint spectral–spatial feature learning model for hyperspectral image classification (2018) IEEE Trans. Geosci. Remote Sens., 57 (3), pp. 1741-1754; Snell, J., Swersky, K., Zemel, R., Prototypical networks for few-shot learning (2017), pp. 4077-4087. , Advances in Neural Information Processing Systems; Liu, Y., Su, M., Liu, L., Li, C., Peng, Y., Hou, J., Jiang, T., Deep residual prototype learning network for hyperspectral image classification (2020) Second Target Recognition and Artificial Intelligence Summit Forum, 11427, p. 1142705. , International Society for Optics and Photonics; Tang, H., Li, Y., Han, X., Huang, Q., Xie, W., A spatial–spectral prototypical network for hyperspectral remote sensing image (2019) IEEE Geosci. Remote Sens. Lett., 17 (1), pp. 167-171; Xi, B., Li, J., Li, Y., Song, R., Shi, Y., Liu, S., Du, Q., Deep prototypical networks with hybrid residual attention for hyperspectral image classification (2020) IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens., 13, pp. 3683-3700; Muqeet, A., Iqbal, M., Bae, S., Hran: hybrid residual attention network for single image super-resolution (2019) IEEE Access, 7, pp. 137020-137029; Sung, F., Yang, Y., Zhang, L., Xiang, T., Torr, P.H.S., Hospedales, T.M., Learning to compare: relation network for few-shot learning (2018), pp. 1199-1208. , Proc. IEEE Conf. Comput. Vis. Pattern Recognit; Deng, B., Shi, D., Relation network for hyperspectral image classification (2019), pp. 483-488. , 2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW), IEEE; Gao, K., Liu, B., Yu, X., Qin, J., Zhang, P., Tan, X., Deep relation network for hyperspectral image few-shot classification (2020) Remote Sens., 12 (6), p. 923; Ma, X., Ji, S., Wang, J., Geng, J., Wang, H., Hyperspectral image classification based on two-phase relation learning network (2019) IEEE Trans. Geosci. Remote Sens., 57 (12), pp. 10398-10409; Rao, M., Tang, P., Zhang, Z., Spatial–spectral relation network for hyperspectral image classification with limited training samples (2019) IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens., 12 (12), pp. 5086-5100; Jane, B., Isabelle, G., Yann, L., Eduard, S., Roopak, S., Signature verification using a siamese time delay neural network (1994), pp. 737-744. , Advances in Neural Information Processing Systems; Sumit, C., Raia, H., Yann, L., Learning a similarity metric discriminatively, with application to face verification (2005), 1, pp. 539-546. , Proc. IEEE Conf. Comput. Vis. Pattern Recognit., IEEE; Norouzi, M., Fleet, D., Salakhutdinov, R., Hamming distance metric learning (2012), pp. 1061-1069. , Advances in Neural Information Processing Systems; Liu, B., Yu, X., Zhang, P., Yu, A., Fu, Q., Wei, X., Supervised deep feature extraction for hyperspectral image classification (2017) IEEE Trans. Geosci. Remote Sens., 56 (4), pp. 1909-1921; Liu, B., Yu, X., Yu, A., Wan, G., Deep convolutional recurrent neural network with transfer learning for hyperspectral image classification (2018) J. Appl. Remote Sens., 12 (2); Li, Z., Tang, X., Li, W., Wang, C., Liu, C., He, J., A two-stage deep domain adaptation method for hyperspectral image classification (2020) Remote Sens., 12 (7), p. 1054; Huang, L., Chen, Y., Dual-path siamese cnn for hyperspectral image classification with limited training samples, IEEE Geosci. Remote Sens. Lett; Rao, M., Tang, P., Zhang, Z., A developed siamese cnn with 3d adaptive spatial-spectral pyramid pooling for hyperspectral image classification (2020) Remote Sens., 12 (12), p. 1964; Miao, J., Wang, B., Wu, X., Zhang, L., Hu, B., Zhang, J., Deep feature extraction based on siamese network and auto-encoder for hyperspectral image classification (2019), pp. 397-400. , IGARSS 2019-2019 IEEE International Geoscience and Remote Sensing Symposium, IEEE; Deng, B., Jia, S., Shi, D., Deep metric learning-based feature embedding for hyperspectral image classification (2020) IEEE Trans. Geosci. Remote Sens., 58 (2), pp. 1422-1435; Yang, J., Zhao, Y., Chan, J., Learning and transferring deep joint spectral-spatial features for hyperspectral classification (2017) IEEE Trans. Geosci. Remote Sens., 55 (8), pp. 4729-4742; Hu, L., Luo, X., Wei, Y., Hyperspectral image classification of convolutional neural network combined with valuable samples (2020) J. Phys. Conf. Ser., 1549; Wan, S., Gong, C., Zhong, P., Du, B., Zhang, L., Yang, J., Multiscale dynamic graph convolutional network for hyperspectral image classification (2019) IEEE Trans. Geosci. Remote Sens., 58 (5), pp. 3162-3177; Liu, B., Gao, K., Yu, A., Guo, W., Wang, R., Zuo, X., Semisupervised graph convolutional network for hyperspectral image classification (2020) J. Appl. Remote Sens., 14 (2); Wan, S., Gong, C., Zhong, P., Pan, S., Li, G., Yang, J., Hyperspectral image classification with context-aware dynamic graph convolutional network (2020) IEEE Trans. Geosci. Remote Sens., 59 (1), pp. 597-612; Howard, A., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., Mobilenets: efficient convolutional neural networks for mobile vision applications, arXiv preprint arXiv:1704.04861},
correspondence_address1={Yu, S.; Department of Computer Science and Engineering, China; email: yusq@sustech.edu.cn},
publisher={Elsevier B.V.},
issn={09252312},
coden={NRCGE},
language={English},
abbrev_source_title={Neurocomputing},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zhou2021,
author={Zhou, Z. and Shin, J.Y. and Gurudu, S.R. and Gotway, M.B. and Liang, J.},
title={Active, continual fine tuning of convolutional neural networks for reducing annotation effortsL Active continual fine tuningcnnrae},
journal={Medical Image Analysis},
year={2021},
volume={71},
doi={10.1016/j.media.2021.101997},
art_number={101997},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103984392&doi=10.1016%2fj.media.2021.101997&partnerID=40&md5=a34523890d5a3fec65c16117e4591377},
affiliation={Department of medical Informatics, Arizona State University, Scottsdale, AZ  85259, United States; Division of Gastroenterology and Hepatology, Mayo Clinic, Scottsdale, AZ  85259, United States; Department of Radiology, Mayo Clinic, Scottsdale, AZ  85259, United States},
abstract={The splendid success of convolutional neural networks (CNNs) in computer vision is largely attributable to the availability of massive annotated datasets, such as IMAGENET and PLACES. However, in medical imaging, it is challenging to create such large annotated datasets, as annotating medical images is not only tedious, laborious, and time consuming, but it also demands costly, specialty-oriented skills, which are not easily accessible. To dramatically reduce annotation cost, this paper presents a novel method to naturally integrate active learning and transfer learning (fine-tuning) into a single framework, which starts directly with a pre-trained CNN to seek “worthy” samples for annotation and gradually enhances the (fine-tuned) CNN via continual fine-tuning. We have evaluated our method using three distinct medical imaging applications, demonstrating that it can reduce annotation efforts by at least half compared with random selection. © 2021 Elsevier B.V.},
author_keywords={Active learning;  Annotation cost reduction;  Computer-aided diagnosis;  Convolutional neural networks;  Medical image analysis;  Transfer learning},
keywords={Convolution;  Large dataset;  Medical imaging;  Transfer learning, Active Learning;  Annotated datasets;  Fine tuning;  Imaging applications;  Random selection, Convolutional neural networks, active learning;  Article;  binary classification;  colon polyp;  colonoscopy;  computer assisted diagnosis;  convolutional neural network;  deep learning;  diagnostic imaging;  disease classification;  human;  image analysis;  image quality;  learning algorithm;  lung embolism;  machine learning;  major clinical study;  multiclass classification;  priority journal},
funding_details={National Institutes of HealthNational Institutes of Health, NIH, R01HL128785},
funding_details={Mayo ClinicMayo Clinic},
funding_details={Arizona State UniversityArizona State University, ASU},
funding_text 1={This research has been supported partially by ASU and Mayo Clinic through a Seed Grant and an Innovation Grant, and partially by the NIH under Award Number R01HL128785 . The content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH. We thank S. Tatapudi and A. Pluhar for helping improve the writing of this paper. The content of this paper is covered by patents pending.},
references={Aggarwal, U., Popescu, A., Hudelot, C., Active learning for imbalanced datasets (2020) Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pp. 1428-1437; Ardila, D., Kiraly, A.P., Bharadwaj, S., Choi, B., Reicher, J.J., Peng, L., Tse, D., Corrado, G., End-to-end lung cancer screening with three-dimensional deep learning on low-dose chest computed tomography (2019) Nat. Med., 25 (6), pp. 954-961; Azizi, S., Mustafa, B., Ryan, F., Beaver, Z., Freyberg, J., Deaton, J., Loh, A., Chen, T., (2021), Big self-supervised models advance medical image classification. arXiv preprint arXiv:2101.05224; Balcan, M.-F., Broder, A., Zhang, T., Margin based active learning (2007) International Conference on Computational Learning Theory, pp. 35-50. , Springer; Beluch, W.H., Genewein, T., Nürnberger, A., Köhler, J.M., The power of ensembles for active learning in image classification (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9368-9377; Borisov, A., Tuv, E., Runger, G., Active batch learning with stochastic query by forest (2010) JMLR: Workshop and Conference Proceedings (2010), , Citeseer; Bortsova, G., Dubost, F., Hogeweg, L., Katramados, I., de Bruijne, M., Semi-supervised medical image segmentation via learning consistency under transformations (2019) International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 810-818. , Springer; Buda, M., Maki, A., Mazurowski, M.A., A systematic study of the class imbalance problem in convolutional neural networks (2018) Neur. Netw., 106, pp. 249-259; Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P., Joulin, A., (2020), Unsupervised learning of visual features by contrasting cluster assignments. arXiv preprint arXiv:2006.09882; Chakraborty, S., Balasubramanian, V., Sun, Q., Panchanathan, S., Ye, J., Active batch selection via convex relaxations with guaranteed solution bounds (2015) IEEE Trans. Pattern Analy. Mach. Intell., 37 (10), pp. 1945-1958; Chen, S., Ma, K., Zheng, Y., (2019), Med3d: Transfer learning for 3d medical image analysis. arXiv preprint arXiv:1904.00625; Chen, T., Kornblith, S., Norouzi, M., Hinton, G., (2020), A simple framework for contrastive learning of visual representations. arXiv preprint arXiv:2002.05709; Chen, X., He, K., (2020), Exploring simple siamese representation learning. arXiv preprint arXiv:2011.10566; Chen, Z., Liu, B., Lifelong machine learning (2018) Synth. Lect. Artif. Intell. Mach. Learn., 12 (3), pp. 1-207; Cui, W., Liu, Y., Li, Y., Guo, M., Li, Y., Li, X., Wang, T., Ye, C., Semi-supervised brain lesion segmentation with an adapted mean teacher model (2019) International Conference on Information Processing in Medical Imaging, pp. 554-565. , Springer; Culotta, A., McCallum, A., Reducing labeling effort for structured prediction tasks (2005) AAAI, 5, pp. 746-751; Dagan, I., Engelson, S.P., Committee-based sampling for training probabilistic classifiers (1995) Machine Learning Proceedings 1995, pp. 150-157. , Elsevier; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 248-255. , IEEE; Ding, Y., Sohn, J.H., Kawczynski, M.G., Trivedi, H., Harnish, R., Jenkins, N.W., Lituiev, D., Mari Aparici, C., A deep learning model to predict a diagnosis of alzheimer disease by using 18f-FDG PET of the brain (2018) Radiology, 290 (2), pp. 456-464; Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Gelly, S., (2020), An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929; Esteva, A., Kuprel, B., Novoa, R.A., Ko, J., Swetter, S.M., Blau, H.M., Thrun, S., Dermatologist-level classification of skin cancer with deep neural networks (2017) Nature, 542 (7639), p. 115; Esteva, A., Robicquet, A., Ramsundar, B., Kuleshov, V., DePristo, M., Chou, K., Cui, C., Dean, J., A guide to deep learning in healthcare (2019) Nat. Med., 25 (1), pp. 24-29; Feng, R., Zhou, Z., Gotway, M.B., Liang, J., Parts2whole: Self-supervised contrastive learning via reconstruction (2020) Domain Adaptation and Representation Transfer, and Distributed and Collaborative Learning, pp. 85-95. , Springer; Fotedar, G., Tajbakhsh, N., Ananth, S., Ding, X., Extreme consistency: Overcoming annotation scarcity and domain shifts (2020) International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 699-709. , Springer; Gal, Y., Ghahramani, Z., Dropout as a bayesian approximation: Representing model uncertainty in deep learning (2016) international conference on machine learning, pp. 1050-1059. , PMLR; Gal, Y., Islam, R., Ghahramani, Z., Deep bayesian active learning with image data (2017) International Conference on Machine Learning, pp. 1183-1192. , PMLR; Grill, J.-B., Strub, F., Altché, F., Tallec, C., Richemond, P.H., Buchatskaya, E., Doersch, C., Azar, M.G., (2020), Bootstrap your own latent: A new approach to self-supervised learning. arXiv preprint arXiv:2006.07733; Guan, Q., Huang, Y., Multi-label chest x-ray image classification via category-wise residual attention learning (2018) Pattern Recogn. Lett.; Guendel, S., Grbic, S., Georgescu, B., Liu, S., Maier, A., Comaniciu, D., Learning to recognize abnormalities in chest x-rays with location-aware dense networks (2018) Iberoamerican Congress on Pattern Recognition, pp. 757-765. , Springer; Guyon, I., Cawley, G.C., Dror, G., Lemaire, V., Results of the active learning challenge (2011) Active Learning and Experimental Design workshop In conjunction with AISTATS 2010, pp. 19-45; Haghighi, F., Taher, M.R.H., Zhou, Z., Gotway, M.B., Liang, J., Learning semantics-enriched representation via self-discovery, self-classification, and self-restoration (2020) International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 137-147. , Springer; He, H., Garcia, E.A., Learning from imbalanced data (2009) IEEE Trans. Knowl. Data Eng., 21 (9), pp. 1263-1284; He, K., Fan, H., Wu, Y., Xie, S., Girshick, R., Momentum contrast for unsupervised visual representation learning (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9729-9738; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Hino, H., (2020), Active learning: Problem settings and recent developments. arXiv preprint arXiv:2012.04225; Hinton, G., (2021), How to represent part-whole hierarchies in a neural network. arXiv preprint arXiv:2102.12627; Holub, A., Perona, P., Burl, M.C., Entropy-based active learning for object recognition (2008) 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, pp. 1-8. , IEEE; Huang, G., Liu, Z., Weinberger, K.Q., van der Maaten, L., Densely connected convolutional networks (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 1, p. 3; Huang, S.-C., Kothari, T., Banerjee, I., Chute, C., Ball, R.L., Borus, N., Huang, A., Irvin, J., Peneta scalable deep-learning model for automated diagnosis of pulmonary embolism using volumetric ct imaging (2020) npj Digi. Med., 3 (1), pp. 1-9; Irvin, J., Rajpurkar, P., Ko, M., Yu, Y., Ciurea-Ilcus, S., Chute, C., Marklund, H., Shpanskaya, K., Chexpert: A large chest radiograph dataset with uncertainty labels and expert comparison (2019) Proceedings of the AAAI Conference on Artificial Intelligence, 33, pp. 590-597; Isensee, F., Jaeger, P.F., Kohl, S.A.A., Petersen, J., Maier-Hein, K.H., nnu-net: a self-configuring method for deep learning-based biomedical image segmentation (2021) Nat. Method., 18 (2), pp. 203-211; Japkowicz, N., Stephen, S., The class imbalance problem: A systematic study (2002) Intell. Data Analy., 6 (5), pp. 429-449; Käding, C., Rodner, E., Freytag, A., Denzler, J., Fine-tuning deep neural networks in continuous learning scenarios (2016) Asian Conference on Computer Vision, pp. 588-605. , Springer; Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu, A.A., Milan, K., Grabska-Barwinska, A., Overcoming catastrophic forgetting in neural networks (2017) Proceedings of the national academy of sciences, 114 (13), pp. 3521-3526; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in neural information processing systems, pp. 1097-1105; Kukar, M., Transductive reliability estimation for medical diagnosis (2003) Artif. Intell. Med., 29 (1), pp. 81-106; Kulick, J., Lieck, R., Toussaint, M., (2014), Active learning of hyperparameters: An expected cross entropy criterion for active model selection. arXiv e-prints; Kuo, W., Häne, C., Yuh, E., Mukherjee, P., Malik, J., Cost-sensitive active learning for intracranial hemorrhage detection (2018) International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 715-723. , Springer; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), p. 436; Li, X., Guo, Y., Adaptive active learning for image classification (2013) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 859-866; Li, X., Yu, L., Chen, H., Fu, C.-W., Xing, L., Heng, P.-A., Transformation-consistent self-ensembling model for semisupervised medical image segmentation (2020) IEEE Trans. Neur. Netw. Learn. Syst.; Lu, L., Zheng, Y., Carneiro, G., Yang, L., Deep learning and convolutional neural networks for medical image computing (2017) Adv. Comput. Vis. Pattern Recogn.; Ma, Y., Zhou, Q., Chen, X., Lu, H., Zhao, Y., Multi-attention network for thoracic disease classification and localization (2019) ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 1378-1382. , IEEE; Mahapatra, D., Bozorgtabar, B., Thiran, J.-P., Reyes, M., Efficient active learning for image classification and segmentation using a sample selection and conditional generative adversarial network (2018) International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 580-588. , Springer; McCallumzy, A.K., Nigamy, K., Employing EM and pool-based active learning for text classification (1998) Proc. International Conference on Machine Learning (ICML), pp. 359-367. , Citeseer; McCloskey, M., Cohen, N.J., Catastrophic interference in connectionist networks: The sequential learning problem (1989) Psychology of learning and motivation, 24, pp. 109-165. , Elsevier; Moen, E., Bannon, D., Kudo, T., Graf, W., Covert, M., Van Valen, D., Deep learning for cellular image analysis (2019) Nat. Method, pp. 1-14; Mormont, R., Geurts, P., Marée, R., Comparison of deep transfer learning strategies for digital pathology (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 2262-2271; Mundt, M., Hong, Y.W., Pliushch, I., Ramesh, V., (2020), A wholistic view of continual learning with deep neural networks: Forgotten lessons and the bridge to active and open world learning. arXiv preprint arXiv:2009.01797; Munjal, P., Hayat, N., Hayat, M., Sourati, J., Khan, S., (2020), Towards robust and reproducible active learning using neural networks. arXiv, abs/2002.09564; Ozdemir, F., Peng, Z., Tanner, C., Fuernstahl, P., Goksel, O., Active learning for segmentation by optimizing content information for maximal entropy (2018) Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, pp. 183-191. , Springer; Parisi, G.I., Kemker, R., Part, J.L., Kanan, C., Wermter, S., Continual lifelong learning with neural networks: A review (2019) Neur. Netw., 113, pp. 54-71; Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T., Efros, A.A., Context encoders: Feature learning by inpainting (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2536-2544; Purushwalkam, S., Gupta, A., (2020), Demystifying contrastive self-supervised learning: Invariances, augmentations and dataset biases. arXiv preprint arXiv:2007.13916; Ravizza, S., Huschto, T., Adamov, A., Böhm, L., Büsser, A., Flöther, F.F., Hinzmann, R., Robertson, D.H., Predicting the early risk of chronic kidney disease in patients with diabetes using real-world data (2019) Nat. Med., 25 (1), pp. 57-59; Ren, P., Xiao, Y., Chang, X., Huang, P.-Y., Li, Z., Chen, X., Wang, X., (2020), A survey of deep active learning. arXiv preprint arXiv:2009.00236; Sabour, S., Frosst, N., Hinton, G.E., (2017), Dynamic routing between capsules. arXiv preprint arXiv:1710.09829; Scheffer, T., Decomain, C., Wrobel, S., Active hidden markov models for information extraction (2001) International Symposium on Intelligent Data Analysis, pp. 309-318. , Springer; Sener, O., Savarese, S., (2017), Active learning for convolutional neural networks: A core-set approach. arXiv preprint arXiv:1708.00489; Settles, B., Active learning literature survey. University of Wisconsin, Madison 52 (55-66), 11; Shannon, C.E., A mathematical theory of communication (1948) Bell Syst. Techn. J., 27 (3), pp. 379-423; Shao, W., Sun, L., Zhang, D., Deep active learning for nucleus classification in pathology images (2018) 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018), pp. 199-202. , IEEE; Shen, D., Liu, T., Peters, T.M., Staib, L.H., Essert, C., Zhou, S., Yap, P.-T., Khan, A., Medical Image Computing and Computer Assisted Intervention–MICCAI 2019: 22nd International Conference, Shenzhen, China, October 13–17, 2019, Proceedings (2019), 11767. , Springer Nature; Shui, C., Zhou, F., Gagné, C., Wang, B., Deep active learning: Unified and principled method for query and training (2020) International Conference on Artificial Intelligence and Statistics, pp. 1308-1318. , PMLR; Simonyan, K., Zisserman, A., (2014), Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556; Sourati, J., Akcakaya, M., Dy, J.G., Leen, T.K., Erdogmus, D., Classification active learning based on mutual information (2016) Entropy, 18 (2), p. 51; Sourati, J., Gholipour, A., Dy, J.G., Kurugol, S., Warfield, S.K., Active deep learning with fisher information for patch-wise semantic segmentation (2018) Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, pp. 83-91. , Springer; Sourati, J., Gholipour, A., Dy, J.G., Tomas-Fernandez, X., Kurugol, S., Warfield, S.K., Intelligent labeling based on fisher information for medical image segmentation using deep learning (2019) IEEE Trans. Med. Imaging, 38 (11), pp. 2642-2653; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going Deeper with Convolutions (2015), Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Tajbakhsh, N., Gotway, M.B., Liang, J., Computer-aided pulmonary embolism detection using a novel vessel-aligned multi-planar image representation and convolutional neural networks (2015) International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 62-69. , Springer; Tajbakhsh, N., Jeyaseelan, L., Li, Q., Chiang, J.N., Wu, Z., Ding, X., Embracing imperfect datasets: A review of deep learning solutions for medical image segmentation (2020) Med. Image Analy., p. 101693; Tajbakhsh, N., Shin, J.Y., Gotway, M.B., Liang, J., Computer-aided detection and visualization of pulmonary embolism using a novel, compact, and discriminative image representation (2019) Med. Image Analy., 58, p. 101541; Tajbakhsh, N., Shin, J.Y., Gurudu, S.R., Hurst, R.T., Kendall, C.B., Gotway, M.B., Liang, J., Convolutional neural networks for medical image analysis: Full training or fine tuning? (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1299-1312; Tang, Y., Wang, X., Harrison, A.P., Lu, L., Xiao, J., Summers, R.M., Attention-guided curriculum learning for weakly supervised classification and localization of thoracic diseases on chest radiographs (2018) International Workshop on Machine Learning in Medical Imaging, pp. 249-258. , Springer; Touvron, H., Vedaldi, A., Douze, M., Jégou, H., (2020), Fixing the train-test resolution discrepancy: Fixefficientnet. arXiv preprint arXiv:2003.08237; Tsymbalov, E., Panov, M., Shapeev, A., Dropout-based active learning for regression (2018) International conference on analysis of images, social networks and texts, pp. 247-258. , Springer; Venturini, L., Papageorghiou, A.T., Noble, J.A., Namburete, A.I.L., Uncertainty estimates as data selection criteria to boost omni-supervised learning (2020) International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 689-698. , Springer; Wang, W., Lu, Y., Wu, B., Chen, T., Chen, D.Z., Wu, J., Deep active self-paced learning for accurate pulmonary nodule segmentation (2018) International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 723-731. , Springer; Yamamoto, Y., Tsuzuki, T., Akatsuka, J., Ueki, M., Morikawa, H., Numata, Y., Takahara, T., Nakazawa, R., Automated acquisition of explainable knowledge from unannotated histopathology images (2019) Nat. Commun., 10 (1), pp. 1-9; Yang, L., Zhang, Y., Chen, J., Zhang, S., Chen, D.Z., (2017), Suggestive annotation: A deep active learning framework for biomedical image segmentation. arXiv preprint arXiv:1706.04737; Yu, L., Wang, S., Li, X., Fu, C.-W., Heng, P.-A., Uncertainty-aware self-ensembling model for semi-supervised 3d left atrium segmentation (2019) International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 605-613. , Springer; Yuan, M., Lin, H.-T., Boyd-Graber, J., (2020), Cold-start active learning through self-supervised language modeling. arXiv preprint arXiv:2010.09535; Yuan, X.-T., Zhang, T., Truncated power method for sparse eigenvalue problems (2013) J. Mach. Learn. Res., 14 (Apr), pp. 899-925; Zhang, R., Isola, P., Efros, A.A., Colorful image colorization (2016) Proceedings of the European Conference on Computer Vision, pp. 649-666. , Springer; Zhou, B., Lapedriza, A., Khosla, A., Oliva, A., Torralba, A., Places: A 10 million image database for scene recognition (2017) IEEE Trans. Pattern Analy. Mach. Intell.; Zhou, S.K., Rueckert, D., Fichtinger, G., Handbook of Medical Image Computing and Computer Assisted Intervention (2019), Academic Press; Zhou, Z., Shin, J., Feng, R., Hurst, R.T., Kendall, C.B., Liang, J., Integrating active learning and transfer learning for carotid intima-media thickness video interpretation (2019) Journal of digital imaging, 32 (2), pp. 290-299; Zhou, Z., Shin, J., Zhang, L., Gurudu, S., Gotway, M., Liang, J., Fine-tuning convolutional neural networks for biomedical image analysis: actively and incrementally (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7340-7349; Zhou, Z., Sodha, V., Pang, J., Gotway, M.B., Liang, J., Models genesis (2021) Med. Image Analy., 67, p. 101840. , http://www.sciencedirect.com/science/article/pii/S1361841520302048; Zhou, Z., Sodha, V., Rahman Siddiquee, M.M., Feng, R., Tajbakhsh, N., Gotway, M.B., Liang, J., Models genesis: Generic autodidactic models for 3d medical image analysis (2019) Medical Image Computing and Computer Assisted Intervention – MICCAI 2019, pp. 384-393. , https://link.springer.com/chapter/10.1007/978-3-030-32251-9_42, Springer International Publishing Cham; Zhu, J., Li, Y., Hu, Y., Ma, K., Zhou, S.K., Zheng, Y., Rubik's cube+: A self-supervised feature learning framework for 3d medical image analysis (2020) Med. Image Analy., 64, p. 101746},
correspondence_address1={Liang, J.; Department of medical Informatics, United States; email: Jianming.Liang@asu.edu},
publisher={Elsevier B.V.},
issn={13618415},
coden={MIAEC},
language={English},
abbrev_source_title={Med. Image Anal.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Li2021223,
author={Li, C. and Chen, X. and Wang, H. and Wang, P. and Zhang, Y. and Wang, W.},
title={End-to-end attack on text-based CAPTCHAs based on cycle-consistent generative adversarial network},
journal={Neurocomputing},
year={2021},
volume={433},
pages={223-236},
doi={10.1016/j.neucom.2020.11.057},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100206839&doi=10.1016%2fj.neucom.2020.11.057&partnerID=40&md5=75eb85a31438e5c6b4b155a7672c002b},
affiliation={College of Cybersecurity, Sichuan University, Chengdu, 610065, China; College of Cybersecurity and the Cybersecurity Research Institute, Sichuan University, Chengdu, 610065, China; College of Computer Science, Sichuan University, Chengdu, 610065, China; College of Art, Sichuan University, Chengdu, 610065, China},
abstract={As a widely deployed security scheme, text-based completely automated public Turing tests to tell computers and humans apart (CAPTCHAs) have become increasingly unable to resist machine learning-based attacks. So far, many researchers have conducted studies on approaches for attacking text-based CAPTCHAs deployed by different companies, such as Microsoft, Amazon, and Apple, and achieved specific results. However, most of these attacks have shortcomings, such as the poor portability of attack methods, which require a series of data preprocessing steps and rely on large amounts of labeled CAPTCHAs. In this study, we propose an efficient and simple end-to-end attack method based on cycle-consistent generative adversarial networks (Cycle-GANs). Compared to previous studies, our approach significantly reduces the cost of data labeling. Additionally, this method has high portability. It can attack ordinary text-based CAPTCHA schemes only by modifying a few configuration parameters, which makes the attack easier to execute. First, we train CAPTCHA synthesizers based on the Cycle-GAN to generate some fake samples. Basic recognizers based on a convolutional recurrent neural network are trained using the fake data. Subsequently, an active transfer learning method is employed to optimize the basic recognizer utilizing tiny amounts of labeled real-world CAPTCHA samples. Our approach efficiently cracked the CAPTCHA schemes deployed by 10 popular websites, indicating that our attack method may be universal. Additionally, we analyzed the current most popular anti-recognition mechanisms. The results show that the combination of more anti-recognition mechanisms can improve the security of CAPTCHAs. However, the improvement is limited. Conversely, generating more complex CAPTCHAs may cost more resources and reduce the usability of CAPTCHAs. © 2020},
author_keywords={Active transfer learning;  CAPTCHAs;  CRNN;  Cycle-GAN},
keywords={Convolutional neural networks;  Cost reduction;  Electronic mail filters;  Learning systems;  Recurrent neural networks;  Transfer learning, Adversarial networks;  Attack methods;  Configuration parameters;  Data labeling;  Data preprocessing;  Recognition mechanism;  Security scheme;  Transfer learning methods, Network security},
funding_details={Sichuan Province Science and Technology Support ProgramSichuan Province Science and Technology Support Program, 20YYJC4001},
funding_details={National Natural Science Foundation of ChinaNational Natural Science Foundation of China, NSFC, 61802271, 81602935, 81773548, U19A2081},
funding_details={Fundamental Research Funds for the Central UniversitiesFundamental Research Funds for the Central Universities, SCU2020D038},
funding_text 1={This study was supported by the Fundamental Research Funds for the Central Universities under Grant No. SCU2020D038; the Sichuan Science and Technology Program under Grant No. 20YYJC4001; the National Natural Science Foundation of China (NSFC) under Grant Nos. 61802271, 81602935, 81773548, and U19A2081. The authors thank anonymous reviewers for their helpful comments to improve the paper.},
funding_text 2={This study was supported by the Fundamental Research Funds for the Central Universities under Grant No. SCU2020D038; the Sichuan Science and Technology Program under Grant No. 20YYJC4001; the National Natural Science Foundation of China (NSFC) under Grant Nos. 61802271, 81602935, 81773548, and U19A2081. The authors thank anonymous reviewers for their helpful comments to improve the paper.},
references={Torky, M., Meligy, A., Ibrahim, H., Securing online social networks against bad bots based on a necklace captcha approach (2016) Proceedings of the 12th International Computer Engineering Conference (ICENCO), pp. 158-163. , IEEE; Kim, D., Sample, L., Search prevention with captcha against web indexing: A proof of concept (2019) Proceedings of the 22nd International Conference on Computational Science and Engineering (CSE), pp. 219-224. , IEEE; Gelernter, N., Herzberg, A., Tell me about yourself: The malicious captcha attack (2016) Proceedings of the 25th International Conference on World Wide Web (WWW), pp. 999-1008; Tang, M., Gao, H., Zhang, Y., Liu, Y., Zhang, P., Wang, P., Research on deep learning techniques in breaking text-based captchas and designing image-based captcha (2018) IEEE Transactions on Information Forensics and Security (TIFS), 13, pp. 2522-2537; Shah, M., Harras, K., Hitting three birds with one system: A voice-based captcha for the modern user (2018) Proceedings of the 22nd IEEE International Conference on Web Services (ICWS), pp. 257-264; Gao, H., Wang, W., Qi, J., Wang, X., Liu, X., Yan, J., The robustness of hollow captchas (2013) Proceedings of the 20th ACM SIGSAC Conference on Computer and Communications Security (CCS), pp. 1075-1086. , ACM; Gao, H., Tang, M., Liu, Y., Zhang, P., Liu, X., Research on the security of microsoft's two-layer captcha (2017) IEEE Transactions on Information Forensics and Security (TIFS), 12, pp. 1671-1685; Ye, G., Tang, Z., Fang, D., Zhu, Z., Feng, Y., Xu, P., Chen, X., Wang, Z., Yet another text captcha solver: A generative adversarial network based approach (2018) Proceedings of the 25th ACM SIGSAC Conference on Computer and Communications Security (CCS), pp. 332-348. , ACM; Xu, X., Liu, L., Li, B., A survey of captcha technologies to distinguish between human and computer (2020) Neurocomputing, 408, pp. 292-307; Yan, C., Li, Z., Zhang, Y., Liu, Y., Ji, X., Zhang, Y., Depth image denoising using nuclear norm and learning graph model (2020) ACM Transactions on Multimedia Computing Communications and Applications; George, D., Lehrach, W., Kansky, K., Lázaro-Gredilla, M., Laan, C., Marthi, B., Lou, X., Wang, H., A generative vision model that trains with high data efficiency and breaks text-based captchas (2017) Science, 358, p. 2612; Goodfellow, I.J., Bulatov, Y., Ibarz, J., Arnoud, S., Shet, V., Multi-digit number recognition from street view imagery using deep convolutional neural networks (2014) Proceedings of the 2nd International Conference on Learning Representations (ICLR); Zi, Y., Gao, H., Cheng, Z., Liu, Y., An end-to-end attack on text captchas (2019) IEEE Transactions on Information Forensics and Security (TIFS), 15, pp. 753-766; Zhu, J.-Y., Park, T., Isola, P., Efros, A.A., Unpaired image-to-image translation using cycle-consistent adversarial networks (2017) Proceedings of the IEEE International Conference on Computer Vision (ICCV), pp. 2223-2232; Shi, B., Bai, X., Yao, C., An end-to-end trainable neural network for image-based sequence recognition and its application to scene text recognition (2016) IEEE Transactions on Pattern Analysis and Machine Intelligence, 39, pp. 2298-2304; Mori, G., Malik, J., Recognizing objects in adversarial clutter: Breaking a visual captcha (2003) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), vol. 1, , IEEE pp. I–I; Chellapilla, K., Simard, P.Y., Using machine learning to break visual human interaction proofs (hips) (2005) Proceedings of Advances in Neural Information Processing Systems (NIPS), pp. 265-272; Simard, P.Y., Szeliski, R., Benaloh, J., Couvreur, J., Calinov, I., Using character recognition and segmentation to tell computer from humans (2003) Proceedings of the 7th International Conference on Document Analysis and Recognition (CDAR), pp. 418-423. , IEEE; Yan, J., El Ahmad, A.S., A low-cost attack on a microsoft captcha (2008) Proceedings of the 15th ACM SIGSAC Conference on Computer and Communications Security (CCS), pp. 543-554. , ACM; Franc, V., Hlaváč, V., License plate character segmentation using hidden markov chains (2005) Joint Pattern Recognition Symposium, pp. 385-392. , Springer; Starostenko, O., Cruz-Perez, C., Uceda-Ponga, F., Alarcon-Aquino, V., Breaking text-based captchas with variable word and character orientation (2015) Pattern Recognition, 48, pp. 1101-1112; Liu, P., Guo, J.-M., Wu, C.-Y., Cai, D., Fusion of deep learning and compressed domain features for content-based image retrieval (2017) IEEE Transactions on Image Processing, 26, pp. 5706-5717; Yan, C., Gong, B., Wei, Y., Gao, Y., Deep multi-view enhancement hashing for image retrieval (2020) IEEE Transactions on Pattern Analysis and Machine Intelligence, , 1–1; Schlemper, J., Caballero, J., Hajnal, J.V., Price, A.N., Rueckert, D., A deep cascade of convolutional neural networks for dynamic mr image reconstruction (2017) IEEE transactions on Medical Imaging, 37, pp. 491-503; Yan, C., Shao, B., Zhao, H., Ning, R., Zhang, Y., Xu, F., 3d room layout estimation from a single rgb image (2020) IEEE Transactions on Multimedia, , 1–1; Zhang, K., Zuo, W., Chen, Y., Meng, D., Zhang, L., Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising (2017) IEEE Transactions on Image Processing, 26, pp. 3142-3155; Zhang, L., Xie, Y., Luan, X., He, J., Captcha automatic segmentation and recognition based on improved vertical projection (2017) Proceedings of the 9th IEEE International Conference on Communication Software and Networks (ICCSN), pp. 1167-1172. , IEEE; Isola, P., Zhu, J.-Y., Zhou, T., Efros, A.A., Image-to-image translation with conditional adversarial networks (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1125-1134; Shi, W., Caballero, J., Huszár, F., Totz, J., Aitken, A.P., Bishop, R., Rueckert, D., Wang, Z., Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1874-1883; Kingma, D.P., Ba, J., Adam: A method for stochastic optimization (2015) Proceedings of the 3rd International Conference on Learning Representations (ICLR); Xu, B., Wang, N., Chen, T., Li, M., (2015), Empirical evaluation of rectified activations in convolutional network arXiv preprint arXiv:1505.00853; Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., Chen, X., Improved techniques for training gans (2016) Proceedings of Advances in Neural Information Processing Systems (NIPS), pp. 2234-2242; Lucic, M., Kurach, K., Michalski, M., Gelly, S., Bousquet, O., Are gans created equal? A large-scale study (2018) Proceedings of Advances in Neural Information Processing Systems (NIPS), pp. 700-709; Zhang, R., Isola, P., Efros, A.A., Colorful image colorization (2016), pp. 649-666. , Proceedings of European Conference on Computer Vision (ECCV), Springer; Schuster, M., Paliwal, K.K., Bidirectional recurrent neural networks (1997) IEEE Transactions on Signal Processing, 45, pp. 2673-2681; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778; Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., Densely connected convolutional networks (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4700-4708; Wang, Z., Bovik, A.C., A universal image quality index (2002) IEEE Signal Processing Letters (SPL), 9, pp. 81-84; Huynh-Thu, Q., Ghanbari, M., Scope of validity of psnr in image/video quality assessment (2008) Electronics Letters, 44, pp. 800-801; Guizar-Sicairos, M., Thurman, S.T., Fienup, J.R., Efficient subpixel image registration algorithms (2008) Optics Letters, 33, pp. 156-158; Roberts, J.W., Van Aardt, J.A., Ahmed, F.B., Assessment of image fusion procedures using entropy, image quality, and multispectral classification (2008) Journal of Applied Remote Sensing, 2; Maes, F., Collignon, A., Vandermeulen, D., Marchal, G., Suetens, P., Multimodality image registration by maximization of mutual information (1997) IEEE Transactions on Medical Imaging (TMI), 16, pp. 187-198; Zhang, R., Isola, P., Efros, A.A., Shechtman, E., Wang, O., The unreasonable effectiveness of deep features as a perceptual metric (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 586-595; Bursztein, E., Martin, M., Mitchell, J., Text-based captcha strengths and weaknesses (2011) Proceedings of the 18th ACM SIGSAC Conference on Computer and Communications Security (CCS), pp. 125-138. , ACM; Osadchy, M., Hernandez-Castro, J., Gibson, S., Dunkelman, O., Pérez-Cabo, D., No bot expects the deepcaptcha! introducing immutable adversarial examples, with applications to captcha generation (2017) IEEE Transactions on Information Forensics and Security, 12, pp. 2640-2653; Shi, C., Ji, S., Liu, Q., Liu, C., Chen, Y., He, Y., Liu, Z., Wang, T., Text captcha is dead? A large scale deployment and empirical study (2020) The 27th ACM Conference on Computer and Communications Security},
correspondence_address1={Chen, X.; College of Cybersecurity and the Cybersecurity Research Institute, China; email: chenxsh@scu.edu.cn},
publisher={Elsevier B.V.},
issn={09252312},
coden={NRCGE},
language={English},
abbrev_source_title={Neurocomputing},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Liu2021,
author={Liu, Y. and Hansen, J.},
title={Extracting Features from Driving Scenarios for Driving Workload Level Classification - A Case Study of Transfer Learning},
journal={SAE Technical Papers},
year={2021},
number={2021},
doi={10.4271/2021-01-0189},
note={cited By 0; Conference of SAE 2021 WCX Digital Summit ; Conference Date: 13 April 2021 Through 15 April 2021;  Conference Code:168424},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104867435&doi=10.4271%2f2021-01-0189&partnerID=40&md5=fb966fe5fc9564ef84e45ac8da2faab5},
affiliation={University of Texas, Dallas, United States},
abstract={In the stage of automobile industry transition from SAE level "0,1"low autonomous through "2,3,4"human-in-the-loop and ultimately "5"fully autonomous driving, advanced driving monitor system is critical to understand the status, performance, and behavior of drivers for next-generation intelligent vehicles. By making necessary warnings or adjustments, they could operate collaboratively to ensure a safe and efficient traffic environment. The performance and behavior can be viewed as a reflection of the driver's cognitive workload, which corresponds as well to the environment of their driving scenarios. In this study, image features extracted from driving scenarios, as well as additional environmental features were utilized to classify driving workload levels for different driving scenario video clips. As a continuing study of exploring transfer learning capability, two transfer learning approaches for feature extraction, image segmentation mask transfer approach and image-fixation map overlaid approach were compared and shown comparable results with a 0.910 AUC score and 0.918 AUC score respectively. Environmental information with easy accessibility also shown the effectiveness of contributing to the classification task as additional feature sources. © 2021 SAE International. All rights reserved.},
keywords={Image segmentation;  Transfer learning, Autonomous driving;  Classification tasks;  Cognitive workloads;  Environmental features;  Environmental information;  Extracting features;  Learning capabilities;  Traffic environment, Classification (of information)},
references={(2020) Traffic Safety Facts Annual Report, , Washington, DC: Department of Transportation; Hansen, J.H.L., Busso, C., Zheng, Y., Sathyanarayana, A., Driver Modeling for Detection and Assessment of Driver Distraction: Examples from the UTDrive Test Bed (2017) IEEE Signal Processing Magazine, 34 (4), pp. 130-142; Liu, Y., Hansen, J., Analysis of Driving Performance Based on Driver Experience and Vehicle Familiarity: A UTDrive/Mobile-UTDrive App Study (2019) SAE International Journal of Transportation Safety, 7 (2), pp. 175-191. , https://doi.org/10.4271/09-07-02-0010; Weinger, M.B., Herndon, O.W., Zornow, M.H., Paulus, M.P., An Objective Methodology for Task Analysis and Workload Assessment in Anesthesia Providers (1994) Anesthesiology: The Journal of the American Society of Anesthesiologists, 80 (1), pp. 77-92; Yilu, Z., Yuri, O., Jing, Z., (2004) Driver Cognitive Workload Estimation: A Data-Driven Perspective, pp. 642-647. , Proceedings. The 7th International IEEE Conference on Intelligent Transportation Systems (IEEE Cat. 04TH8749), Washington, DC, IEEE; Brookhuis, K.A., De Waard, D., Monitoring Drivers' Mental Workload in Driving Simulators Using Physiological Measures (2010) Accident Analysis & Prevention, 42 (3), pp. 898-903; Xing, Y., Lv, C., Cao, D., Wang, H., Zhao, Y., Driver Workload Estimation Using a Novel Hybrid Method of Error Reduction Ratio Causality and Support Vector Machine (2018) Measurement, 114, pp. 390-397; Xie, Y., Murphey, Y.L., Kochhar, D., Personalized Driver Workload Estimation Using Deep Neural Network Learning from Physiological and Vehicle Signals (2019) IEEE Transactions on Intelligent Vehicles; Marquart, G., Cabrall, C., De W., J., Review of Eye-Related Measures of Drivers' Mental Workload (2015) Procedia Manufacturing, 3, pp. 2854-2861; Pan, S.J., Yang, Q., A Survey on Transfer Learning (2009) IEEE Transactions on Knowledge and Data Engineering, 22 (10), pp. 1345-1359; Yurtsever, E., Liu, Y., Lambert, J., Miyajima, C., (2019) Risky Action Recognition in Lane Change Video Clips Using Deep Spatiotemporal Networks with Segmentation Mask Transfer, pp. 3100-3107. , 2019 IEEE Intelligent Transportation Systems Conference (ITSC), IEEE; Wu, P., Dietterich, T.G., (2004) Improving SVM Accuracy by Training on Auxiliary Data Sources, p. 110. , Proceedings of the Twenty-First International Conference on Machine Learning; Tobing, P.L., Wu, Y.-C., Hayashi, T., Kobayashi, K., Toda, T., NU Voice Conversion System for the Voice Conversion Challenge 2018 (2018) Odyssey, pp. 219-226; Howard, J., Ruder, S., (2018), Universal Language Model Fine-Tuning for Text Classification," arXiv preprint arXiv:1801.06146; Huang, J.-T., Li, J., Yu, D., Deng, L., Gong, Y., (2013) Cross-Language Knowledge Transfer Using Multilingual Deep Neural Network with Shared Hidden Layers, pp. 7304-7308. , 2013 IEEE International Conference on Acoustics, Speech and Signal Processing, IEEE; Geiger, A., Lauer, M., Wojek, C., Stiller, C., Urtasun, R., 3D Traffic Scene Understanding from Movable Platforms (2013) IEEE Transactions on Pattern Analysis and Machine Intelligence, 36 (5), pp. 1012-1025; Kendall, A., Badrinarayanan, V., Cipolla, R., (2015), Bayesian Segnet: Model Uncertainty in Deep Convolutional Encoder-Decoder Architectures for Scene Understanding," arXiv preprint arXiv:1511.02680; Pan, X., Shi, J., Luo, P., Wang, X., Tang, X., (2017), Spatial as Deep: Spatial CNN for Traffic Scene Understanding," arXiv preprint arXiv:1712.06080; Palazzi, A., Abati, D., Solera, F., Cucchiara, R., Predicting the Driver's Focus of Attention: The DR (Eye) VE Project (2018) IEEE Transactions on Pattern Analysis and Machine Intelligence, 41 (7), pp. 1720-1733; Liu, Y., Hansen, J.H.L., (2019) Towards Complexity Level Classification of Driving Scenarios Using Environmental Information, pp. 810-815. , 2019 IEEE Intelligent Transportation Systems Conference (ITSC), IEEE; He, K., Gkioxari, G., Dollár, P., Girshick, R., (2017) Mask R-CNN, pp. 2961-2969. , Proceedings of the IEEE International Conference on Computer Vision; Haklay, M., Weber, P., Openstreetmap: User-Generated Street Maps (2008) IEEE Pervasive Computing, 7 (4), pp. 12-18; He, K., Zhang, X., Ren, S., Sun, J., (2016) Deep Residual Learning for Image Recognition, pp. 770-778. , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
correspondence_address1={Liu, Y.; University of TexasUnited States; email: yxl152530@utdallas.edu},
sponsors={AAM; appen; ASSEMBLY; AVL; Denso},
publisher={SAE International},
issn={01487191},
language={English},
abbrev_source_title={SAE Techni. Paper.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Chen202153,
author={Chen, C. and Steven, X.},
title={Combined Transfer and Active Learning for High Accuracy Music Genre Classification Method},
journal={2021 IEEE 2nd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering, ICBAIE 2021},
year={2021},
pages={53-56},
doi={10.1109/ICBAIE52039.2021.9390062},
art_number={9390062},
note={cited By 0; Conference of 2nd IEEE International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering, ICBAIE 2021 ; Conference Date: 26 March 2021 Through 28 March 2021;  Conference Code:168280},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104473765&doi=10.1109%2fICBAIE52039.2021.9390062&partnerID=40&md5=85affb0c79c3530d1ae55696ce2c7f04},
affiliation={Ipq Organization Beijing Royal School, Beijing, China; Peking University, Electronics Engineering and Computer Science, Beijing, China},
abstract={Music genre classification system has been widely used by commercial music apps or professional music systems. At the same time, the growing complexity of genres and the rapped combination of multiple genres continuously challenge the accuracy of classical algorithms. Therefore, the need for more advanced genre classification system has been triggered. This paper propose a novel active transfer music genre classification method (ATMGCM) for musical genre classification. After comparing the ATMGCM with SVM and Random Forest, the ATMGCM algorithm has higher accuracy in massive database or with noises. In addition, the simulation results indicate that the ATMGCM has a significant decrease in niche genres. Therefore, the Transfer learning is applied to transfer knowledge from the source dataset to the target dataset, and active learning is applied to determine informative labels of a small part of samples from unlabeled datasets. Through experiments, this study shows that ATMGCM algorithm is effective at classifying genres. Furthermore, this method only need to label about 10%-15% of unlabeled data and can still achieve significant performance improvement. In the future, the research will use RNN model (LSTM) to improve the performance of classification results. © 2021 IEEE.},
author_keywords={Active Learning;  Convolutional Neural Network(CNN);  Genre Classification;  Music Recommendation;  Transfer Learning},
keywords={Big data;  Decision trees;  Internet of things;  Long short-term memory;  Transfer learning, Active Learning;  Classification results;  Genre classification;  High-accuracy;  Music genre classification;  Musical genre classification;  Unlabeled data, Support vector machines},
references={Tzanetakis, G., Cook, P., Musical genre classification of audio signals (2002) IEEE Transactions on Speech and Audio Processing, 10 (5), pp. 293-302. , July; Xu, C., Maddage, N.C., Shao, X., Cao, F., Tian, Q., Musical genre classification using support vector machines (2003) 2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings. (ICASSP '03), pp. V-429. , Hong Kong; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , https://doi.org/10.1109/CVPR.2016.90; Cortes, C., Vapnik, V., Support vector networks (1995) Machine Learning, 20, pp. 1-25; Patel, S.V., Jokhakar, V.N., A random forest based machine learning approach for mild steel defect diagnosis (2016) 2016 IEEE International Conference on Computational Intelligence and Computing Research (ICCIC), pp. 1-8. , Chennai; Pan, S.J., Yang, Q., A survey on transfer learning (2010) IEEE Transactions on Knowledge and Data Engineering, 22 (10), pp. 1345-1359. , Oct; Duplyakin, D., Brown, J., Ricci, R., Active learning in performance analysis (2016) 2016 IEEE International Conference on Cluster Computing (CLUSTER), pp. 182-191. , Taipei; Vidyasagar, M., Kullback-leibler divergence rate between probability distributions on sets of different cardinalities (2010) 49th IEEE Conference on Decision and Control (CDC), pp. 948-953. , Atlanta, GA; Marom, N.D., Rokach, L., Shmilovici, A., Using the confusion matrix for improving ensemble classifiers (2010) 2010 IEEE 26-th Convention of Electrical and Electronics Engineers in Israel, pp. 000555-000559. , Eliat},
sponsors={IEEE},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9780738131221},
language={English},
abbrev_source_title={IEEE Int. Conf. Big Data, Artif. Intell. Internet Things Eng., ICBAIE},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Ang2021738,
author={Ang, S.J. and Wang, W. and Schwalbe-Koda, D. and Axelrod, S. and Gómez-Bombarelli, R.},
title={Active learning accelerates ab initio molecular dynamics on reactive energy surfaces},
journal={Chem},
year={2021},
volume={7},
number={3},
pages={738-751},
doi={10.1016/j.chempr.2020.12.009},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099662441&doi=10.1016%2fj.chempr.2020.12.009&partnerID=40&md5=736240da421c207747480755f19e3be1},
affiliation={Department of Materials Science and Engineering, Massachusetts Institute of Technology, Cambridge, MA, United States; Department of Chemistry and Chemical Biology, Harvard University, Cambridge, MA, United States},
abstract={Through autonomous data acquisition and machine learning, we demonstrate that our neural-network-based reactive force fields allow us to study the dynamical effects of several pericyclic reactions and to predict solvent effects on periselectivity. Our method is over 2,000 times faster than the traditional density functional theory approach, and its accuracy matches the parent quantum mechanical method. Given the efficiency of our machine learning framework, we envisage its applicability in studying larger reactive systems with a higher complexity. © 2020 Elsevier Inc.
Modeling dynamical effects in chemical reactions typically requires ab initio molecular dynamics (AIMD) simulations due to the breakdown of transition state theory (TST). Reactive AIMD simulations are limited to lower-accuracy electronic structure methods and weak statistics because quantum mechanical energies and forces must be evaluated at femtosecond time resolution over many replicas. We report a data-driven pipeline that allows for the treatment of dynamical effects with the same level of theory and overall cost as that of TST approaches. High-throughput ab initio calculations and autonomous data acquisition are coupled to graph convolutional neural-network interatomic potentials, allowing for inexpensive reactive AIMD simulations at quantum mechanical accuracy. We demonstrate the approach by accurately simulating post-TS dynamical effects in three distinct pericyclic reactions, including a challenging trispericyclic reaction with a complex bifurcating potential energy surface. This approach is broadly applicable to understanding dynamical effects and predicting reaction outcomes in large, previously intractable systems. © 2020 Elsevier Inc.
In silico elucidation of reaction mechanisms using density functional theory (DFT) can explain and predict experimental observations. However, because of the computational cost of accurate DFT simulations, theoretical studies are often restricted to systems with fewer than 100 atoms at a few stationary points on potential energy surfaces. These can be insufficient for describing challenging reaction mechanisms where dynamical effects are important. Herein, we report a low-cost transferable pipeline that accelerates ab initio molecular dynamics by a factor of 2,000. It consists of high-throughput DFT computation, active learning, and transfer learning to train high-quality reactive force fields based on neural networks. These force fields reproduce the underlying DFT potential energy surface and enable reactive dynamics simulations. We anticipate that our pipeline will lead to accurate and affordable mechanistic studies of complex, experimentally relevant reactive systems. © 2020 Elsevier Inc.},
author_keywords={ab initio molecular dynamics;  artificial intelligence;  bifurcating potential energy surface;  graph convolutional neural networks;  machine learning;  organic reaction mechanisms;  quantum chemistry;  reactive force fields;  SDG9: Industry, innovation, and infrastructure},
funding_details={Defense Advanced Research Projects AgencyDefense Advanced Research Projects Agency, DARPA, HR00111920025},
funding_details={Toyota Research InstituteToyota Research Institute, TRI},
funding_text 1={S.J.A. thanks the financial support from the Agency for Science, Technology and Research, Singapore (A?STAR) through the A?STAR Graduate Scholarship (Postdoctoral Fellowship). W.W. thanks the Toyota Research Institute, D. S.-K. thanks the MIT Energy Initiative Seed Fund, S.A. thanks the MIT Buchsbaum Fund and DARPA HR00111920025, and R.G.-B. thanks MIT DMSE and Toyota Faculty Chair for support. The computations in this paper were executed at the Massachusetts Green High-Performance Computing Center with support from MIT Research Computing. R.G.-B. conceived and supervised the project, R.G.-B. and S.J.A. designed and planned the research; S.J.A. W.W. D.S.-K. S.A. and R.G.-B. developed the computational tools; S.J.A. executed the research; S.J.A. wrote the first manuscript draft; all authors contributed to writing and editing of the manuscript. The authors declare no competing interests.},
references={Hare, S.R., Tantillo, D.J., Post-transition state bifurcations gain momentum – current state of the field (2017) Pure Appl. Chem., 89, pp. 679-698; Tan, J.S.J., Hirvonen, V., Paton, R.S., Dynamic intermediates in the radical cation Diels-alder cycloaddition: lifetime and suprafacial stereoselectivity (2018) Org. Lett., 20, pp. 2821-2825; Yang, Z., Jamieson, C.S., Xue, X.-S., Garcia-Borràs, M., Benton, T., Dong, X., Liu, F., Houk, K.N., Mechanisms and dynamics of reactions involving entropic intermediates (2019) Trends Chem., 1, pp. 22-34; Yang, Z., Yang, S., Yu, P., Li, Y., Doubleday, C., Park, J., Patel, A., Liu, H.-W., Influence of water and enzyme SpnF on the dynamics and energetics of the ambimodal [6+4]/[4+2] cycloaddition (2018) Proc. Natl. Acad. Sci. USA, 115, pp. E848-E855; Ohashi, M., Liu, F., Hai, Y., Chen, M., Tang, M.C., Yang, Z., Sato, M., Tang, Y., SAM-dependent enzyme-catalysed pericyclic reactions in natural product biosynthesis (2017) Nature, 549, pp. 502-506; Iftimie, R., Minary, P., Tuckerman, M.E., Ab initio molecular dynamics: concepts, recent developments, and future trends (2005) Proc. Natl. Acad. Sci. USA, 102, pp. 6654-6659; Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G.S., Devin, M., TensorFlow: large-scale machine learning on heterogeneous distributed systems (2016) arXiv; Butler, K.T., Davies, D.W., Cartwright, H., Isayev, O., Walsh, A., Machine learning for molecular and materials science (2018) Nature, 559, pp. 547-555; Wang, W., Axelrod, S., Gómez-Bombarelli, R., Differentiable molecular simulations for control and learning (2020) arXiv, , arXiv:2003.00868; Behler, J., Parrinello, M., Generalized neural-network representation of high-dimensional potential-energy surfaces (2007) Phys. Rev. Lett., 98, p. 146401; Smith, J.S., Isayev, O., Roitberg, A.E., ANI-1: an extensible neural network potential with DFT accuracy at force field computational cost (2017) Chem. Sci., 8, pp. 3192-3203; Smith, J.S., Nebgen, B.T., Zubatyuk, R., Lubbers, N., Devereux, C., Barros, K., Tretiak, S., Roitberg, A.E., Approaching coupled cluster accuracy with a general-purpose neural network potential through transfer learning (2019) Nat. Commun., 10, p. 2903; Devereux, C., Smith, J.S., Davis, K.K., Barros, K., Zubatyuk, R., Isayev, O., Roitberg, A.E., Extending the applicability of the ANI deep learning molecular potential to sulfur and halogens (2020) J Chem Theory Comput, 16, pp. 4192-4202; Schütt, K.T., Arbabzadah, F., Chmiela, S., Müller, K.R., Tkatchenko, A., Quantum-chemical insights from deep tensor neural networks (2017) Nat. Commun., 8, p. 13890; Schütt, K.T., Sauceda, H.E., Kindermans, P.J., Tkatchenko, A., Müller, K.R., SchNet - A deep learning architecture for molecules and materials (2018) J. Chem. Phys., 148, p. 241722; Schütt, K.T., Kessel, P., Gastegger, M., Nicoli, K.A., Tkatchenko, A., Müller, K.R., SchNetPack: A deep learning toolbox for atomistic systems (2019) J. Chem. Theor. Comput., 15, pp. 448-455; Zhang, L., Han, J., Wang, H., Car, R., E, W., Deep potential molecular dynamics: a scalable model with the accuracy of quantum mechanics (2018) Phys. Rev. Lett., 120, p. 143001; Chen, C., Ye, W., Zuo, Y., Zheng, C., Ong, S.P., Graph networks as a universal machine learning framework for molecules and crystals (2019) Chem. Mater., 31, pp. 3564-3572; Klicpera, J., Groß, J., Günnemann, S., Directional message passing for molecular graphs (2020) arXiv, p. 03123; Qiao, Z., Welborn, M., Anandkumar, A., Manby, F.R., Miller, T.F., OrbNet: deep learning for quantum chemistry using symmetry-adapted atomic-orbital features (2020) J. Chem. Phys., 153, p. 124111; Wang, W., Gómez-Bombarelli, R., Coarse-graining auto-encoders for molecular dynamics (2019) npj Comput. Mater., 5, p. 125; Ruza, J., Wang, W., Schwalbe-Koda, D., Axelrod, S., Harris, W.H., Gómez-Bombarelli, R., Temperature-transferable coarse-graining of ionic liquids with dual graph convolutional neural networks (2020) J Chem Phys, 153, p. 164501; Noé, F., Tkatchenko, A., Müller, K.R., Clementi, C., Machine learning for molecular simulation (2020) Annu. Rev. Phys. Chem., 71, pp. 361-390; Coley, C.W., Eyke, N.S., Jensen, K.F., Autonomous discovery in the chemical sciences part I: progress (2020) Angew. Chem. Int. Ed. Engl., 59, pp. 22858-22893; Yao, K., Herr, J.E., Toth, D.W., Mckintyre, R., Parkhill, J., The TensorMol-0.1 model chemistry: a neural network augmented with long-range physics (2018) Chem. Sci., 9, pp. 2261-2269; Koistinen, O.P., Ásgeirsson, V., Vehtari, A., Jónsson, H., Nudged elastic band calculations accelerated with Gaussian process regression based on inverse interatomic distances (2019) J. Chem. Theor. Comput., 15, pp. 6738-6751; Garrido Torres, J.A., Jennings, P.C., Hansen, M.H., Boes, J.R., Bligaard, T., Low-scaling algorithm for nudged elastic band calculations using a surrogate machine learning model (2019) Phys. Rev. Lett., 122, p. 156001; Hachmann, J., Olivares-Amaya, R., Atahan-Evrenk, S., Amador-Bedolla, C., Sánchez-Carrera, R.S., Gold-Parker, A., Vogt, L., Aspuru-Guzik, A., The harvard clean energy project: large-scale computational screening and design of organic photovoltaics on the world community grid (2011) J. Phys. Chem. Lett., 2, pp. 2241-2251; Lin, K., Gómez-Bombarelli, R., Beh, E.S., Tong, L., Chen, Q., Valle, A., Aspuru-Guzik, A., Gordon, R.G., A redox-flow battery with an alloxazine-based organic electrolyte (2016) Nat. Energy, 1, p. 16102; Gómez-Bombarelli, R., Aguilera-Iparraguirre, J., Hirzel, T.D., Duvenaud, D.K., Maclaurin, D., Blood-Forsythe, M.A., Chae, H.S., Wu, T., Design of efficient molecular organic light-emitting diodes by a high-throughput virtual screening and experimental approach (2016) Nat. Mater., 15, pp. 1120-1127; Pun, G.P.P., Batra, R., Ramprasad, R., Mishin, Y., Physically informed artificial neural networks for atomistic modeling of materials (2019) Nat. Commun., 10, p. 2339; Wei, J.N., Duvenaud, D., Aspuru-Guzik, A., Neural networks for the prediction of organic chemistry reactions (2016) ACS Cent. Sci., 2, pp. 725-732; Ioannidis, E.I., Gani, T.Z.H., Kulik, H.J., molSimplify: a toolkit for automating discovery in inorganic chemistry (2016) J. Comput. Chem., 37, pp. 2106-2117; Friederich, P., dos Passos Gomes, G., De Bin, R., Aspuru-Guzik, A., Balcells, D., Machine learning dihydrogen activation in the chemical space surrounding Vaska's complex (2020) Chem. Sci., 11, pp. 4584-4601; Grambow, C.A., Pattanaik, L., Green, W.H., Deep learning of activation energies (2020) J. Phys. Chem. Lett., 11, pp. 2992-2997; Smith, J.S., Nebgen, B., Lubbers, N., Isayev, O., Roitberg, A.E., Less is more: sampling chemical space with active learning (2018) J. Chem. Phys., 148, p. 241733; Liu, C.Y., Ding, S.T., Cycloadditions of electron-deficient 8,8-disubstituted heptafulvenes to electron-rich 6,6-disubstituted fulvenes (1992) J. Org. Chem., 57, pp. 4539-4544; Xue, X.S., Jamieson, C.S., Garcia-Borràs, M., Dong, X., Yang, Z., Houk, K.N., Ambimodal Trispericyclic transition state and dynamic control of periselectivity (2019) J. Am. Chem. Soc., 141, pp. 1217-1221; Settles, B., Active learning literature survey (2009), http://digital.library.wisc.edu/1793/60660; Ribeiro, R.F., Marenich, A.V., Cramer, C.J., Truhlar, D.G., Use of solution-phase vibrational frequencies in continuum models for the free energy of solvation (2011) J. Phys. Chem. B, 115, pp. 14556-14562; Grimme, S., Supramolecular binding thermodynamics by dispersion-corrected density functional theory (2012) Chemistry, 18, pp. 9955-9964; Grimme, S., Ehrlich, S., Goerigk, L., Effect of the damping function in dispersion corrected density functional theory (2011) J. Comput. Chem., 32, pp. 1456-1465; Grimme, S., Antony, J., Ehrlich, S., Krieg, H., A consistent and accurate ab initio parametrization of density functional dispersion correction (DFT-D) for the 94 elements H-Pu (2010) J. Chem. Phys., 132, p. 154104; Hare, S.R., Li, A., Tantillo, D.J., Post-transition state bifurcations induce dynamical detours in Pummerer-like reactions (2018) Chem. Sci., 9, pp. 8937-8945; Sinnokrot, M.O., Valeev, E.F., Sherrill, C.D., Estimates of the ab initio limit for π-π interactions: the benzene dimer (2002) J. Am. Chem. Soc., 124, pp. 10887-10893; Sherrill, C.D., Computations of noncovalent π interactions (2009) Reviews in Computational, pp. 1-38. , K.B. Lipkowitz T.R. Cundari Wiley; Ye, X., Li, Z.H., Wang, W., Fan, K., Xu, W., Hua, Z., The parallel π-π stacking: a model study with MP2 and DFT methods (2004) Chem. Phys. Lett., 397, pp. 56-61; Wang, W., Zhang, Y., Wang, Y.B., The π···π Stacking interactions between homogeneous dimers of C6F(x)I((6-x)) (x = 0, 1, 2, 3, 4, and 5): a comparative study with the halogen bond (2012) J. Phys. Chem. A, 116, pp. 12486-12491; Huber, S.M., Jimenez-Izal, E., Ugalde, J.M., Infante, I., Unexpected trends in halogen-bond based noncovalent adducts (2012) Chem. Commun. (Camb), 48, pp. 7708-7710; Jungbauer, S.H., Walter, S.M., Schindler, S., Rout, L., Kniep, F., Huber, S.M., Activation of a carbonyl compound by halogen bonding (2014) Chem. Commun. (Camb)., 50, pp. 6281-6284; Kee, C.W., Wong, M.W., In silico design of halogen-bonding-based organocatalyst for Diels-Alder reaction, Claisen rearrangement, and cope-type hydroamination (2016) J. Org. Chem., 81, pp. 7459-7470; Gliese, J.P., Jungbauer, S.H., Huber, S.M., A halogen-bonding-catalyzed Michael addition reaction (2017) Chem. Commun. (Camb)., 53, pp. 12052-12055; Neese, F., The ORCA program system (2012) WIREs Comput. Mol. Sci., 2, pp. 73-78; Neese, F., Software update: the ORCA program system, version 4.0 (2018) WIREs Comput. Mol. Sci., 8, p. e1327; Zhao, Y., Truhlar, D.G., The M06 suite of density functionals for main group thermochemistry, thermochemical kinetics, noncovalent interactions, excited states, and transition elements: two new functionals and systematic testing of four M06-class functionals and 12 other functionals (2008) Theor. Chem. Acc., 120, pp. 215-241; Goerigk, L., Hansen, A., Bauer, C., Ehrlich, S., Najibi, A., Grimme, S., A look at the density functional theory zoo with the advanced GMTKN55 database for general main group thermochemistry, kinetics and noncovalent interactions (2017) Phys. Chem. Chem. Phys., 19, pp. 32184-32215; Wheeler, S.E., Houk, K.N., Integration grid errors for meta-gga-predicted reaction energies: origin of grid errors for the M06 suite of functionals (2010) J. Chem. Theor. Comput., 6, pp. 395-404; Mardirossian, N., Head-Gordon, M., How accurate are the Minnesota density functionals for noncovalent interactions, isomerization energies, thermochemistry, and barrier heights involving molecules composed of main-group elements? (2016) J. Chem. Theor. Comput., 12, pp. 4303-4325; Smidstrup, S., Pedersen, A., Stokbro, K., Jónsson, H., Improved initial guess for minimum energy path calculations (2014) J. Chem. Phys., 140, p. 214106; Kingma, D.P., Ba, J., Adam: a method for stochastic optimization (2014) arXiv, , arXiv:1412.6980; Hase, W., Duchovic, R., Hu, X., Komornicki, A., Lim, K., Lu, D.-H., Peslherbe, G., Varandas, A., VENUS96: a general chemical dynamics computer program (1996) Quantum Chemical Program Exchange Bulletin, 16, p. 43; Safi, A., Nicolas, C., Neau, E., Chevalier, J., Diffusion coefficients of organic compounds at infinite dilution in mixtures involving associating compounds. Experimental determination and modeling by group contribution methods (2008) J. Chem. Eng. Data, 53, pp. 444-448},
correspondence_address1={Gómez-Bombarelli, R.; Department of Materials Science and Engineering, United States; email: rafagb@mit.edu},
publisher={Elsevier Inc.},
issn={24519308},
coden={CHEMV},
language={English},
abbrev_source_title={Chem},
document_type={Article},
source={Scopus},
}

@ARTICLE{Vununu20211,
author={Vununu, C. and Lee, S.-H. and Kwon, K.-R.},
title={A classification method for the cellular images based on active learning and cross-modal transfer learning},
journal={Sensors},
year={2021},
volume={21},
number={4},
pages={1-24},
doi={10.3390/s21041469},
art_number={1469},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100941517&doi=10.3390%2fs21041469&partnerID=40&md5=e99162224c8ab13d94e67bb9643c8044},
affiliation={Department of IT Convergence and Application Engineering, Pukyong National University, Busan, 48513, South Korea; Department of Computer Engineering, Dong-A University, Busan, 49315, South Korea},
abstract={In computer-aided diagnosis (CAD) systems, the automatic classification of the different types of the human epithelial type 2 (HEp-2) cells represents one of the critical steps in the diagnosis procedure of autoimmune diseases. Most of the methods prefer to tackle this task using the supervised learning paradigm. However, the necessity of having thousands of manually annotated examples constitutes a serious concern for the state-of-the-art HEp-2 cells classification methods. We present in this work a method that uses active learning in order to minimize the necessity of annotating the majority of the examples in the dataset. For this purpose, we use cross-modal transfer learning coupled with parallel deep residual networks. First, the parallel networks, which take simultaneously different wavelet coefficients as inputs, are trained in a fully supervised way by using a very small and already annotated dataset. Then, the trained networks are utilized on the targeted dataset, which is quite larger compared to the first one, using active learning techniques in order to only select the images that really need to be annotated among all the examples. The obtained results show that active learning, when mixed with an efficient transfer learning technique, can allow one to achieve a quite pleasant discrimination performance with only a few annotated examples in hands. This will help in building CAD systems by simplifying the burdensome task of labeling images while maintaining a similar performance with the state-of-the-art methods. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
author_keywords={Active learning;  Computer-aided diagnosis;  Deep learning;  HEp-2 cell images classification;  Pattern recognition;  Transfer learning},
keywords={Image classification;  Learning systems;  Transfer learning, Autoimmune disease;  Automatic classification;  Classification methods;  Computer Aided Diagnosis(CAD);  Diagnosis procedure;  Different wavelets;  Learning techniques;  State-of-the-art methods, Computer aided diagnosis, autoimmune disease;  classification;  computer assisted diagnosis;  epithelium cell;  human;  problem based learning, Autoimmune Diseases;  Deep Learning;  Diagnosis, Computer-Assisted;  Epithelial Cells;  Humans;  Neural Networks, Computer;  Problem-Based Learning},
funding_details={Ministry of Trade, Industry and EnergyMinistry of Trade, Industry and Energy, MOTIE},
funding_details={National Research Foundation of KoreaNational Research Foundation of Korea, NRF},
funding_details={Kementerian Pendidikan MalaysiaKementerian Pendidikan Malaysia, KPM, 2020R1I1A306659411, R1F1A1069124},
funding_text 1={Acknowledgments: This research was supported by the Basic Science Research Program through the National Research Foundation of Korea(NRF) funded by the Ministry of Education (2020R1I1A306659411,2020R1F1A1069124), and Ministry of Trade, Industry and Energy for its financial support of the project titled “the establishment of advanced marine industry open laboratory and development of realistic convergence content”.},
references={Rigon, A., Soda, P., Zennaro, D., Iannello, G., Afeltra, A., Indirect immunofluorescence in autoimmune diseases: Assessment of digital images for diagnostic purpose (2007) Cytom. B Clin. Cytom, 72, pp. 472-477; Foggia, P., Percannella, G., Soda, P., Vento, M., Benchmarking HEp-2 cells classification methods (2013) IEEE Trans. Med. Imaging, 32, pp. 1878-1889; Foggia, P., Percannella, G., Saggese, A., Vento, M., Pattern recognition in stained HEp-2 cells: Where are we now? (2014) Pattern Recog-nit, 47, pp. 2305-2314; Cataldo, S.D., Bottino, A., Ficarra, E., Macii, E., Applying textural features to the classification of HEp-2 cell patterns in IIF images Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012), pp. 689-694. , Tsukuba, Japan, 11–15 November 2012; Wiliem, A., Wong, Y., Sanderson, C., Hobson, P., Chen, S., Lovell, B.C., Classification of human epithelial type 2 cell indirect immunofluorescence images via codebook based descriptors Proceedings of the 2013 IEEE Workshop on Applications of Computer Vision (WACV), pp. 95-102. , Tampa, FL, USA, 15–17 January 2013; Stoklasa, R., Majtner, T., Svoboda, D., Efficient k-NN based HEp-2 cells classifier (2014) Pattern Recognit, 47, pp. 249-2418; Nosaka, R., Fukui, K., HEp-2 cell classification using rotation invariant co-occurrence among local binary patterns (2014) Pattern Recog-nit, 47, pp. 2428-2436; Cataldo, S.D., Bottino, A., Islam, I.U., Vieira, T.F., Ficarra, E., Subclass discriminant analysis of morphological and textural features for HEp-2 staining pattern classification (2014) Pattern Recognit, 47, pp. 2389-2399; Theodorakopoulos, I., Kastaniotis, D., Economou, G., Fotopoulos, S., HEp-2cells classification via sparse representation of textural features fused into dissimilarity space (2014) Pattern Recognit, 47, pp. 2367-2378; Huang, Y.C., Hsieh, T.Y., Chang, C.Y., Cheng, W.T., Lin, Y.C., Huang, Y.L., HEp-2 cell images classification based on textural and statistic features using self-organizing map Proceedings of the 4th Asian Conference on Intelligent Information and Database Systems, Part II, pp. 529-538. , Kaohsiung, Taiwan, 19–21 March 2012; Thibault, G., Angulo, J., Meyer, F., Advanced statistical matrices for texture characterization: Application to cell classification (2014) IEEE Trans. Biomed. Eng, 61, pp. 630-637; Wiliem, A., Sanderson, C., Wong, Y., Hobson, P., Minchin, R.F., Lovell, B.C., Automatic classification of human epithelial type 2 cell indirect immunofluorescence images using cell pyramid matching (2014) Pattern Recognit, 47, pp. 2315-2324; Xu, X., Lin, F., Ng, C., Leong, K.P., Automated classification for HEp-2 cells based on linear local distance coding framework (2015) J. Image Video Proc, 2015, pp. 1-13; Ponomarev, G.V., Arlazarov, V.L., Gelfand, M.S., Kazanov, M.D., ANA HEp-2 cells image classification using number, size, shape and localization of targeted cell regions (2014) Pattern Recognit, 47, pp. 2360-2366; Shen, L., Lin, J., Wu, S., Yu, S., HEp-2 image classification using intensity order pooling based features and bag of words (2014) Pattern Recognit, 47, pp. 2419-2427; Gao, Z., Wang, L., Zhou, L., Zhang, J., HEp-2 cell image classification with deep convolutional neural networks (2017) IEEE J. Biomed. Health Inf, 21, pp. 416-428; Bayramoglu, N., Kannala, J., Heikkilä, J., Human epithelial type 2 cell classification with convolutional neural networks Proceedings of the IEEE 15th International Conference on Bioinformatics and Bioengineering (BIBE), pp. 1-6. , Belgrade, Serbia, 2–4 November 2015; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., Caffe: Convolutional architecture for fast feature embedding Proceedings of the 22nd ACM International Conference on Multimedia, pp. 675-678. , Orlando, FL, USA, 3–7 November 2014; Liu, J., Xu, B., Shen, L., Garibaldi, J., Qiu, G., HEp-2 cell classification based on a deep autoencoding-classification convolutional neural network Proceedings of the 14th IEEE International Symposium on Biomedical Imaging (ISBI 2017), pp. 1019-1023. , Melbourne, Aus-tralia, 18–21 April 2017; Rodrigues, L.F., Naldi, M.C., Mari, J.F., Comparing convolutional neural networks and preprocessing techniques for HEp-2 cell classification in immunofluorescence images (2020) Comput. Biol. Med, 116, p. 103542; Xi, J., Linlin, S., Xiande, Z., Shiqi, Y., Deep convolutional neural network based HEp-2 cell classification Proceedings of the 2016 23rd International Conference on Pattern Recognition (ICPR), pp. 77-80. , Cancun, Mexico, 4–8 December 2016; Li, Y., Shen, L., A deep residual inception network for HEp-2 cell classification (2017) Proceedings of 3rd International Workshop, DLMIA 2017, and 7th International Workshop, ML-CDS 2017, , Québec City, QC, Canada, 14 September; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition Proceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , Las Vegas, NV, USA, 27–30 June 2016; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Going deeper with convolutions Proceedings of the 2015 IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9. , Boston, MA, USA, 7–12 June 2015; Shen, L., Jia, X., Li, Y., Deep cross residual network for HEp-2 cell staining pattern classification (2018) Pattern Recognit, 82, pp. 68-78; Majtner, T., Bajic, B., Lindblad, J., Sladoje, N., Blanes-Vidal, V., Nadimi, E.S., On the effectiveness of generative adversarial networks as HEp-2 image augmentation tool (2019) Proceedings of the Scandinavian Conference on Image Analysis (SCIA 2019), pp. 439-451. , https://link.springer.com/chapter/10.1007%2F978-3-030-20205-7_36, Norrkoping, Sweden, 11–13 June (accessed on 16 January 2021); Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets Proceedings of the 27th International Conference on Neural Information Processing Systems (NIPS 2014), pp. 2672-2680. , https://arxiv.org/pdf/1406.2661.pdf, Montréal, QC, Canada, 8–13 December 2014; (accessed on 16 January 2021); Radford, A., Metz, L., Chintala, S., Unsupervised representation learning with deep convolutional generative adversarial net-works (2016) Proceedings of the 4th International Conference on Learning Representations (ICLR 2016), , https://arxiv.org/pdf/1511.06434.pdf, San Juan, Puerto Rico, 2 4 May (accessed on 16 January 2021); Li, Y., Shen, L., HEp-Net: A smaller and better deep-learning network for HEp-2 cell classification (2019) Comput. Methods Biomech. Biomed. Eng, 7, pp. 266-272; Vununu, C., Lee, S.-K., Kwon, K.-R., A Deep feature extraction method for HEp-2 image classification (2018) Electronics, 8; Vununu, C., Lee, S.-K., Kwon, K.-R., A strictly unsupervised deep learning method for HEp-2 cell image classification (2020) Sensors, 20, p. 2717; Phan, H.T.H., Kumar, A., Kim, J., Feng, D., Transfer learning of a convolutional neural network for HEp-2 cell image classifica-tion (2016) Proceedings of the 2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI), pp. 1208-1211. , Prague, Czech Republic, 16 June; Simonyan, K., Zisserman, A., A very deep convolutional networks for large-scale image recognition (2015) Proceedings of the 2015 International Conference on Learning Representation (ICLR15), , https://arxiv.org/pdf/1409.1556.pdf, San Diego, CA, USA, 7–9 May (accessed on 16 January 2021); Lu, M., Gao, L., Guo, X., Liu, Q., Yin, J., HEp-2 cell image classification method based on very deep convolutional networks with small datasets (2017) Proceedings of the 9th International Conference on Digital Image Processing (ICDIP 2017), , Hong Kong, China, 19–22 May; Nguyen, L.D., Gao, R., Lin, D., Lin, Z., Biomedical image classification based on a feature concatenation and ensemble of deep CNNs (2019) J. Ambient Intell. Hum. Comput; Cascio, D., Taormina, V., Raso, G., Deep CNN for IIF images classification in autoimmune diagnostics (2019) Appl. Sci, 9, p. 1618; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Proceedings of the 25th International Conference on Neural Information Processing Systems (NIPS’12), pp. 1097-1105. , Lake Tahoe, NV, USA, 3–6 December; Lei, H., Han, T., Zhou, F., Yu, Z., Qin, J., Elazab, A., Lei, B., A deeply supervised residual network for HEp-2 cell classification via cross-modal transfer learning (2018) Pattern Recognit, 79, pp. 290-302; Lovell, B.C., Percannella, G., Saggese, A., Vento, M., Wiliem, A., International contest on pattern recognition techniques for indirect immunofluorescence images analysis Proceedings of the 2016 23rd International Conference on Pattern Recognition (ICPR), pp. 74-76. , Cancun, Mexico, 4–8 December 2016; Lewis, D.D., Catlett, J., Heterogeneous uncertainty sampling for supervised learning (1994) Proceedings of the Eleventh International Conference on Machine Learning, pp. 148-156. , New Brunswick, NJ, USA, 10–13 July; Seung, H.S., Opper, M., Sompolinsky, H., Query by committee (1992) Proceedings of the Fifth Annual Workshop on Computational Learning Theory, pp. 287-294. , Pittsburgh, PA, USA, 27–29 July; Shi, F., Wang, Z., Hu, M., Zhai, G., Active learning plus deep learning can establish cost-effective and robust model for multi-channel image: A case of hyperspectral image classification (2020) Sensors, 20, p. 4975; Wang, D., Shang, Y., A new active labeling method for deep learning Proceedings of the 2014 International Joint Conference on Neural Networks (IJCNN), pp. 112-119. , Beijing, China, 6–11 July 2014; Zhou, Z., Shin, J., Zhang, L., Gurudu, S., Gotway, M., Liang, J., Fine-tuning convolutional neural networks for biomedical image analysis: Actively and incrementally Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7340-7351. , Honolulu, HI, USA, 21–26 July 2017; Sener, O., Savarese, S., Active learning for convolutional neural networks: A core-set approach (2018) Proceedings of the International Conference on Learning Representations, , https://arxiv.org/pdf/1708.00489.pdf, Vancouver, BC, Canada, 30 April–3 May (accessed on 16 January 2021); Tkachenko, R., Izonin, I., Model and principals for the implementation of neural-like structures based on geometric data trans-formations (2019) Adv. Intell. Syst. Comput, 754, pp. 578-587; Cascio, D., Taormina, V., Raso, G., Deep convolutional neural network for HEp-2 fluorescence intensity classification (2019) Appl. Sci, 9, p. 408; Merone, M., Sansone, C., Soda, P., A computer-aided diagnosis system for HEp-2 fluorescence intensity classification (2019) Artif. Intell. Med, 97, pp. 71-78; Nigam, I., Agrawal, S., Singh, R., Vatsa, M., Revisiting HEp-2 cell classification (2015) IEEE Access, 3, pp. 3102-3113; Vununu, C., Lee, S.-K., Kwon, O.-J., Kwon, K.-R., A dynamic learning method for the classification of the HEp-2 cell images (2019) Electronics, 8, p. 850; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift Proceedings of the 32nd International Conference on Machine Learning, pp. 448-456. , Lille, France, 7–9 July 2015; Bengio, Y., Learning deep architecture for AI (2009) Foundat. Trends Mach. Learn, 2, pp. 1-127; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning representations by back-propagating errors (1986) Nature, 323, pp. 533-536; Shannon, C.E., A mathematical theory of communication (2001) ACM Sigmob. Mob. Comput. Commun. Rev, 5, pp. 3-55; Lewis, D.D., Gale, W.A., A sequential algorithm for training text classifiers (1994) Proceedings of the 17th ACM International Conference on Research and Development in Information Retrieval, pp. 3-12. , Dublin, Ireland, 3–6 July; Scheffer, T., Decomain, C., Wrobel, S., Active hidden markov models for information extraction (2001) International Symposium on Intelligent Data Analysis, pp. 309-318. , Springer: Berlin/Heidelberg, Germany; Tong, S., Koller, D., Support vector machine active learning with applications to text classification (2001) J. Mach. Learn. Res, 2, pp. 45-66; Abe, N., Mamitsuka, H., Query learning strategies using boosting and bagging Proceedings of the Fifteenth International Conference on Machine Learning (ICML 1998), pp. 1-8. , Madison, WI, USA, 24–27 July 1998; Huo, L.Z., Tang, P., A batch-mode active learning algorithm using region-partitioning diversity for SVM classifier (2014) IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens, 7, pp. 1036-1046; Qi, X., Zhao, G., Chen, J., Pietikainen, M., Exploring illumination robust descriptors for human epithelial type 2 cell classification (2016) Pattern Recognit, 60, pp. 420-429},
correspondence_address1={Kwon, K.-R.; Department of IT Convergence and Application Engineering, South Korea; email: krkwon@pknu.ac.kr},
publisher={MDPI AG},
issn={14248220},
pubmed_id={33672489},
language={English},
abbrev_source_title={Sensors},
document_type={Article},
source={Scopus},
}

@ARTICLE{Saboori2021356,
author={Saboori, A. and Ghassemian, H. and Razzazi, F.},
title={Active Multiple Kernel Fredholm Learning for Hyperspectral Images Classification},
journal={IEEE Geoscience and Remote Sensing Letters},
year={2021},
volume={18},
number={2},
pages={356-360},
doi={10.1109/LGRS.2020.2969970},
art_number={8995792},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091986835&doi=10.1109%2fLGRS.2020.2969970&partnerID=40&md5=3aecb05d3101dd66c530eb03fc7446a2},
affiliation={Department of Electrical and Computer Engineering, Science and Research Branch, Islamic Azad University, Tehran, Iran; Image Proc. and Information Analysis Laboratory at Faculty of Electrical and Computer Engineering, Tarbiat Modares University, Tehran, Iran},
abstract={Active learning (AL) represents an encouraging solution for hyperspectral image classification based on domain adaptation (DA) with very limited labeled samples in target domain. Although the traditional AL methods have exhibited the promising results in DA, some challenges still exist. On the one hand, the previous AL schemes assign a label to the most informative unlabeled data by user and, thus, are characterized by errors, time, and costs, which ignores dealing with noisy and complex data in target domain. On the other hand, the traditional AL methods based on kernel prediction model assume a predefined kernel and the identical distribution for source and target domains, which reduces the performance of classifier on target domain. To overcome these issues, we propose the Active Multiple Kernel Fredholm Learning (AMKFL), where a Fredholm kernel regularized model is presented to label the samples instead of the user, and then define two Fredholm integrals with multiple kernels to find an optimal kernel between different distributions, which increases the classification accuracy and generalization capabilities in noisy cases. The experimental results with two popular hyperspectral data sets show that the proposed AMKFL improves the classification accuracy significantly compared to the traditional methods while decreasing the user interaction. © 2004-2012 IEEE.},
author_keywords={Active learning (AL);  classification;  domain adaptation (DA);  Fredholm learning;  hyperspectral images (HSIs)},
keywords={Classification (of information);  Predictive analytics;  Spectroscopy, Classification accuracy;  Different distributions;  Fredholm integral;  Generalization capability;  Hyperspectral Data;  Images classification;  Kernel predictions;  Performance of classifier, Image classification, algorithm;  data set;  detection method;  image classification;  numerical model;  satellite imagery},
references={Tuia, D., Persello, C., Bruzzone, L., Domain adaptation for the classification of remote sensing data: An overview of recent advances (2016) Ieee Geosci. Remote Sens. Mag, 4 (2), pp. 41-57. , Jun; Patel, V.M., Gopalan, R., Li, R., Chellappa, R., Visual domain adaptation: A survey of recent advances (2015) Ieee Signal Process. Mag, 32 (3), pp. 53-69. , May; Tang, X., Jiao, L., Emery, W.J., SAR image content retrieval based on fuzzy similarity and relevance feedback (2017) Ieee J. Sel. Topics Appl. Earth Observ. Remote Sens, 10 (5), pp. 1824-1842. , May; Huang, L., Ma, Y., Liu, X., A general non-parametric active learning framework for classification on multiple manifolds Pattern Recognit. Lett, , to be published; Persello, C., Bruzzone, L., Active learning for domain adaptation in the supervised classification of remote sensing images (2012) Ieee Trans. Geosci. Remote Sens, 50 (11), pp. 4468-4483. , Nov; Matasci, G., Tuia, D., Kanevski, M., SVM-based boosting of active learning strategies for efficient domain adaptation (2012) Ieee J. Sel. Topics Appl. Earth Observ. Remote Sens, 5 (5), pp. 1335-1343. , Oct; Di, W., Crawford, M.M., Active learning via multi-view and local proximity co-regularization for hyperspectral image classification (2011) Ieee J. Sel. Topics Signal Process, 5 (3), pp. 618-628. , Jun; Que, Q., Belkin, M., Wang, Y., Learning with Fredholm kernels (2014) Proc. Adv. Neural Inf. Process. Syst, pp. 2951-2959; Wang, W., Wang, H., Zhang, Z., Zhang, C., Gao, Y., Semi-supervised domain adaptation via Fredholm integral based kernel methods (2019) Pattern Recognit, 85, pp. 185-197. , Jan; Deng, C., Liu, X., Li, C., Tao, D., Active multi-kernel domain adaptation for hyperspectral image classification (2018) Pattern Recognit, 77, pp. 306-315. , May; Borhani, M., Ghassemian, H., Kernel multivariate spectral-spatial analysis of HSI Data (2015) Ieee J. Sel. Topics Appl. Earth Observ. Remote Sens, 8 (6), pp. 2418-2426. , Jun; Deng, C., Xue, Y., Liu, X., Li, C., Tao, D., Active transfer learning network: A unified deep joint spectral-spatial feature learning model for hyperspectral image classification (2019) Ieee Trans. Geosci. Remote Sens, 57 (3), pp. 1741-1754. , Mar; Zehtabian, A., Ghassemian, H., Automatic object-based hyperspectral image classification using complex diffusions and a new distance metric (2016) Ieee Trans. Geosci. Remote Sens, 54 (7), pp. 4106-4114. , Jul; Zhang, X., Sun, Y., Jiang, K., Li, C., Jiao, L., Zhou, H., Spatial sequential recurrent neural network for hyperspectral image classification (2018) Ieee J. Sel. Topics Appl. Earth Observ. Remote Sens, 11 (11), pp. 4141-4155. , Nov; Liu, X., He, J., Lang, B., Multiple feature kernel hashing for largescale visual search (2014) Pattern Recognit, 47 (2), pp. 748-757. , Feb; Kianisarkaleh, A., Ghassemian, H., Nonparametric feature extraction for classification of hyperspectral images with limited training samples (2016) Isprs J. Photogram. Remote Sens, 119, pp. 64-78. , Sep; Tuia, D., Volpi, M., Copa, L., Kanevski, M., Munoz-Mari, J., A survey of active learning algorithms for supervised remote sensing image classification (2011) Ieee J. Sel. Topics Signal Process, 5 (3), pp. 606-617. , Jun; Sun, Z., Wang, C., Wang, H., Li, J., Learn multiple-kernel SVMs for domain adaptation in hyperspectral data (2013) Ieee Geosci. Remote Sens. Lett, 10 (5), pp. 1224-1228. , Sep},
correspondence_address1={Saboori, A.; Department of Electrical and Computer Engineering, Iran; email: arash.saboori@srbiau.ac.ir},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={1545598X},
language={English},
abbrev_source_title={IEEE Geosci. Remote Sens. Lett.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Li2021220,
author={Li, W. and Wu, Q. and Luo, H. and Zhang, G. and Peng, Z. and Chen, K.},
title={Research on Active Learning Method Based on Domain Adaptation and Collaborative Training},
journal={Lecture Notes in Electrical Engineering},
year={2021},
volume={653},
pages={220-227},
doi={10.1007/978-981-15-8599-9_27},
note={cited By 0; Conference of 2nd International Conference on Artificial Intelligence in China, ChinaAI 2020 ;  Conference Code:255399},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102516180&doi=10.1007%2f978-981-15-8599-9_27&partnerID=40&md5=559b32a38c483231c4bcc3d1b74c601b},
affiliation={State Grid East Inner Mongolia Electric Power Supply Co. Ltd, Hohhot, China; NARI Group Corporation Ltd, Nanjing, China; Wuhan NARI Limited Liability Company, State Grid Electric Power Research Institute, Wuhan, China},
abstract={In recent years, more and more deep learning technologies have been widely applied in various fields, such as intelligent medical, intelligent manufacturing, to realize the intelligence of various systems. In order to solve the problems of traditional manual inspection of power equipment, we propose a Convolutional Neural Network (CNN) has brought a revolutionary change to computer vision, but the ability of CNN to study relies heavily on the amount of labeled data. Currently, most of the labeled datasets are made up of natural images, which makes it a difficult problem to acquire labeled data in specific fields such as biomedical because of the high cost of human labeling. Active learning is an important method to solve this problem. This thesis is oriented to the problem of image classification and studies the current challenges and solutions of active learning. How to select the samples to be labeled so that the best neural network model can be learned at the minimum labeling cost is the core of the active learning algorithm. This thesis focuses on the selection strategy of the samples to be labeled, analyzes, and summarizes the advantages and disadvantages of current active learning methods, and designs a learning model. © 2021, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
author_keywords={Active learning;  Co-training;  Fine-tuning;  Sample diversity},
keywords={Convolutional neural networks;  Deep learning;  Engineering education;  Labeled data;  Learning systems, Active learning methods;  Active-learning algorithm;  Collaborative training;  Domain adaptation;  Intelligent Manufacturing;  Learning technology;  Neural network model;  Revolutionary changes, Learning algorithms},
funding_details={Science and Technology Project of State GridScience and Technology Project of State Grid},
funding_text 1={Acknowledgements. This work was funded by the State Grid Science and Technology Project (Research on Key Technologies of Intelligent Image Preprocessing and Visual Perception of Transmission and Transformation Equipment).},
references={Thompson, C.A., Califf, M.E., Mooney, R.J., (1999) Active Learning for Natural Language Parsing and Information Extraction[A]. ICML[C], pp. 406-414; Xu, Y., Zhang, H., Miller, K., Noise-tolerant interactive learning using pairwise comparisons[A] (2017) Adv Neural Inf Process Syst[C], pp. 2431-2440; Wang, Z., Du, B., Zhang, L., (2017) On Gleaning Knowledge from Multiple Domains for Active Learning [A]. IJCAI [C], pp. 3013-3019; Ma, F., Meng, D., Xie, Q., Self-paced co-training[A] (2017) Proceedings of the 34Th International Conference on Machine Learning, 70 (C), pp. 2275-2284. , , vol , . pp; Simonyan, K., (2014) Zisserman a (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition[J]. Arxiv Preprint Arxiv, 1409, p. 1556; He, K., Zhang, X., Ren, S., (2016) Deep Residual Learning for Image Recognition[A], pp. 770-778. , In: Proceedings of the IEEE conference on computer vision and pattern recognition[C]; Sinha, S., Ebrahimi, S., Darrell, T., (2019) Variational Adversarial Active Learning[A], pp. 5972-5981. , In: Proceedings of the IEEE international conference on computer vision[C]},
correspondence_address1={Wu, Q.; NARI Group Corporation LtdChina; email: 8278799@qq.com},
editor={Liang Q., Wang W., Mu J., Liu X., Na Z., Cai X.},
publisher={Springer Science and Business Media Deutschland GmbH},
issn={18761100},
isbn={9789811585982},
language={English},
abbrev_source_title={Lect. Notes Electr. Eng.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Hamrouni202176,
author={Hamrouni, Y. and Paillassa, E. and Chéret, V. and Monteil, C. and Sheeren, D.},
title={From local to global: A transfer learning-based approach for mapping poplar plantations at national scale using Sentinel-2},
journal={ISPRS Journal of Photogrammetry and Remote Sensing},
year={2021},
volume={171},
pages={76-100},
doi={10.1016/j.isprsjprs.2020.10.018},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096647580&doi=10.1016%2fj.isprsjprs.2020.10.018&partnerID=40&md5=b898132aa03519a239c3fbb2ef1f11c5},
affiliation={Université de Toulouse, INRAE, UMR DYNAFOR, Castanet-Tolosan, France; Conseil National du Peuplier, Paris, France; Centre National de la Propriété Forestière, Institut pour le Développement Forestier, Bordeaux, France},
abstract={Reliable estimates of poplar plantations area are not available at the French national scale due to the unsuitability and low update rate of existing forest databases for this short-rotation species. While supervised classification methods have been shown to be highly accurate in mapping forest cover from remotely sensed images, their performance depends to a great extent on the labelled samples used to build the models. In addition to their high acquisition cost, such samples are often scarce and not fully representative of the variability in class distributions. Consequently, when classification models are applied to large areas with high intra-class variance, they generally yield poor accuracies because of data shift issues. In this paper, we propose the use of active learning to efficiently adapt a classifier trained on a source image to spatially distinct target images with minimal labelling effort and without sacrificing the classification performance. The adaptation consists in actively adding to the initial local model new relevant training samples from other areas in a cascade that iteratively improves the generalisation capabilities of the classifier leading to a global model tailored to these different areas. This active selection relies on uncertainty sampling to directly focus on the most informative pixels for which the algorithm is the least certain of their class labels. Experiments conducted on Sentinel-2 time series revealed their high capacity to identify poplar plantations at a local scale with an average F-score ranging from 89.5% to 99.3%. For large area adaptation, the results showed that when the same number of training samples was used, active learning outperformed random sampling by up to 5% of the overall accuracy and up to 12% of the class F-score. Additionally, and depending on the class considered, the random sampling model required up to 50% more samples to achieve the same performance of an active learning-based model. Moreover, the results demonstrate the suitability of the derived global model to accurately map poplar plantations among other tree species with overall accuracy values up to 14% higher than those obtained with local models. The proposed approach paves the way for a national scale mapping in an operational context. © 2020 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)},
author_keywords={Active learning;  Domain adaptation;  Large areas;  Poplar plantations;  Sentinel-2;  Spatial transfer},
keywords={Classification (of information);  Forestry;  Iterative methods;  Sampling;  Transfer learning, Class distributions;  Classification models;  Classification performance;  Learning-based approach;  Reliable estimates;  Remotely sensed images;  Supervised classification;  Uncertainty samplings, Mapping, accuracy assessment;  algorithm;  data acquisition;  database;  deciduous tree;  forest cover;  machine learning;  mapping method;  numerical model;  plantation;  remote sensing;  scale effect;  Sentinel;  supervised classification, France, Populus},
funding_details={2017/0228},
funding_details={Association Nationale de la Recherche et de la TechnologieAssociation Nationale de la Recherche et de la Technologie, ANRT},
funding_details={Ministère de l'Education Nationale, de l'Enseignement Superieur et de la RechercheMinistère de l'Education Nationale, de l'Enseignement Superieur et de la Recherche, MESR},
funding_details={Ministère de l'Agriculture et de l'AlimentationMinistère de l'Agriculture et de l'Alimentation, BOP 149-26-12},
funding_text 1={Y.H. received a PhD scholarship from the French Ministry of Higher Education and Research (ANRT/CIFRE grant number 2017/0228 ). The project is spearheaded by the French National Poplar Council (CNP) and was supported by public funding from the French Ministry of Food and Agriculture (grant number BOP 149-26-12 ), the regions of Nouvelle Aquitaine and Grand Est and the County Council of Lot-et-Garonne. The project involved as well private funders, namely the Codifab (Professional Committee for the Development of French Furniture Industries) , France Bois Forêt , Alliance Forêts Bois and the company Garnica Plywood . The study has also received financial support from the French Space Agency CNES , as part of TOSCA Parcelle project.},
funding_text 2={Y.H. received a PhD scholarship from the French Ministry of Higher Education and Research (ANRT/CIFRE grant number 2017/0228). The project is spearheaded by the French National Poplar Council (CNP) and was supported by public funding from the French Ministry of Food and Agriculture (grant number BOP 149-26-12), the regions of Nouvelle Aquitaine and Grand Est and the County Council of Lot-et-Garonne. The project involved as well private funders, namely the Codifab (Professional Committee for the Development of French Furniture Industries), France Bois For?t, Alliance For?ts Bois and the company Garnica Plywood. The study has also received financial support from the French Space Agency CNES, as part of TOSCA Parcelle project. The authors would like to thank Johann H?bel? and Nicolas Vanderheeren for their technical expertise in poplar cultivation and for their field assistance.},
references={Alajlan, N., Pasolli, E., Melgani, F., Franzoso, A., Large-scale image classification using active learning (2014) IEEE Geosci. Remote Sens. Lett., 11 (1), pp. 259-263; Amor, I.B.S.B., Chehata, N., Bailly, J., Farah, I.R., Lagacherie, P., Parcel-based active learning for large extent cultivated area mapping (2018) IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens., 11 (1), pp. 79-88; Angluin, D., Queries and concept learning (1988) Mach. Learn., 2 (4), pp. 319-342; Belgiu, M., Drăguţ, L., Random forest in remote sensing: A review of applications and future directions (2016) ISPRS J. Photogramm. Remote Sens., 114, pp. 24-31; Borry, F.C., de Roover, B.P., Leysen, M.M., de Wulf, R.R., Goossens, R.E., Evaluation of SPOT and TM data for forest stratification: A case study for small-size poplar stands (1993) IEEE Trans. Geosci. Remote Sens., 31 (2), pp. 483-490; Breiman, L., Random forests (2001) Mach. Learn., 45 (1), pp. 5-32; Brinker, K., Incorporating diversity in active learning with support vector machines (2003) International Conference on Machine Learning, pp. 59-66. , AAAI Press Washington, DC, USA; Bruzzone, L., Cossu, R., A multiple-cascade-classifier system for a robust and partially unsupervised updating of land-cover maps (2002) IEEE Trans. Geosci. Remote Sens., 40 (9), pp. 1984-1996; Bruzzone, L., Prieto, D., Unsupervised retraining of a maximum likelihood classifier for the analysis of multitemporal remote sensing images (2001) IEEE Trans. Geosci. Remote Sens., 39 (2), pp. 456-460; Cao, X., Yao, J., Xu, Z., Meng, D., Hyperspectral image classification with convolutional neural network and active learning (2020) IEEE Trans. Geosci. Remote Sens., 58 (7), pp. 4604-4616; Chardenon, J., Flouzat, G., The application of remote sensing to poplar growing: identification and inventory of poplar groves, prediction of timber production; France, Italy (1981) Rev. For. Fr., 33 (6), pp. 478-493; Cheng, Y., Yu, L., Xu, Y., Liu, X., Lu, H., Cracknell, A.P., Kanniah, K., Gong, P., Towards global oil palm plantation mapping using remote-sensing data (2018) Int. J. Remote Sens., 39 (18), pp. 5891-5906; Cohn, D., Atlas, L., Ladner, R., Improving generalization with active learning (1994) Mach. Learn., 15 (2), pp. 201-221; Crawford, M.M., Tuia, D., Yang, H.L., Active learning: Any value for classification of remotely sensed data? (2013) Proc. IEEE, 101 (3), pp. 593-608; Danka, T., Horvath, P., ModAL: A modular active learning framework for Python (2018); Demir, B., Minello, L., Bruzzone, L., Definition of effective training sets for supervised classification of remote sensing images by a novel cost-sensitive active learning method (2014) IEEE Trans. Geosci. Remote Sens., 52 (2), pp. 1272-1284; Demir, B., Persello, C., Bruzzone, L., Batch-mode active-learning methods for the interactive classification of remote sensing images (2011) IEEE Trans. Geosci. Remote Sens., 49 (3), pp. 1014-1031; Descals, A., Szantoi, Z., Meijaard, E., Sutikno, H., Rindanata, G., Wich, S., Oil palm (elaeis guineensis) mapping with details: Smallholder versus industrial plantations and their extent in Riau, Sumatra (2019) Remote Sens., 11 (21), p. 2590; Di, W., Crawford, M.M., Critical class oriented active learning for hyperspectral image classification (2011) 2011 IEEE International Geoscience and Remote Sensing Symposium, pp. 3899-3902. , IEEE Vancouver, BC, Canada; Dong, J., Xiao, X., Sheldon, S., Biradar, C., Xie, G., Mapping tropical forests and rubber plantations in complex landscapes by integrating PALSAR and MODIS imagery (2012) ISPRS J. Photogramm. Remote Sens., 74, pp. 20-33; Duchaufour, P., Les sols à peupliers (1955) Rev. For. Fr., (7), p. 539; Eslami, A., Zahedi, S.S., Providing poplar plantation map by Indian remote sensing (IRS) satellite imagery in Northern Iran (2011) Afr. J. Agric. Res., 6 (20), pp. 4769-4774; Poplars, F.A.O., (2016), Other Fast-Growing Trees - Renewable Resources for Future Green Economies. Synthesis of Country Progress Reports. Berlin, Germany; Fischer, M., Zenone, T., Trnka, M., Orság, M., Montagnani, L., Ward, E.J., Tripathi, A.M., Ceulemans, R., Water requirements of short rotation poplar coppice: Experimental and modelling analyses across Europe (2018) Agricult. Forest Meteorol., 250-251, pp. 343-360; Foody, G.M., Explaining the unsuitability of the kappa coefficient in the assessment and comparison of the accuracy of thematic maps obtained by image classification (2020) Remote Sens. Environ., 239; Ghosh, A., Joshi, P.K., A comparison of selected classification algorithms for mapping bamboo patches in lower Gangetic plains using very high resolution WorldView 2 imagery (2014) Int. J. Appl. Earth Obs. Geoinf., 26, pp. 298-311; Gong, B., Grauman, K., Sha, F., Connecting the dots with landmarks: Discriminatively learning domain-invariant features for unsupervised domain adaptation (2013) International Conference on Machine Learning, pp. 222-230; Gong, Z., Zhong, P., Hu, W., Diversity in machine learning (2019) IEEE Access, 7, pp. 64323-64350; Grignetti, A., Coaloa, D., Niccolini, G., Classification of poplar stand areas by high-resolution satellite images (2009) For.@ - Riv. Selvic. Ecol. For., 6 (1), pp. 299-311; Hagolle, O., Huc, M., Villa Pascual, D., Dedieu, G., A multi-temporal and multi-spectral method to estimate aerosol optical thickness over land, for the atmospheric correction of FormoSat-2, LandSat, VENμS and Sentinel-2 images (2015) Remote Sens., 7 (3), pp. 2668-2691; Han, P., Chen, J., Han, Y., Yi, L., Zhang, Y., Jiang, X., Monitoring rubber plantation distribution on Hainan Island using Landsat OLI imagery (2018) Int. J. Remote Sens., 39 (8), pp. 2189-2206; Heyman, O., Gaston, G., Kimerling, A., Campbell, J., A per-segment approach to improving aspen mapping from high-resolution remote sensing imagery (2003) J. For., 101 (4), pp. 29-33; Hu, J., He, Z., Li, J., He, L., Wang, Y., 3D-gabor inspired multiview active learning for spectral-spatial hyperspectral image classification (2018) Remote Sens., 10 (7), p. 1070; Descriptif de Contenu BD Forêt® Version 2.0 (2014), IGN; Inglada, J., Otb Gapfilling, A Temporal Gapfilling For Image Time Series Library (2016), Zenodo; Inglada, J., Arias, M., Tardy, B., Hagolle, O., Valero, S., Morin, D., Dedieu, G., Koetz, B., Assessment of an operational system for crop type map production using high temporal and spatial resolution satellite optical imagery (2015) Remote Sens., 7 (9), pp. 12356-12379; Inglada, J., Vincent, A., Arias, M., Marais-Sicre, C., Improved early crop type identification by joint use of high temporal resolution SAR and optical image time series (2016) Remote Sens., 8 (5), p. 362; Isebrands, J.G., Richardson, J., (2013) Poplars and Willows: Trees for Society and the Environment, , FAO Rome; Joshi, A.J., Porikli, F., Papanikolopoulos, N., Multi-class active learning for image classification (2009) 2009 IEEE Conference on Computer Vision and Pattern Recognition, pp. 2372-2379; Julien, Y., Sobrino, J.A., Comparison of cloud-reconstruction methods for time series of composite NDVI data (2010) Remote Sens. Environ., 114 (3), pp. 618-625; Kandasamy, S., Baret, F., Verger, A., Neveux, P., Weiss, M., A comparison of methods for smoothing and gap filling time series of remote sensing observations – application to MODIS LAI products (2013) Biogeosciences, 10 (6), pp. 4055-4071; Karasiak, N., Dejoux, J.-F., Fauvel, M., Willm, J., Monteil, C., Sheeren, D., Statistical stability and spatial instability in mapping forest tree species by comparing 9 years of satellite image time series (2019) Remote Sens., 11 (21), p. 2512; Lambert, J., Drenou, C., Denux, J.-P., Balent, G., Cheret, V., Monitoring forest decline through remote sensing time series analysis (2013) GISci. Remote Sens., 50 (4), pp. 437-457; Lazecky, M., Lhota, S., Penaz, T., Klushina, D., Application of Sentinel-1 satellite to identify oil palm plantations in Balikpapan Bay (2018) IOP Conf. Ser.: Earth Environ. Sci., 169; Lewis, D.D., Gale, W.A., A sequential algorithm for training text classifiers (1994) SIGIR ’94, pp. 3-12. , Croft B.W. van Rijsbergen C.J. Springer London London; Li, Z., Fox, J.M., Integrating Mahalanobis typicalities with a neural network for rubber distribution mapping (2011) Remote Sens. Lett., 2 (2), pp. 157-166; Li, Z., Fox, J.M., Mapping rubber tree growth in mainland Southeast Asia using time-series MODIS 250 m NDVI and statistical data (2012) Appl. Geogr., 32 (2), pp. 420-432; Liu, P., Zhang, H., Eom, K., Active deep learning for classification of hyperspectral images (2017) IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens., 10 (2), pp. 712-724; Ma, L., Fu, T., Li, M., Active learning for object-based image classification using predefined training objects (2018) Int. J. Remote Sens., 39 (9), pp. 2746-2765; Malek, S., Miglietta, F., Gobakken, T., Næsset, E., Gianelle, D., Dalponte, M., Optimizing field data collection for individual tree attribute predictions using active learning methods (2019) Remote Sens., 11 (8), p. 949; Matasci, G., Volpi, M., Kanevski, M., Bruzzone, L., Tuia, D., Semisupervised transfer component analysis for domain adaptation in remote sensing image classification (2015) IEEE Trans. Geosci. Remote Sens., 53 (7), pp. 3550-3564; McCallum, A., Nigam, K., Employing EM and pool-based active learning for text classification (1998) Proceedings of the Fifteenth International Conference on Machine Learning, ICML ’98, pp. 350-358. , Morgan Kaufmann Publishers Inc. San Francisco, CA, USA; Mitra, P., Uma Shankar, B., Pal, S., Segmentation of multispectral remote sensing images using active support vector machines (2004) Pattern Recognit. Lett., 25 (9), pp. 1067-1074; Paillassa, É., Les peupleraies: Quels enjeux pour l'avenir de la populiculture Française? (2014) Rev. For. Fr., 66 (3), pp. 301-311; Pan, S.J., Yang, Q., A survey on transfer learning (2010) IEEE Trans. Knowl. Data Eng., 22 (10), pp. 1345-1359; Pasolli, E., Melgani, F., Tuia, D., Pacifici, F., Emery, W.J., SVM active learning approach for image classification using spatial information (2014) IEEE Trans. Geosci. Remote Sens., 52 (4), pp. 2217-2233; Pasolli, E., Yang, H.L., Crawford, M.M., Active-metric learning for classification of remotely sensed hyperspectral images (2016) IEEE Trans. Geosci. Remote Sens., 54 (4), pp. 1925-1939; Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Duchesnay, É., Scikit-learn: Machine learning in python (2011) J. Mach. Learn. Res., 12, pp. 2825-2830; Persello, C., Boularias, A., Dalponte, M., Gobakken, T., Næsset, E., Schölkopf, B., Cost-sensitive active learning with lookahead: Optimizing field surveys for remote sensing data classification (2014) IEEE Trans. Geosci. Remote Sens., 52 (10), pp. 6652-6664; Persello, C., Bruzzone, L., Active learning for domain adaptation in the supervised classification of remote sensing images (2012) IEEE Trans. Geosci. Remote Sens., 50 (11), pp. 4468-4483; Petitjean, F., Ketterlin, A., Gançarski, P., A global averaging method for dynamic time warping, with applications to clustering (2011) Pattern Recognit., 44 (3), pp. 678-693; Poortinga, A., Tenneson, K., Shapiro, A., Nquyen, Q., San Aung, K., Chishtie, F., Saah, D., Mapping plantations in Myanmar by fusing landsat-8, Sentinel-2 and Sentinel-1 data along with systematic error quantification (2019) Remote Sens., 11 (7), p. 831; Rajan, S., Ghosh, J., Crawford, M.M., An active learning approach to hyperspectral data classification (2008) IEEE Trans. Geosci. Remote Sens., 46 (4), pp. 1231-1242; Robert, A., Poplar plantations in France, at the heart of a conflict between provisioning services and cultural (dis)services (2018) Ecosystem Services in a Changing World: Moving from Theory to Practice, San Sebastián, Spain; Rosenqvist, A., Evaluation of JERS-1, ERS-1 and Almaz SAR backscatter for rubber and oil palm stands in West Malaysia (1996) Int. J. Remote Sens. - Int. J. Remote Sens., 17, pp. 3219-3231; Settles, B., Active learning (2012) Synth. Lect. Artif. Intell. Mach. Learn., 6 (1), pp. 1-114; Shannon, C.E., A mathematical theory of communication (1948) Bell Syst. Tech. J., 27 (3), pp. 379-423; Stumpf, A., Lachiche, N., Malet, J., Kerle, N., Puissant, A., Active learning in the spatial domain for remote sensing image classification (2014) IEEE Trans. Geosci. Remote Sens., 52 (5), pp. 2492-2507; Tuia, D., Pasolli, E., Emery, W.J., Using active learning to adapt remote sensing image classifiers (2011) Remote Sens. Environ., 115 (9), pp. 2232-2242; Tuia, D., Persello, C., Bruzzone, L., Domain adaptation for the classification of remote sensing data: An overview of recent advances (2016) IEEE Geosci. Remote Sens. Mag., 4 (2), pp. 41-57; Tuia, D., Ratle, F., Pacifici, F., Kanevski, M., Emery, W., Active learning methods for remote sensing image classification (2009) IEEE Trans. Geosci. Remote Sens., 47 (7), pp. 2218-2232; Tuia, D., Volpi, M., Copa, L., Kanevski, M., Munoz-Mari, J., A survey of active learning algorithms for supervised remote sensing image classification (2011) IEEE J. Sel. Top. Sign. Proces., 5 (3), pp. 606-617; Vlachos, A., A stopping criterion for active learning (2008) Comput. Speech Lang., 22 (3), pp. 295-312; Volpi, M., Tuia, D., Kanevski, M., Memory-based cluster sampling for remote sensing image classification (2012) IEEE Trans. Geosci. Remote Sens., 50 (8), pp. 3096-3106; Woodcock, C.E., Macomber, S.A., Pax-Lenney, M., Cohen, W.B., Monitoring large areas for forest change using Landsat: Generalization across space, time and Landsat sensors (2001) Remote Sens. Environ., 78 (1), pp. 194-203; Xiao, C., Li, P., Feng, Z., Monitoring annual dynamics of mature rubber plantations in Xishuangbanna during 1987-2018 using Landsat time series data: A multiple normalization approach (2019) Int. J. Appl. Earth Obs. Geoinf., 77, pp. 30-41; Ye, S., Rogan, J., Sangermano, F., Monitoring rubber plantation expansion using Landsat data time series and a Shapelet-based approach (2018) ISPRS J. Photogramm. Remote Sens., 136, pp. 134-143; Zhang, Z., Pasolli, E., Crawford, M., An adaptive multiview active learning approach for spectral–spatial classification of hyperspectral images (2020) IEEE Trans. Geosci. Remote Sens., 58 (4), pp. 2557-2570; Zhang, Z., Pasolli, E., Yang, H., Crawford, M., Multimetric active learning for classification of remote sensing data (2016) IEEE Geosci. Remote Sens. Lett., 13 (7), pp. 1007-1011; Zhong, P., Gong, Z., Li, S., Schönlieb, C.-B., Learning to diversify deep belief networks for hyperspectral image classification (2017) IEEE Trans. Geosci. Remote Sens., 55 (6), pp. 3516-3530},
correspondence_address1={Hamrouni, Y.; Université de Toulouse, France; email: yousra.hamrouni@inrae.fr},
publisher={Elsevier B.V.},
issn={09242716},
coden={IRSEE},
language={English},
abbrev_source_title={ISPRS J. Photogramm. Remote Sens.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Norouzzadeh2021150,
author={Norouzzadeh, M.S. and Morris, D. and Beery, S. and Joshi, N. and Jojic, N. and Clune, J.},
title={A deep active learning system for species identification and counting in camera trap images},
journal={Methods in Ecology and Evolution},
year={2021},
volume={12},
number={1},
pages={150-161},
doi={10.1111/2041-210X.13504},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096811722&doi=10.1111%2f2041-210X.13504&partnerID=40&md5=d140ebcdcd9b5fd304a393962dd2d104},
affiliation={Microsoft AI for Earth, Redmond, WA, United States; Computer Science Department, University of Wyoming, Laramie, WY, United States; Computer Science Department, California Institute of Technology, Pasadena, CA, United States; Microsoft Research, Redmond, WA, United States; OpenAI, San Francisco, CA, United States},
abstract={A typical camera trap survey may produce millions of images that require slow, expensive manual review. Consequently, critical conservation questions may be answered too slowly to support decision-making. Recent studies demonstrated the potential for computer vision to dramatically increase efficiency in image-based biodiversity surveys; however, the literature has focused on projects with a large set of labelled training images, and hence many projects with a smaller set of labelled images cannot benefit from existing machine learning techniques. Furthermore, even sizable projects have struggled to adopt computer vision methods because classification models overfit to specific image backgrounds (i.e. camera locations). In this paper, we combine the power of machine intelligence and human intelligence via a novel active learning system to minimize the manual work required to train a computer vision model. Furthermore, we utilize object detection models and transfer learning to prevent overfitting to camera locations. To our knowledge, this is the first work to apply an active learning approach to camera trap images. Our proposed scheme can match state-of-the-art accuracy on a 3.2 million image dataset with as few as 14,100 manual labels, which means decreasing manual labelling effort by over 99.5%. Our trained models are also less dependent on background pixels, since they operate only on cropped regions around animals. The proposed active deep learning scheme can significantly reduce the manual labour required to extract information from camera trap images. Automation of information extraction will not only benefit existing camera trap projects, but can also catalyse the deployment of larger camera trap arrays. © 2020 British Ecological Society},
author_keywords={active learning;  camera trap images;  computer vision;  deep learning;  deep neural networks},
references={(2018) Detection models, , https://github.com/Microsoft/CameraTraps, Retrieved from; Bahdanau, D., Chorowski, J., Serdyuk, D., Brakel, P., Bengio, Y., End-to-end attention-based large vocabulary speech recognition (2016) 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 4945-4949; Beery, S., Van Horn, G., Perona, P., Recognition in terra incognita (2018) Proceedings of the European Conference on Computer Vision; Burton, A.C., Neilson, E., Moreira, D., Ladle, A., Steenweg, R., Fisher, J.T., Bayne, E., Boutin, S., Wildlife camera trapping: A review and recommendations for linking surveys to ecological processes (2015) Journal of Applied Ecology, 520 (3), pp. 675-685; Caltech camera traps, , http://lila.science/datasets/caltech-camera-traps, Retrieved from; Cho, K., Van Merriënboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., Bengio, Y., Learning phrase representations using rnn encoder-decoder for statistical machine translation (2014) arXiv preprint; Dasgupta, S., Hsu, D., Hierarchical sampling for active learning (2008) Proceedings of the 25th international conference on Machine learning, pp. 208-215. , ACM; Elith, J., Kearney, M., Phillips, S., The art of modelling range-shifting species (2010) Methods in Ecology and Evolution, 1 (4), pp. 330-342. , https://doi.org/10.1111/j.2041-210X.2010.00036.x; eMammal project, , https://emammal.si.edu, Retrieved from; Forrester, T., McShea, W.J., Keys, R.W., Costello, R., Baker, M., Parsons, A., (2013) emammal: Citizen science camera trapping as a solution for broad-scale, long-term monitoring of wildlife populations, , Sustainable Pathways Learning from the Past and Shaping the Future; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep learning, , MIT Press; Guo, Y., Greiner, R., Optimistic active-learning using mutual information (2007) IJCAI, 7, pp. 823-829; Hagan, M.T., Demuth, H.B., Beale, M.H., De Jesús, O., (1996) Neural network design, 20. , Pws Publications; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778. , IEEE; Hecht-Nielsen, R., (1989) Theory of the backpropagation neural network, , International Joint Conference on Neural Networks (IJCNN); Hermans, A., Beyer, L., Leibe, B., In defense of the triplet loss for person re-identification (2017) arXiv preprint; Hinton, G., Deng, L., Yu, D., Dahl, G., Mohamed, A.-R., Jaitly, N., Senior, A., Kingsbury, B., Deep neural networks for acoustic modeling in speech recognition (2012) IEEE signal processing magazine, 26, pp. 82-97. , 6th ed., IEEE; Kingma, D.P., Ba, J., Adam: A method for stochastic optimization (2014) arXiv preprint; Koch, G., Zemel, R., Salakhutdinov, R., Siamese neural networks for one-shot image recognition (2015) ICML deep learning workshop, 2; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) 2012 Advances in Neural Information Processing Systems (NIPS); LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 5210 (7553), p. 436; Lewis, D.D., Gale, W.A., A sequential algorithm for training text classifiers (1994) SIGIR'94, pp. 3-12. , Springer; Martínez, A.M., Kak, A.C., Pca versus lda (2001) IEEE Transactions on Pattern Analysis and Machine Intelligence, 230 (2), p. 233. , 228–; Miao, Z., Gaynor, K.M., Wang, J., Liu, Z., Muellerklein, O., Norouzzadeh, M.S., McInturff, A., Getz, W.M., Insights and approaches using deep learning to classify wildlife (2019) Scientific Reports, 90 (1); Mohri, M., Rostamizadeh, A., Talwalkar, A., (2012) Foundations of machine learning, , (Eds.) (, MIT Press; North American camera trap images, , http://lila.science/datasets/nacti, Retrieved from; Norouzzadeh, M.S., (2020) norouzzadeh-et-al-mee-2020, , https://doi.org/10.5281/zenodo.4052020; Norouzzadeh, M.S., Nguyen, A., Kosmala, M., Swanson, A., Palmer, M.S., Packer, C., Clune, J., Automatically identifying, counting, and describing wild animals in camera-trap images with deep learning (2018) Proceedings of the National Academy of Sciences of the United States of America, 1150 (25), pp. E5716-E5725; O'Connell, A.F., Nichols, J.D., Karanth Ullas, K., (2010) Camera traps in animal ecology: Methods and analyses, , Springer Science & Business Media; Ren, S., He, K., Girshick, R., Sun, J., Faster r-cnn: towards real-time object detection with region proposal networks (2015) Advances in neural information processing systems, pp. 91-99; Robbins, H., Monro, S., A stochastic approximation method (1951) The Annals of Mathematical Statistics, 22, pp. 400-407; Schneider, S., Taylor, G.W., Kremer, S., Deep learning object detection methods for ecological camera trap data (2018) 2018 15th Conference on Computer and Robot Vision (CRV), pp. 321-328. , IEEE; Schroff, F., Kalenichenko, D., Philbin, J., Facenet: A unified embedding for face recognition and clustering (2015) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 815-823. , IEEE; Sener, O., Savarese, S., Active learning for convolutional neural networks: A core-set approach (2017) arXiv preprint; Settles, B., (2009) Active learning literature survey, , (Technical report)., Department of Computer Sciences, University of Wisconsin-Madison; Settles, B., Craven, M., An analysis of active learning strategies for sequence labeling tasks (2008) Proceedings of the conference on empirical methods in natural language processing, pp. 1070-1079. , Association for Computational Linguistics; Seung, H.S., Opper, M., Sompolinsky, H., Query by committee (1992) Proceedings of the fifth annual workshop on computational learning theory, pp. 287-294. , ACM; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014) arXiv preprint; Southwood, T.R.E., Henderson, P.A., (2009) Ecological methods, , John Wiley & Sons; Sutskever, I., Vinyals, O., Le, Q.V., Sequence to sequence learning with neural networks (2014) Advances in neural information processing systems, pp. 3104-3112; Swanson, A., Kosmala, M., Lintott, C., Simpson, R., Smith, A., Packer, C., Snapshot serengeti, high-frequency annotated camera trap images of 40 mammalian species in an african savanna (2015) Scientific Data, 2, p. 150026; Tabak, M.A., Norouzzadeh, M.S., Wolfson, D.W., Sweeney, S.J., VerCauteren, K.C., Snow, N.P., Halseth, J.M., Miller, R.S., Machine learning to classify animal species in camera trap images: Applications in ecology (2018) Methods in Ecology and Evolution, 10 (4), pp. 585-590; Tieleman, T., Hinton, G., Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude (2012) COURSERA: Neural Networks for Machine Learning, 40 (2), pp. 26-31; Tikhonov, G., Abrego, N., Dunson, D., Ovaskainen, O., Using joint species distribution models for evaluating how species-to-species associations depend on the environmental context (2017) Methods in Ecology and Evolution, 80 (4), pp. 443-452; van der Maaten, L., Hinton, G., Laurens van der Maaten and Geoffrey Hinton. Visualizing data using t-sne (2008) Journal of Machine Learning Research, 90, pp. 2579-2605; Xu, Z., Yu, K., Tresp, V., Xu, X., Wang, J., Representative sampling for text classification using support vector machines (2003) European conference on information retrieval, pp. 393-407. , Springer; Yosinski, J., Clune, J., Bengio, Y., Lipson, H., How transferable are features in deep neural networks? (2014) 2014 Advances in Neural Information Processing Systems (NIPS)},
correspondence_address1={Morris, D.; Microsoft AI for EarthUnited States; email: dan@microsoft.com},
publisher={British Ecological Society},
issn={2041210X},
language={English},
abbrev_source_title={Methods Ecol. Evol.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Netzer20201191,
author={Netzer, E. and Geva, A.B.},
title={Human-in-the-loop active learning via brain computer interface},
journal={Annals of Mathematics and Artificial Intelligence},
year={2020},
volume={88},
number={11-12},
pages={1191-1205},
doi={10.1007/s10472-020-09689-0},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081966919&doi=10.1007%2fs10472-020-09689-0&partnerID=40&md5=94999ce1e111d1a9f10bcfbedd41867a},
affiliation={InnerEye Ltd and Department of Electrical and Computer Engineering, Ben-Gurion University, Beer Sheva, Israel},
abstract={This paper develops and examines an innovative methodology for training an artificial neural network to identify and tag target visual objects in a given database. While the field of Artificial Intelligence in general, and computer vision in particular, has greatly advanced in recent years, fast and efficient methods for tagging (i.e., labeling) visual targets are still lacking. Tagging data is important to train, as it allow to train supervised learning models. However, this is a tiresome task that often creates bottlenecks in academic and industrial research projects. In order to develop an algorithm that improves data tagging processes, this study utilizes the advantages of human cognition and machine learning by combining Brain Computer Interface, Human-In-The-Loop, and Deep Learning. Combining these three fields into one algorithm could enable the rapid annotation of large visual databases that have no prior references and cannot be described as a mathematical optimization function. Human-In-The-Loop is an increasingly researched area that refers to the integration of human feedback in computation processes. At present, computer-based deep learning can only be incorporated in the process of identifying and tagging target objects of interest if a predefined database exists – one that has already been defined by a human user. To reduce the scope of this timely and costly process, our algorithm uses machine learning techniques (i.e., active learning) to minimize the number of target objects a human user needs to identify before the computer can successfully carry out the task independently. In our method, users are connected to electroencephalograms electrodes and shown images using rapid serial visual presentation – a fast method for presenting users with images. Some images are target objects, while others are not. Based on users’ brainwave activity when target objects are shown, the computer learns to identify and tag target objects – already in the learning stage (unlike naïve uniform sampling methods that first require human input, and only then begin the learning stage). As such, our work is proof of concept for the effectiveness of involving humans in the computer’s learning stage, i.e., human-in-the-loop as opposed to the traditional method of humans first tagging the data and the machines then learning and creating a model. © 2020, Springer Nature Switzerland AG.},
author_keywords={Active Learning;  Brain Computer Interface;  Clustering;  Deep learning;  EEG;  Human-In-The-Loop;  Transfer Learning},
funding_details={Ben-Gurion University of the NegevBen-Gurion University of the Negev, BGU},
funding_text 1={We would like to thank the Israel Innovation Authority of the Ministry of Economy and Industry for supporting this study. We would also like to thank InnerEye Ltd. for funding and running the experiments and for providing the EEG classification system used in this study. Eitan Netzer’s work was supported by InnerEye Ltd., Ben Gurion University of the Negev, and the Israel Innovation Authority of the Ministry of Economy and Industry.},
references={Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Schirner, G., Erdogmus, D., Chowdhury, K., Padir, T., The future of human-in-the-loop cyber-physical systems (2013) Computer, 46 (1), pp. 36-45; (2012) Amazon mechanical turk, 17, p. 2012. , Retrieved August; Zhu, X., (2005) Semi-Supervised Learning Literature Survey; Gal, Y., Islam, R., Ghahramani, Z., (2017) Deep Bayesian Active Learning with Image Data; Alpert, G.F., Manor, R., Spanier, A.B., Deouell, L.Y., Geva, A.B., Spatiotemporal representations of rapid visual target detection: A single-trial EEG classification algorithm (2014) IEEE Transactions on Biomedical Engineering, 61 (8), pp. 2290-2303; Manor, R., Geva, A.B., Convolutional neural network for multi-category rapid serial visual presentation bci (2015) Frontiers in Computational Neuroscience, 9 (146); Sajda, P., Pohlmeyer, E., Wang, J., Parra, L.C., Christoforou, C., Dmochowski, J., Hanna, B., Chang, S.-F., In a blink of an eye and a switch of a transistor: Cortically coupled computer vision (2010) Proceedings of the IEEE, 98 (3), pp. 462-478; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) nature, 521 (7553), p. 436; Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., Riedmiller, M., (2013) Playing Atari with Deep Reinforcement Learning; Taigman, Y., Yang, M., Ranzato, M.A., Wolf, L., Deepface: closing the gap to human-level performance in face verification (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1701-1708; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning representations by back-propagating errors (1986) nature, 323 (6088), p. 533; Nguyen, A., Yosinski, J., Clune, J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436; Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K., Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition (2016) Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540. , ACM; Pohlmeyer, E.A., Jangraw, D.C., Wang, J., Chang, S.-F., Sajda, P., Combining computer and human vision into a bci: Can the whole be greater than the sum of its parts? (2010) Engineering in Medicine and Biology Society (EMBC), 2010 Annual International Conference of the IEEE, pp. 138-141. , IEEE; Gerson, A.D., Parra, L.C., Sajda, P., Cortically coupled computer vision for rapid image search (2006) IEEE Transactions on neural systems and rehabilitation engineering, 14 (2), pp. 174-179; Bengio, Y., Deep learning of representations for unsupervised and transfer learning (2012) Proceedings of ICML Workshop on Unsupervised and Transfer Learning, pp. 17-36; Fei-Fei, L., Knowledge transfer in learning to recognize visual objects classes (2006) Proceedings of the International Conference on Development and Learning (ICDL), p. page 11; Mesnil, G., Dauphin, Y., Glorot, X., Rifai, S., Bengio, Y., Goodfellow, I., Lavoie, E., Warde-Farley, D., Unsupervised and transfer learning challenge: A deep learning approach (2011) Proceedings of the 2011 International Conference on Unsupervised and Transfer Learning Workshop, 27, pp. 97-111. , JMLR. org; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., Imagenet large scale visual recognition challenge (2015) International Journal of Computer Vision, 115 (3), pp. 211-252; Daniel, C., Mahajan, M., Dale, J., Pepper, S., Lin, Y., Yoo, S., A transfer learning approach to parking lot classification in aerial imagery (2017) Scientific Data Summit (NYSDS), 2017 New York, pp. 1-5. , IEEE; Yosinski, J., Clune, J., Bengio, Y., Lipson, H., How transferable are features in deep neural networks? (2014) Advances in Neural Information Processing Systems, pp. 3320-3328; Bengio, Y., Learning deep architectures for ai (2009) Foundations and trends® in Machine Learning, 2 (1), pp. 1-127; Salvador, S., Chan, P., Determining the number of clusters/segments in hierarchical clustering/segmentation algorithms (2004) 16Th IEEE International Conference on Tools with Artificial Intelligence, , IEEE; Donchin, E., Ritter, W., McCallum, W.C., (1978) Cognitive Psychophysiology: The Endogenous Components of The Erp. Event-Related Brain Potentials in Man, pp. 349-411; Kutas, M., McCarthy, G., Donchin, E., Augmenting mental chronometry: the p300 as a measure of stimulus evaluation time (1977) Science, 197 (4305), pp. 792-795; Donchin, E., Coles, M.G.H., Is the p300 component a manifestation of context updating? (1988) Behavioral and brain sciences, 11 (3), pp. 357-374; Polich, J., Updating p300: an integrative theory of p3a and p3b (2007) Clin. Neurophysiol., 118 (10), pp. 2128-2148; Li, K., Sankar, R., Arbel, Y., Donchin, E., Single trial independent component analysis for p300 bci system (2009) Engineering in Medicine and Biology Society, 2009, pp. 4035-4038. , EMBC 2009. Annual International Conference of the IEEE, IEEE; Springenberg, J.T., Dosovitskiy, A., Brox, T., Riedmiller, M., (2014) Striving for Simplicity: The All Convolutional Net},
correspondence_address1={Netzer, E.; InnerEye Ltd and Department of Electrical and Computer Engineering, Israel; email: netzereitan@gmail.com},
publisher={Springer Science and Business Media Deutschland GmbH},
issn={10122443},
language={English},
abbrev_source_title={Ann. Math. Artif. Intell.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Li2020,
author={Li, F. and Zeng, M. and Xiao, J. and Li, X. and Li, Y. and Hu, G.},
title={Active learning for image preparation of automatic vending machine (AVM) employing transfer learning method},
journal={Journal of Physics: Conference Series},
year={2020},
volume={1684},
number={1},
doi={10.1088/1742-6596/1684/1/012114},
art_number={012114},
note={cited By 0; Conference of 2020 International Seminar on Artificial Intelligence, Networking and Information Technology, AINIT 2020 ; Conference Date: 18 September 2020 Through 20 September 2020;  Conference Code:165433},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097347789&doi=10.1088%2f1742-6596%2f1684%2f1%2f012114&partnerID=40&md5=c4cdb450a32e26ec248cfc88db950b86},
affiliation={Communications and Information Dept., Shanghai Technical Institute of Electronics and Information, Shanghai, China},
abstract={In this paper, we employed active learning methods to prepare annotated images for our training of automatic vending machine (AVM) system, in order to minimize human annotation cost. Due to the tiny data of our system, transfer learning approach is used by implementing the already trained Yolov3-tiny model for COCO dataset as our training start. Also, we evaluated the effectiveness of 3 annotation strategies: smallest annotation area (SAA), largest annotation area (LAA) and moderate annotation area (MAA), for photos of top views from above. The results show that the idea of employing active learning methods to prepare annotated data is feasible. Also, the annotation strategy of MAA demonstrates the superior performance, for its enough object area and the least background area. © Published under licence by IOP Publishing Ltd.},
keywords={Transfer learning;  Vending machines, Active Learning;  Active learning methods;  Human annotations;  Top views;  Transfer learning methods, Learning systems},
funding_details={Shanghai Municipal Education CommissionShanghai Municipal Education Commission, E-002-20-GQ0501-27},
funding_text 1={The paper is sponsored by Shanghai Municipal Education Commission, the funds No. is E-002-20-GQ0501-27.},
references={Kanagasabapathi, V., Naveenraj, K., Neelavarnan, V., Naveen Raj, S., (2019) 5th International Conference on Advanced Computing & Communication Systems (ICACCS) (Coimbatore,is India) Automatic chocolate vending machine, pp. 584-587. , 2019; Zhang, W., Zhang, X. L., (2010) 6th International Conference on Wireless Communications Networking and Mobile Computing (WiCOM) (Chengdu) Design and Implementation of Automatic Vending Machine Based on the Short Massage Payment, p. 1. , 2010 4; Azami, S. B. Z., Tanabian, M., Automatic mobile payment on a non-connected vending machine," (2004) Canadian Conference on Electrical and Computer Engineering 2004 (IEEE Cat. No.04CH37513), 2, pp. 731-734. , (Niagara Falls, Ontario, Canada); Deng, Y., A New Framework to Reduce Doctor's Workload for Medical Image Annotation in (2019) IEEE Access, 7, p. 107097; Wang, K., Zhang, D., Li, Y., Zhang, R., Lin, L., Cost-Effective Active Learning for Deep Image Classification (2017) IEEE Transactions on Circuits and Systems for Video Technology, 27, pp. 2591-2600. , Dec; Huang, Y., Liu, Z., Jiang, M., Yu, X., Ding, X., Cost-Effective Vehicle Type Recognition in Surveillance Images With Deep Active Learning and Web Data (2020) IEEE Transactions on Intelligent Transportation Systems, 21, pp. 79-86. , Jan; Wang, K., Zhang, D., Li, Y., Zhang, R., Lin, L., Cost-Effective Active Learning for Deep Image Classification (2017) IEEE Transactions on Circuits and Systems for Video Technology, 27, pp. 2591-2600. , Dec; Yan, Y., Nie, F., Li, W., Gao, C., Yang, Y., Xu, D., Image Classification by Cross-Media Active Learning With Privileged Information (2016) IEEE Transactions on Multimedia, 18, pp. 2494-2502. , Dec; Tuia, D., Ratle, F., Pacifici, F., Kanevski, M. F., Emery, W. J., Correction to 'active learning methods for remote sensing image classification (2010) IEEE Trans. Geosci. Remote Sens, 48, p. 2767. , Jun; Hakkani-Tur, D., Tur, G., Rahim, M., Riccardi, G., (2004) 2004 IEEE International Conference on Acoustics, Speech, and Signal Processing, , (Montreal, Que) Unsupervised and active learning in automatic speech recognition for call classification I-429; Cai, D., He, X., Manifold Adaptive Experimental Design for Text Categorization in (2012) IEEE Transactions on Knowledge and Data Engineering, 24, pp. 707-719. , April; Demir, B., Bruzzone, L., A Novel Active Learning Method in Relevance Feedback for Content-Based Remote Sensing Image Retrieval in (2015) IEEE Transactions on Geoscience and Remote Sensing, 53, pp. 2323-2334. , May; Hoi, S. C. H., Rong, Jin, Jianke, Zhu, Lyu, M. R., (2008) 2008 IEEE Conference on Computer Vision and Pattern Recognition (Anchorage, AK) Semi-supervised SVM batch mode active learning for image retrieval, pp. 1-7; Zhang, B., Wang, Y., Chen, F., Multilabel Image Classification Via High-Order Label Correlation Driven Active Learning in (2014) IEEE Transactions on Image Processing, 23, pp. 1430-1441. , March; Vijayanarasimhan, S., Grauman, K., (2011) CVPR 2011, Providence (RI) Large-scale live active learning: Training object detectors with crawled data and crowds, pp. 1449-1456; Pan, S. J., Yang, Q., A Survey on Transfer Learning (2010) IEEE Transactions on Knowledge an d Data Engineering, 22, pp. 1345-1359. , Oct; Shao, L., Zhu, F., Li, X., Transfer Learning for Visual Categorization: A Survey in (2015) IEEE Transactions on Neural Networks and Learning Systems, 26, pp. 1019-1034. , May; Wang, H., Feiping, Nie, Huang, H., Ding, C., (2011) 2011 International Conference on Computer Vision (Barcelona) Dyadic transfer learning for cross-domain image classification, pp. 551-556; Pan, S. J., Kwok, J. T., Yang, Q., Transfer learning via dimensionality reduction (2008) Proc. 23rd Nat. Conf. Artif. Intell. (AAAI), pp. 677-682. , Jul},
publisher={IOP Publishing Ltd},
issn={17426588},
language={English},
abbrev_source_title={J. Phys. Conf. Ser.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Chen20202147,
author={Chen, L. and Canton, G. and Liu, W. and Hippe, D.S. and Balu, N. and Watase, H. and Hatsukami, T.S. and Waterton, J.C. and Hwang, J.-N. and Yuan, C.},
title={Fully automated and robust analysis technique for popliteal artery vessel wall evaluation (FRAPPE) using neural network models from standardized knee MRI},
journal={Magnetic Resonance in Medicine},
year={2020},
volume={84},
number={4},
pages={2147-2160},
doi={10.1002/mrm.28237},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081752743&doi=10.1002%2fmrm.28237&partnerID=40&md5=3f88a5d26a8cce29824f1f341b86cf15},
affiliation={Department of Electrical and Computer Engineering, University of Washington, Seattle, WA, United States; Department of Radiology, University of Washington, Seattle, WA, United States; Department of Surgery, University of Washington, Seattle, WA, United States; Centre for Imaging Sciences, Manchester Academic Health Science Centre, The University of Manchester, Manchester, United Kingdom},
abstract={Purpose: To develop a fully automated vessel wall (VW) analysis workflow (fully automated and robust analysis technique for popliteal artery evaluation, FRAPPE) on the popliteal artery in standardized knee MR images. Methods: Popliteal artery locations were detected from each MR slice by a deep neural network model and connected into a 3D artery centerline. Vessel wall regions around the centerline were then segmented using another neural network model for segmentation in polar coordinate system. Contours from vessel wall segmentations were used for vascular feature calculation, such as mean wall thickness and wall area. A transfer learning and active learning framework was applied in training the localization and segmentation neural network models to maintain accuracy while reducing manual annotations. This new popliteal artery analysis technique (FRAPPE) was validated against manual segmentation qualitatively and quantitatively in a series of 225 cases from the Osteoarthritis Initiative (OAI) dataset. Results: FRAPPE demonstrated high accuracy and robustness in locating popliteal arteries, segmenting artery walls, and quantifying arterial features. Qualitative evaluations showed 1.2% of slices had noticeable major errors, including segmenting the wrong target and irregular vessel wall contours. The mean Dice similarity coefficient with manual segmentation was 0.79, which is comparable to inter-rater variations. Repeatability evaluations show most of the vascular features have good to excellent repeatability from repeated scans of same subjects, with intra-class coefficient ranging from 0.80 to 0.98. Conclusion: This technique can be used in large population-based studies, such as OAI, to efficiently assess the burden of atherosclerosis from routine MR knee scans. © 2020 International Society for Magnetic Resonance in Medicine},
author_keywords={atherosclerosis;  machine learning;  popliteal artery;  vessel wall imaging;  vessel wall segmentation},
keywords={Automation;  Deep learning;  Deep neural networks;  Magnetic resonance imaging;  Transfer learning, Analysis techniques;  Intra-class coefficient;  Manual segmentation;  Mean wall thickness;  Neural network model;  Polar coordinate systems;  Qualitative evaluations;  Similarity coefficients, Neural networks, arterial wall thickness;  Article;  atherosclerosis;  convolutional neural network;  deep neural network;  fully automated and robust analysis technique for popliteal artery evaluation;  human;  image analysis;  image segmentation;  machine learning;  measurement repeatability;  nuclear magnetic resonance imaging;  popliteal artery},
funding_details={National Institutes of HealthNational Institutes of Health, NIH, R01-HL103609},
funding_details={U.S. Department of Health and Human ServicesU.S. Department of Health and Human Services, HHS},
funding_details={American Heart AssociationAmerican Heart Association, AHA, 18AIML34280043},
funding_details={PfizerPfizer},
funding_details={GlaxoSmithKlineGlaxoSmithKline, GSK},
funding_details={MerckMerck},
funding_details={NvidiaNvidia, N01‐AR‐2‐2261, N01‐AR‐2‐2262},
funding_details={Novartis Pharmaceuticals CorporationNovartis Pharmaceuticals Corporation, NPC},
funding_text 1={This research is supported by grants from American Heart Association (18AIML34280043), National Institute of Health (R01-HL103609) and Philips Healthcare. We gratefully acknowledge the support of NVIDIA Corporation for donating the Titan GPU. The Osteoarthritis Initiative (OAI) is a public-private partnership comprised of 5 contracts (N01-AR-2-2258; N01-AR-2-2259; N01-AR-2-2260; N01-AR-2-2261; and N01-AR-2-2262) funded by the National Institutes of Health (NIH), a branch of the Department of Health and Human Services, and conducted by the OAI Study Investigators. Private funding partners include Merck Research Laboratories; Novartis Pharmaceuticals Corporation, GlaxoSmithKline; and Pfizer, Inc. Private sector funding for the OAI is managed by the Foundation for the NIH. This article was prepared using an OAI public use dataset and does not necessarily reflect the opinions or views of the OAI investigators, the NIH, or the private funding partners.},
funding_text 2={We gratefully acknowledge the support of NVIDIA Corporation for donating the Titan GPU. The Osteoarthritis Initiative (OAI) is a public‐private partnership comprised of 5 contracts (N01‐AR‐2‐2258; N01‐AR‐2‐2259; N01‐AR‐2‐2260; N01‐AR‐2‐2261; and N01‐AR‐2‐2262) funded by the National Institutes of Health (NIH), a branch of the Department of Health and Human Services, and conducted by the OAI Study Investigators. Private funding partners include Merck Research Laboratories; Novartis Pharmaceuticals Corporation, GlaxoSmithKline; and Pfizer, Inc. Private sector funding for the OAI is managed by the Foundation for the NIH. This article was prepared using an OAI public use dataset and does not necessarily reflect the opinions or views of the OAI investigators, the NIH, or the private funding partners.},
references={Herrington, W., Lacey, B., Sherliker, P., Armitage, J., Lewington, S., Epidemiology of atherosclerosis and the potential to reduce the global burden of atherothrombotic disease (2016) Circ Res, 118, pp. 535-546; Bentzon, J.F., Otsuka, F., Virmani, R., Falk, E., Mechanisms of plaque formation and rupture (2014) Circ Res, 114, pp. 1852-1866; Wang, J., Börnert, P., Zhao, H., Simultaneous noncontrast angiography and intraPlaque hemorrhage (SNAP) imaging for carotid atherosclerotic disease evaluation (2013) Magn Reson Med, 69, pp. 337-345; Al-Smadi, A.S., Abdalla, R.N., Elmokadem, A.H., Diagnostic accuracy of high-resolution black-blood MRI in the evaluation of intracranial large-vessel arterial occlusions (2019) Am J Neuroradiol, 40, pp. 954-959; Sun, J., Zhao, X.-Q., Balu, N., Carotid magnetic resonance imaging for monitoring atherosclerotic plaque progression: A multicenter reproducibility study (2015) Int J Cardiovasc Imaging, 31, pp. 95-103; Choudhury, R.P., Birks, J.S., Mani, V., Arterial effects of canakinumab in patients with atherosclerosis and type 2 diabetes or glucose intolerance (2016) J Am Coll Cardiol, 68, pp. 1769-1780; Fawaz-Estrup, F., The osteoarthritis initiative: An overview (2004) Med Health R, 87, pp. 169-171; Wang, Y., Novera, D., Wluka, A.E., Association between popliteal artery wall thickness and knee structure in adults without clinical disease of the knee: A prospective cohort study (2015) Arthritis Rheumatol, 67, pp. 414-422; Liu, W., Balu, N., Canton, G., Understanding atherosclerosis through an osteoarthritis data set (2019) Arterioscler Thromb Vasc Biol, pp. 1-8; Kawahara, T., Nishikawa, M., Kawahara, C., Inazu, T., Sakai, K., Suzuki, G., Atorvastatin, etidronate, or both in patients at high risk for atherosclerotic aortic plaques: A randomized, controlled trial (2013) Circulation, 127, pp. 2327-2335; Wasserman, B.A., Astor, B.C., Richey Sharrett, A., Swingen, C., Catellier, D., MRI measurements of carotid plaque in the atherosclerosis risk in communities (ARIC) study: Methods, reliability and descriptive statistics (2010) J Magn Reson Imaging, 31, pp. 406-415; Hameeteman, K., van't Klooster, R., Selwaness, M., Carotid wall volume quantification from magnetic resonance images using deformable model fitting and learning-based correction of systematic errors (2013) Phys Med Biol, 58, pp. 1605-1623; Arias-Lorza, A.M., Petersen, J., van Engelen, A., Carotid artery wall segmentation in multispectral MRI by coupled optimal surface graph cuts (2016) IEEE Trans Med Imaging, 35, pp. 901-911; Shi, F., Yang, Q., Guo, X., Vessel wall segmentation using convolutional neural networks (2019) IEEE Trans Biomed Eng, p. 1; Gao, S., van ‘t Klooster, R., Kitslaar, P.H., Learning-based automated segmentation of the carotid artery vessel wall in dual-sequence MRI using subdivision surface fitting (2017) Med Phys, 44, pp. 5244-5259; Gao, S., van 't Klooster, R., Brandts, A., Quantification of common carotid artery and descending aorta vessel wall thickness from MR vessel wall imaging using a fully automated processing pipeline (2017) J Magn Reson Imaging, 45, pp. 215-228; Wang, B., Sha, G., Yin, P., Liu, X., Automated segmentation of carotid artery vessel wall in MRI (2018) International Conference on Advanced Hybrid Information Processing, ADHIP 2017: Advanced Hybrid Information Processing, pp. 275-286. , https://doi.org/10.1007/978-3-319-73317-3_33; Redmon, J., Farhadi, A., (2017) YOLO9000: Better, faster, stronger, pp. 6517-6525. , Proc - 30th IEEE Conf Comput Vis Pattern Recognition, CVPR 2017 2017;, -January; Chen, L., Sun, J., Canton, G., Automated artery localization and vessel wall segmentation of magnetic resonance vessel wall images using tracklet refinement and polar conversion (2019) ArXiv; Hippe, D.S., Balu, N., Chen, L., Confidence Weighting for Robust Automated Measurements of Popliteal Vessel Wall MRI (2020) Circ Genomic Precis Med, pp. 39-41. , https://doi.org/10.1161/CIRCGEN.119.002870; Sudre, C.H., Li, W., Vercauteren, T., Ourselin, S., Jorge, C.M., Generalised dice overlap as a deep learning loss function for highly unbalanced segmentations (2017) Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics), 10553, pp. 240-248. , LNCS; Pereira, S., Pinto, A., Alves, V., Silva, C.A., Brain tumor segmentation using convolutional neural networks in MRI images (2016) IEEE Trans Med Imaging, 35, pp. 1240-1251; Kerwin, W., Xu, D., Liu, F., Magnetic resonance imaging of carotid atherosclerosis: Plaque analysis (2007) Top Magn Reson Imaging, 18, pp. 371-378; Chen, L.I., Mossa-Basha, M., Balu, N., Development of a quantitative intracranial vascular features extraction tool on 3D MRA using semiautomated open-curve active contour vessel tracing (2018) Magn Reson Med, 79, pp. 3229-3238; Cai, J.M., Hatsukami, T.S., Ferguson, M.S., Small, R., Polissar, N.L., Yuan, C., Classification of human carotid atherosclerotic lesions with in vivo multicontrast magnetic resonance imaging (2002) Circulation, 106, pp. 1368-1373; Dice, L.R., Measures of the Amount of Ecologic Association Between Species (1945) Ecology, 26, pp. 297-302; Ronneberger, O., Fischer, P., Brox, T., U-Net: Convolutional Networks for Biomedical Image Segmentation (2015) Medical Image Computing and Computer-Assisted Intervention – MICCAI, pp. 234-241. , https://doi.org/10.1007/978-3-319-24574-4_28; Chen, L., Sun, J., Zhang, W., Automatic Segmentation of Carotid Vessel Wall Using Convolutional Neural Network (2018) Proc. Annu. Meet. Int. Soc. Magn. Reson. Med. Paris, Fr. 16–21 June, 2018; He, K., Gkioxari, G., Dollar, P., Mask R-CNN (2017) Proceedings of the IEEE International Conference on Computer Vision; He, K., Zhang, X., Ren, S., Deep Residual Learning for Image Recognition, , arXiv ID 1512.03385; Deng, J., Dong, W., Socher, R., ImageNet: A large-scale hierarchical image database (2009) 2009 IEEE Conference on Computer Vision and Pattern Recognition, pp. 248-255; Bartko, J.J., Measurement and reliability: Statistical thinking considerations (1991) Schizophr Bull, 17, pp. 483-489; Li, F., Yarnykh, V.L., Hatsukami, T.S., Scan-rescan reproducibility of carotid atherosclerotic plaque morphology and tissue composition measurements using multicontrast MRI at 3T (2010) J Magn Reson Imaging, 31, pp. 168-176; Peterfy, C.G., Schneider, E., Nevitt, M., The osteoarthritis initiative: Report on the design rationale for the magnetic resonance imaging protocol for the knee (2008) Osteoarthr Cartil, 16, pp. 1433-1441},
correspondence_address1={Yuan, C.; Department of Radiology, United States; email: cyuan@uw.edu},
publisher={John Wiley and Sons Inc},
issn={07403194},
coden={MRMEE},
pubmed_id={32162395},
language={English},
abbrev_source_title={Magn. Reson. Med.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Qin2020,
author={Qin, X. and Yang, J. and Zhao, L. and Li, P. and Sun, K.},
title={A novel deep forest-based active transfer learning method for PolSAR images},
journal={Remote Sensing},
year={2020},
volume={12},
number={17},
doi={10.3390/RS12172755},
art_number={1643},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090499418&doi=10.3390%2fRS12172755&partnerID=40&md5=7e20277602fdfd259c06721b825c0395},
affiliation={State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, 129 Luoyu Road, Wuhan, 430079, China; School of Remote Sensing and Information Engineering, Wuhan University, 129 Luoyu Road, Wuhan, 430079, China},
abstract={The information extraction of polarimetric synthetic aperture radar (PolSAR) images typically requires a great number of training samples; however, the training samples from historical images are less reusable due to the distribution differences. Consequently, there is a significant manual cost to collecting training samples when processing new images. In this paper, to address this problem, we propose a novel active transfer learning method, which combines active learning and the deep forest model to perform transfer learning. The main idea of the proposed method is to gradually improve the performance of the model in target domain tasks with the increase of the levels of the cascade structure. More specifically, in the growing stage, a new active learning strategy is used to iteratively add the most informative target domain samples to the training set, and the augmented features generated by the representation learning capability of the deep forest model are used to improve the cross-domain representational capabilities of the feature space. In the filtering stage, an effective stopping criterion is used to adaptively control the complexity of the model, and two filtering strategies are used to accelerate the convergence of the model. We conducted experiments using three sets of PolSAR images, and the results were compared with those of four existing transfer learning algorithms. Overall, the experimental results fully demonstrated the effectiveness and robustness of the proposed method. ©},
author_keywords={Active learning;  Deep forest;  PolSAR;  Reusability of training samples;  Transfer learning},
keywords={Deep learning;  Forestry;  Image processing;  Iterative methods;  Learning algorithms;  Sampling;  Synthetic aperture radar;  Transfer learning, Active learning strategies;  Cascade structures;  Filtering strategies;  Learning capabilities;  Polarimetric synthetic aperture radars;  Representational capabilities;  Stopping criteria;  Transfer learning methods, Learning systems},
funding_details={2019CFB484},
funding_details={6141A02022420},
funding_details={National Natural Science Foundation of ChinaNational Natural Science Foundation of China, NSFC, 41771377, 61971318},
funding_text 1={Funding: This research was funded by the National Natural Science Foundation of China (61971318, 41771377), the Hubei Provincial Natural Science Foundation of China (2019CFB484), and the Joint Fund of the Ministry of Education (6141A02022420).},
references={Pan, S.J., Yang, Q., A Survey on Transfer Learning (2010) IEEE Trans. Knowl. Data Eng., 22, pp. 1345-1359; Kamishima, T., Hamasaki, M., Akaho, S., TrBagg: A Simple Transfer Learning Method and its Application to Personalization in Collaborative Tagging (2009) Proceedings of the 2009 Ninth IEEE International Conference on Data Mining, pp. 219-228. , Miami, FL, USA, 6-9 December; Lin, D., An, X., Zhang, J., Double-bootstrapping source data selection for instance-based transfer learning (2013) Pattern Recognit. Lett., 34, pp. 1279-1285; Donahue, J., Hoffman, J., Rodner, E., Saenko, K., Darrell, T., Semi-supervised Domain Adaptation with Instance Constraints (2013) Proceedings of the 2013 IEEE Conference on Computer Vision and Pattern Recognition, pp. 668-675. , Portland, OR, USA, 23-28 June; Liu, X., Wang, G., Cai, Z., Zhang, H., Bagging based ensemble transfer learning (2016) J. Ambient Intell. Humaniz. Comput., 7, pp. 29-36; Liu, B., Xiao, Y., Hao, Z., A Selective Multiple Instance Transfer Learning Method for Text Categorization Problems (2018) Knowl. Based Syst., 141, pp. 178-187; Pereira, L.A., da Silva Torres, R., Semi-supervised transfer subspace for domain adaptation (2018) Pattern Recognit., 75, pp. 235-249; Zhang, L., Guo, L., Gao, H., Dong, D., Fu, G., Hong, X., Instance-based ensemble deep transfer learning network: A new intelligent degradation recognition method and its application on ball screw (2020) Mech. Syst. Signal Process., 140, p. 106681; Pan, S.J., Tsang, I.W., Kwok, J.T., Yang, Q., Domain Adaptation via Transfer Component Analysis (2011) IEEE Trans. Neural Netw., 22, pp. 199-210; Duan, L., Xu, D., Tsang, I.W., Domain Adaptation From Multiple Sources: A Domain-Dependent Regularization Approach (2012) IEEE Trans. Neural Netw. Learn. Syst., 23, pp. 504-518; Othman, E., Bazi, Y., Melgani, F., Alhichri, H., Alajlan, N., Zuair, M., Domain Adaptation Network for Cross-Scene Classification (2017) IEEE Trans. Geosci. Remote Sens., 55, pp. 4441-4456; Theckel Joy, T., Rana, S., Gupta, S., Venkatesh, S., A Flexible Transfer Learning Framework for Bayesian optimization with Convergence Guarantee (2018) Expert Syst. Appl., 115, pp. 656-672; Yan, K., Kou, L., Zhang, D., Learning Domain-Invariant Subspace Using Domain Features and Independence Maximization (2018) IEEE Trans. Cybern., 48, pp. 288-299; Wang, Y., Zhai, J., Li, Y., Chen, K., Xue, H., Transfer learning with partial related "instance-feature" knowledge (2018) Neurocomputing, 310, pp. 115-124; Qin, X., Yang, J., Li, P., Sun, W., Liu, W., A Novel Relational-Based Transductive Transfer Learning Method for PolSAR Images via Time-Series Clustering (2019) Remote Sens., 11, p. 1358; Wang, Z., Song, Y., Zhang, C., (2008) Transferred Dimensionality Reduction. Machine Learning and Knowledge Discovery in Databases, pp. 550-565. , Daelemans, W., Goethals, B., Morik, K., Eds.; Springer: Berlin/Heidelberg, Germany; Chang, H., Han, J., Zhong, C., Snijders, A.M., Mao, J., Unsupervised Transfer Learning via Multi-Scale Convolutional Sparse Coding for Biomedical Applications (2018) IEEE Trans. Pattern Anal. Mach. Intell., 40, pp. 1182-1194; Siddhant, A., Goyal, A., Metallinou, A., Unsupervised Transfer Learning for Spoken Language Understanding in Intelligent Agents (2018); Rochette, A., Yaghoobzadeh, Y., Hazen, T.J., Unsupervised Domain Adaptation of Contextual Embeddings for Low-Resource Duplicate Question Detection (2019); Passalis, N., Tefas, A., Unsupervised Knowledge Transfer Using Similarity Embeddings (2019) IEEE Trans. Neural Netw. Learn. Syst., 30, pp. 946-950; Liu, Y., Ding, L., Chen, C., Liu, Y., Similarity-Based Unsupervised Deep Transfer Learning for Remote Sensing Image Retrieval (2020) IEEE Trans. Geosc. Remote Sens., pp. 1-18; Deng, C., Xue, Y., Liu, X., Li, C., Tao, D., Active Transfer Learning Network: A Unified Deep Joint Spectral-Spatial Feature Learning Model for Hyperspectral Image Classification (2019) IEEE Trans. Geosci. Remote Sens., 57, pp. 1741-1754; Wu, D., Active semi-supervised transfer learning (ASTL) for offline BCI calibration (2017) Proceedings of the 2017 IEEE International Conference on Systems, pp. 246-251. , Man, and Cybernetics (SMC), Banff, AB, Canada, 5-8 October; Yan, Y., Subramanian, R., Lanz, O., Sebe, N., Active transfer learning for multi-view head-pose classification (2012) Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012), pp. 1168-1171. , Tsukuba, Japan, 11-15 November; Tang, X., Du, B., Huang, J., Wang, Z., Zhang, L., On combining active and transfer learning for medical data classification (2019) IET Comput. Vis., 13, pp. 194-205; Wang, N., Li, T., Zhang, Z., Cui, L., TLTL: An Active Transfer Learning Method for Internet of Things Applications (2019) Proceedings of the ICC 2019-2019 IEEE International Conference on Communications (ICC), pp. 1-6. , Shanghai, China, 20-24 May; Zhou, Z., Feng, J., Deep forest: Towards an alternative to deep neural networks (2017); Settles, B., (2010) Active Learning Literature Survey, 52. , University of Wisconsin-Madison: Madison, WI, USA; Schein, A.I., Ungar, L.H., Active learning for logistic regression: An evaluation (2007) Mach. Learn., 68, pp. 235-265; Demir, B., Persello, C., Bruzzone, L., Batch-Mode Active-Learning Methods for the Interactive Classification of Remote Sensing Images (2011) IEEE Trans. Geosci. Remote Sens., 49, pp. 1014-1031; Brinker, K., Incorporating Diversity in Active Learning with Support Vector Machines (2003) Proceedings of the Twentieth International Conference (ICML 2003), pp. 59-66. , Washington, DC, USA, 21-24 August; Persello, C., Bruzzone, L., Active Learning for Domain Adaptation in the Supervised Classification of Remote Sensing Images (2012) IEEE Trans. Geosci. Remote Sens., 50, pp. 4468-4483; Yang, J., Li, S., Xu, W., Active Learning for Visual Image Classification Method Based on Transfer Learning (2018) IEEE Access, 6, pp. 187-198; Cloude, S.R., Pottier, E., An entropy based classification scheme for land applications of polarimetric SAR (1997) IEEE Trans. Geosci. Remote Sens., 35, pp. 68-78; Deng, W., Lendasse, A., Ong, Y., Tsang, I.W., Chen, L., Zheng, Q., Domain Adaption via Feature Selection on Explicit Feature Map (2019) IEEE Trans. Neural Netw. Learn. Syst., 30, pp. 1180-1190; Fernando, B., Habrard, A., Sebban, M., Tuytelaars, T., Unsupervised Visual Domain Adaptation Using Subspace Alignment (2013) Proceedings of the 2013 IEEE International Conference on Computer Vision, pp. 2960-2967. , Sydney, Australia, 1-8 December; Borgwardt, K.M., Gretton, A., Rasch, M.J., Kriegel, H.P., Schölkopf, B., Smola, A.J., Integrating Structured Biological Data by Kernel Maximum Mean Discrepancy (2006) Bioinformatics, 22, pp. 49-57},
correspondence_address1={Zhao, L.; School of Remote Sensing and Information Engineering, 129 Luoyu Road, China; email: zhaolingli@whu.edu.cn},
publisher={MDPI AG},
issn={20724292},
language={English},
abbrev_source_title={Remote Sens.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Wu202039,
author={Wu, X. and Li, W. and Hong, D. and Tian, J. and Tao, R. and Du, Q.},
title={Vehicle detection of multi-source remote sensing data using active fine-tuning network},
journal={ISPRS Journal of Photogrammetry and Remote Sensing},
year={2020},
volume={167},
pages={39-53},
doi={10.1016/j.isprsjprs.2020.06.016},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087788723&doi=10.1016%2fj.isprsjprs.2020.06.016&partnerID=40&md5=6b10522d809a4ce448f916b1b0ecc08d},
affiliation={School of Information and Electronics, Beijing Institute of Technology, Beijing, 100081, China; Beijing Key Laboratory of Fractional Signals and Systems, Beijing, 100081, China; Remote Sensing Technology Institute (IMF), German Aerospace Center (DLR), Wessling, 82234, Germany; Department of Electrical and Computer Engineering, Mississippi State University, Mississippi State, MS, 39762, United States},
abstract={Vehicle detection in remote sensing images has attracted increasing interest in recent years. However, its detection ability is limited due to lack of well-annotated samples, especially in densely crowded scenes. Furthermore, since a list of remotely sensed data sources is available, efficient exploitation of useful information from multi-source data for better vehicle detection is challenging. To solve the above issues, a multi-source active fine-tuning vehicle detection (Ms-AFt) framework is proposed, which integrates transfer learning, segmentation, and active classification into a unified framework for auto-labeling and detection. The proposed Ms-AFt employs a fine-tuning network to firstly generate a vehicle training set from an unlabeled dataset. To cope with the diversity of vehicle categories, a multi-source based segmentation branch is then designed to construct additional candidate object sets. The separation of high quality vehicles is realized by a designed attentive classifications network. Finally, all three branches are combined to achieve vehicle detection. Extensive experimental results conducted on two open ISPRS benchmark datasets, namely the Vaihingen village and Potsdam city datasets, demonstrate the superiority and effectiveness of the proposed Ms-AFt for vehicle detection. In addition, the generalization ability of Ms-AFt in dense remote sensing scenes is further verified on stereo aerial imagery of a large camping site. © 2020},
author_keywords={Active classification network;  Fine-tuning;  Multi-source;  Optical remote sensing imagery;  Segmentation;  Vehicle detection},
keywords={Aerial photography;  Antennas;  Stereo image processing;  Transfer learning;  Vehicles, Benchmark datasets;  Detection ability;  Generalization ability;  Remote sensing data;  Remote sensing images;  Remotely sensed data;  Unified framework;  Vehicle detection, Remote sensing, artificial neural network;  benchmarking;  data set;  detection method;  machine learning;  remote sensing;  satellite data;  satellite imagery;  segmentation, Baden-Wurttemberg;  Brandenburg [Germany];  Germany;  Potsdam;  Vaihingen an der Enz},
funding_details={National Natural Science Foundation of ChinaNational Natural Science Foundation of China, NSFC, 61421001, 61922013, U1833203},
funding_details={Fundamental Research Funds for the Central UniversitiesFundamental Research Funds for the Central Universities, 3052019116},
funding_text 1={This work was supported, in part by the National Natural Science Foundation of China under Grant 61922013 , 61421001 , and U1833203 , and partly by the Fundamental Research Funds for the Central Universities under Grant 3052019116 .},
references={Achanta, R., Shaji, A., Smith, K., Lucchi, A., Fua, P., Süsstrunk, S., Slic superpixels compared to state-of-the-art superpixel methods (2012) IEEE Trans. Pattern Anal. Mach. Intell., 34 (11), pp. 2274-2282; Aldeborgh, N., Ouzounis, G., Stamatiou, K., Unsupervised object detection on remote sensing imagery using hierarchical image representations and deep learning (2017) Proc. Int. Conf. IBig Data from Space (BiDS), pp. 255-258; Arivalagan, S., Venkatachalapathy, K., Vehicle detection in traffic videos using differential evolution algorithm trained neural network (2015) Int. J. Appl. Eng. Res., 10 (6), pp. 14691-14702; Audebert, N., Bertrand, L., Sébastien, L., Segment-before-detect: vehicle detection and classification through semantic segmentation of aerial images (2017) Remote Sens., 9 (4), p. 368; Cao, L., Luo, F., Chen, L., Sheng, Y., Wang, H., Wang, C., Ji, R., Weakly supervised vehicle detection in satellite images via multi-instance discriminative learning (2016) Pattern Recogn., 64, pp. 417-424; Chai, D., A probabilistic framework for building extraction from airborne color image and dsm (2016) IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., 10 (3), pp. 948-959; Chen, G., Liu, L., Hu, W., Pan, Z., Semi-supervised object detection in remote sensing images using generative adversarial networks (2018) Proc. IEEE. Int. Conf. Geoscience and Remote Sensing Symposium (IGARSS), pp. 2503-2506; Chen, Z., Zhang, T., Ouyang, C., End-to-end airplane detection using transfer learning in remote sensing images (2018) Remote sens., 10 (1), p. 139; Cheng, G., Han, J., A survey on object detection in optical remote sensing images (2016) ISPRS J. Photogramm. Remote Sens., 117, pp. 11-28; Cheng, G., Han, J., Zhou, P., Guo, L., Multi-class geospatial object detection and geographic image classification based on collection of part detectors (2014) ISPRS J. Photogramm. Remote Sens., 98 (1), pp. 119-132; Cheng, G., Han, J., Zhou, P., Xu, D., Learning rotation-invariant and fisher discriminative convolutional neural networks for object detection (2018) IEEE Trans. Image Process., 28 (1), pp. 265-278; Cheng, G., Si, Y., Hong, H., Yao, X., Guo, L., (2020), Cross-scale feature fusion for object detection in optical remote sensing images. IEEE Geosci. Remote Sens. Lett; Cheng, G., Zhou, P., Han, J., Learning rotation-invariant convolutional neural networks for object detection in vhr optical remote sensing images (2016) IEEE Trans. Geosci. Remote Sens., 54 (12), pp. 7405-7415; Dai, J., Li, Y., He, K., Sun, J., R-fcn: object detection via region-based fully convolutional networks (2016) Proc. IEEE Int. Conf. on Computer Vision and Pattern Recognition (CVPR), pp. 379-387; Ester, M., Kriegel, H., Sander, J., Xu, X., (1996), pp. 226-231. , A density-based algorithm for discovering clusters in large spatial databases with noise. In: Proc. KDD. vol. 96; Gintautas, P., Franz, K., Peter, R., (2009), Detection of traffic congestion in optical remote sensing imagery. In: Proc. IEEE. Int. Conf. Geoscience and Remote Sensing Symposium (IGARSS); Gstaiger, V., Tian, J., Kiefl, R., Kurz, F., 2d vs. 3d change detection using aerial imagery to support crisis management of large-scale events (2018) Remote Sens., 10 (12), p. 2054; Han, J., Zhang, D., Cheng, G., Guo, L., Ren, J., Object detection in optical remote sensing images based on weakly supervised learning and high-level feature learning (2015) IEEE Trans. Geosci. Remote Sens., 53 (6), pp. 3325-3337; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; He, X., Wang, A., Ghamisi, P., Li, G., Chen, Y., Lidar data classification using spatial transformation and cnn (2019) IEEE Geosci. Remote Sens. Lett., 16 (1), pp. 125-129; Hendrik, S., Dimitri, B., Wolfgang, M., Object-based detection of vehicles using combined optical and elevation data (2018) ISPRS J. Photogramm. Remote Sens., 136, pp. 85-105; Hong, D., Wu, X., Ghamisi, P., Chanussot, J., Yokoya, N., Zhu, X.X., Invariant attribute profiles: a spatial-frequency joint feature extractor for hyperspectral image classification (2020) IEEE Trans. Geosci. Remote Sens., 58 (6), pp. 3791-3808; Hong, D., Yokoya, N., Chanussot, J., Zhu, X.X., An augmented linear mixing model to address spectral variability for hyperspectral unmixing (2019) IEEE Trans. Image Process., 28 (4), pp. 1923-1938; Hong, D., Yokoya, N., Chanussot, J., Zhu, X.X., CoSpace: Common subspace learning from hyperspectral-multispectral correspondences (2019) IEEE Trans. Geosci. Remote Sens., 57 (7), pp. 4349-4359; Hong, D., Yokoya, N., Ge, N., Chanussot, J., Zhu, X., Learnable manifold alignment (LeMA): a semi-supervised cross-modality learning framework for land cover and land use classification (2019) ISPRS J. Photogramm. Remote Sens., 147, pp. 193-205; Huang, R., Hong, D., Xu, Y., Yao, W., Stilla, U., Multi-scale local context embedding for lidar point cloud classification (2020) IEEE Geosci. Remote Sens. Lett., 17 (4), pp. 721-725; Ji, H., Gao, Z., Mei, T., Li, Y., Improved faster r-cnn with multiscale feature fusion and homography augmentation for vehicle detection in remote sensing images (2019) IEEE Geosci. Remote Sens. Lett., 16 (11), pp. 1761-1765; Joseph, R., Ali, F., Yolo9000: Better, faster, stronger (2017) Proc. IEEE Int. Conf. on Computer Vision and Pattern Recognition (CVPR), pp. 6517-6525; Joseph, R., Santosh, D., Ross, G., Ali, F., You only look once: Unified, real-time object detection (2016) Proc. IEEE Int. Conf. on Computer Vision and Pattern Recognition (CVPR), pp. 779-788; Kang, J., Hong, D., Liu, J., Baier, G., Yokoya, N., Demir, B., (2020), Learning convolutional sparse coding on complex domain for interferometric phase restoration. IEEE Trans. Neural Netw. Learn. Syst. doi: 10.1109/TNNLS.2020.2979546; Kang, L., Gellert, M., Fast multiclass vehicle detection on aerial images (2015) IEEE Geosci. Remote Sens. Lett., 12 (9), pp. 1938-1942; Karim, A., Moutakki, Z., Ayaou, T., Amghar, A., Prototype of an embedded system using stratix iii fpga for vehicle detection and traffic management (2014) Proc. Int. Conf. Multimedia Computing and Systems (ICMCS), pp. 141-146; Li, K., Wan, G., Cheng, G., Meng, L., Han, J., Object detection in optical remote sensing images: a survey and a new benchmark (2020) ISPRS J. Photogramm. Remote Sens., 159, pp. 296-307; Lin, D., Fu, K., Wang, Y., Xu, G., Sun, X., Marta gans: unsupervised representation learning for remote sensing image classification (2016) IEEE Geosci. Remote Sens. Lett., 14 (11), pp. 2092-2096; Mandal, M., Shah, M., Meena, P., Devi, S., Vipparthi, S.K., Avdnet: A small-sized vehicle detection network for aerial visual data (2019) IEEE Geosci. Remote Sens. Lett., 17 (3), pp. 494-498; Marmanis, D., Schindler, K., Wegner, J., Galliani, S., Datcu, M., Stilla, U., Classification with an edge: Improving semantic image segmentation with boundary detection (2016) ISPRS J. Photogramm. Remote Sens., 135, pp. 158-172; Niessner, R., Schilling, H., Jutzi, B., Investigations on the potential of convolutional neural networks for vehicle classification based on rgb and lidar data (2017) ISPRS Ann. Photogramm. Remote Sens. Spatial Inf. Sci., 4, p. 115; Ning, C., Zhou, H., Song, Y., Tang, J., Inception single shot multibox detector for object detection (2017) Proc. IEEE Int. Conf. on Multimedia Expo Workshops (ICMEW), pp. 549-554; Pang, J., Sun, W., Ren, J.S., Yang, C., Yan, Q., Cascade residual learning: a two-stage convolutional neural network for stereo matching (2017) Proc. IEEE Int. Conf. on Computer Vision Workshops, pp. 887-895; Rasti, B., Hong, D., Hang, R., Ghamisi, P., Kang, X., Chanussot, J., Benediktsson, J., (2020), Feature extraction for hyperspectral imagery: The evolution from shallow to deep (overview and toolbox). IEEE Geosci. Remote Sens. Mag. doi: 10.1109/MGRS.2020.2979764; Schilling, H., Bulatov, D., Niessner, R., Middelmann, W., Soergel, U., (2018), pp. 4299-4316. , Detection of vehicles in multisensor data via multibranch convolutional neural networks. IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens. 11 (11); Simonyan, K., Zisserman, A., (2014), Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:; Sumbul, G., Cinbis, R.G., Aksoy, S., Multisource region attention network for fine-grained object recognition in remote sensing imagery (2019) IEEE Trans. Geosci. Remote Sens., 57 (7), pp. 4929-4937; Szegedy, C., Ioffe, S., Vanhoucke, V., (2017), Alemi, A.A. Inception-v4, inception-resnet and the impact of residual connections on learning. In: Proc. Thirty-first AAAI Conference on Artificial Intelligence (AAAI); Wei, H., Zhou, G., Zheng, Z., Detection of traffic congestion in optical remote sensing imagery (2013) Proc. IEEE. Int. Conf. Geoscience and Remote Sensing Symposium (IGARSS), pp. 4002-4005; Wen, X., Bruno, V., Konrad, S., Nicola, P., Street-side vehicle detection, classification and change detection using mobile laser scanning data (2019) ISPRS J. Photogramm. Remote Sens., 114, pp. 166-178; Weng, Q., Fu, P., Gao, F., Generating daily land surface temperature at landsat resolution by fusing landsat and modis data (2014) Remote Sens. Environ., 145, pp. 55-67; Weng, Q., Quattrochi, D., Gamba, P.E., Urban Remote Sensing (2018), CRC Press; Wu, X., Hong, D., Chanussot, J., Xu, Y., Tao, R., Wang, Y., Fourier-based rotation-invariant feature boosting: an efficient framework for geospatial object detection (2020) IEEE Geosci. Remote Sens. Lett., 17 (2), pp. 302-306; Wu, X., Hong, D., Tian, J., Chanussot, J., Li, W., Tao, R., Orsim detector: a novel object detection framework in optical remote sensing imagery using spatial-frequency channel features (2019) IEEE Trans. Geosci. Remote Sens., 57 (7), pp. 5146-5158; Xia, G., Bai, X., Ding, J., Zhu, Z., Belongie, S., Luo, J., Datcu, M., Zhang, L., Dota: A large-scale dataset for object detection in aerial images (2018) Proc. IEEE Int. Conf. on Computer Vision and Pattern Recognition (CVPR), pp. 3974-3983; Yang, C., Li, W., Lin, Z., Vehicle object detection in remote sensing imagery based on multi-perspective convolutional neural network (2018) ISPRS Int. J. Geo-Inf., 7 (7), p. 249; Zanotta, D.C., Zortea, M., Ferreira, M.P., A supervised approach for simultaneous segmentation and classification of remote sensing images (2018) ISPRS J. Photogramm. Remote Sens., 142, pp. 162-173},
correspondence_address1={Li, W.; School of Information and Electronics, China; email: liwei089@ieee.org},
publisher={Elsevier B.V.},
issn={09242716},
coden={IRSEE},
language={English},
abbrev_source_title={ISPRS J. Photogramm. Remote Sens.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Lõuk2020,
author={Lõuk, R. and Riid, A. and Pihlak, R. and Tepljakov, A.},
title={Pavement defect segmentation in orthoframes with a pipeline of three convolutional neural networks},
journal={Algorithms},
year={2020},
volume={13},
number={8},
doi={10.3390/A13080198},
art_number={198},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090390206&doi=10.3390%2fA13080198&partnerID=40&md5=6b916fd01c14e508e09a76a44cda9ad1},
affiliation={Department of Software Science, Tallinn University of Technology, Tallinn, 19086, Estonia; Department of Computer Systems, Tallinn University of Technology, Tallinn, 19086, Estonia},
abstract={In the manuscript, the issue of detecting and segmenting out pavement defects on highway roads is addressed. Specifically, computer vision (CV) methods are developed and applied to the problem based on deep learning of convolutional neural networks (ConvNets). A novel neural network structure is considered, based on a pipeline of three ConvNets and endowed with the capacity for context awareness, which improves grid-based search for defects on orthoframes by considering the surrounding image content-an approach, which essentially draws inspiration from how humans tend to solve the task of image segmentation. Also, methods for assessing the quality of segmentation are discussed. The contribution also describes the complete procedure of working with pavement defects in an industrial setting, involving the workcycle of defect annotation, ConvNet training and validation. The results of ConvNet evaluation provided in the paper hint at a successful implementation of the proposed technique. © 2020 by the authors.},
author_keywords={Active learning;  Convolutional Neural Network;  Deep Learning;  Digital image;  Pavement distress;  Transfer learning},
keywords={Convolution;  Deep learning;  Defects;  Image enhancement;  Image segmentation;  Pavements;  Pipelines, Context- awareness;  Convnet;  Grid-based;  Image content;  Industrial settings;  Novel neural network;  Problem-based, Convolutional neural networks},
funding_details={19022},
funding_details={Sihtasutus ArchimedesSihtasutus Archimedes},
funding_text 1={Funding: This research endeavor was partially supported by Archimedes Foundation and Reach-U Ltd. in the scope of the smart specialization research and development project #LEP19022: “Applied research for creating a cost-effective interchangeable 3D spatial data infrastructure with survey-grade accuracy”.},
references={Ragnoli, A., De Blasiis, M.R., Di Benedetto, A., Pavement distress detection methods: A review (2018) Infrastructures., 3, p. 58; Vavrik, W., Evans, L., Sargand, S., Stefanski, J., (2013) PCR Evaluation: Considering Transition from Manual to Semi-Automated Pavement Distress Collection and Analysis, , https://rosap.ntl.bts.gov/view/dot/26795, (accessed on 1 July 2013); Mei, Q., Gül, M., A cost effective solution for pavement crack inspection using cameras and deep neural networks (2020) Constr. Build Mater., 256; Pan, Y., Zhang, X., Cervone, G., Yang, L., Detection of Asphalt Pavement Potholes and Cracks Based on the Unmanned Aerial Vehicle Multispectral Imagery (2018) IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens., 11, pp. 3701-3712; Yi, L., Zou, L., Takahashi, K., Sato, M., High-Resolution Velocity Analysis Method Using the l-1 Norm Regularized Least-Squares Method for Pavement Inspection (2018) IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens., 11, pp. 1005-1015; Choi, J., Zhu, L., Kurosu, H., (2016) Detection of Cracks in Paved Road Surface Using Laser Scan Image Data, , https://pdfs.semanticscholar.org/e591/fcd67903e8c6210a0ec2151ea336536766f9.pdf, (accessed on 19 July 2016); Bhat, S., Naik, S., Gaonkar, M., Sawant, P., Aswale, S., Shetgaonkar, P., A Survey On Road Crack Detection Techniques (2020) In Proceedings of the International Conference on Emerging Trends in Information Technology and Engineering (ic-ETITE), pp. 1-6. , Vellore, India, 24-25 February; Cao, W., Liu, Q., He, Z., Review of pavement defect detection methods (2020) IEEE Access, 8, pp. 14531-14544; Azhar, K., Murtaza, F., Yousaf, M.H., Habib, H.A., Computer vision based detection and localization of potholes in asphalt pavement images (2016) In Proceedings of the Canadian Conference on Electrical and Computer Engineering, pp. 1-5. , Vancouver, BC, Canada, 15-18 May; Jenkins, M.D., Carr, T.A., Iglesias, M.I., Buggy, T., Morison, G., A deep convolutional neural network for semantic pixel-wise segmentation of road and pavement surface cracks (2018) In Proceedings of the 26th European Signal Processing Conference (EUSIPCO), pp. 2120-2124. , Rome, Italy, 3-7 September; Nie, M., Wang, K., Pavement Distress Detection Based on Transfer Learning (2018) In Proceedings of the 2018 5th International Conference on Systems and Informatics, pp. 435-439. , Nanjing, China, 10-12 November; Riid, A., Lõuk, R., Pihlak, R., Tepljakov, A., Vassiljeva, K., Pavement Distress Detection with Deep Learning Using the Orthoframes Acquired by a Mobile Mapping System (2019) Appl. Sci., 9; Yusof, N., Osman, M., Hussain, Z., Noor, M., Ibrahim, A., Tahir, N., Abidin, N., Automated Asphalt Pavement Crack Detection and Classification using Deep Convolution Neural Network (2019) In Proceedings of the 2019 9th IEEE International Conference on Control System, pp. 215-220. , Computing and Engineering, Penang, Malaysia, 29 November-1 December; Huyan, J., Li, W., Tighe, S., Xu, Z., Zhai, J., CrackU-net: A novel deep convolutional neural network for pixelwise pavement crack detection (2020) Struct. Contr. Health Monit., 27; Sun, M., Guo, R., Zhu, J., Fan, W., Roadway Crack Segmentation Based on an Encoder-decoder Deep Network with Multi-scale Convolutional Blocks (2020) In Proceedings of the 10th Annual Computing and Communication Workshop and Conference, pp. 869-874. , Las Vegas, NV, USA, 6-8 January; Li, G., Wan, J., He, S., Liu, Q., Ma, B., Semi-Supervised Semantic Segmentation Using Adversarial Learning for Pavement Crack Detection (2020) IEEE Access, 8, pp. 51446-51459; Akagic, A., Buza, E., Omanovic, S., Pothole detection: An efficient vision based method using RGB color space image segmentation (2017) In Proceedings of the 40th International Convention on Information and Communication Technology, pp. 1104-1109. , Opatija, Croatia, 22-26 May; Seichter, D., Eisenbach, M., Stricker, R., Gross, H.M., How to Improve Deep Learning based Pavement Distress Detection while Minimizing Human Effort (2018) In Proceedings of the IEEE International Conference on Automation Science and Engineering, pp. 63-70. , Munich, Germany, 20-24 August; Chen, J., Liu, G., Chen, X., Road crack image segmentation using global context unet (2019) In Proceedings of the ACM International Conference Proceeding Series; Association for Computing Machinery, pp. 181-185. , Beijing, China, 6-8 December; Gopalakrishnan, K., Khaitan, S., Choudhary, A., Agrawal, A., Deep Convolutional Neural Networks with transfer learning for computer vision-based data-driven pavement distress detection (2017) Constr. Build Mater., 157, pp. 322-330; Tepljakov, A., Riid, A., Pihlak, R., Vassiljeva, K., Petlenkov, E., Deep Learning for Detection of Pavement Distress using Nonideal Photographic Images (2019) In Proceedings of the 42nd International Conference on Telecommunications and Signal Processing, pp. 195-200. , Budapest, Hungary, 1-3 July; https://www.eyevi.tech, (accessed on 30 June 2020); Soppe, T., (2017) Pavement Defect Inventory, , Master's Thesis, Tallinn University of Applied Sciences, Tallinn, Estonia, June; Masters, D., Luschi, C., Revisiting Small Batch Training for Deep Neural Networks. (2018) arXiv, , https://arxiv.org/abs/1804.07612, (accessed on 20 April 2018); Ronneberger, O., Fischer, P., Brox, T., U-Net: Convolutional Networks for Biomedical Image Segmentation. (2015) arXiv, , https://arxiv.org/abs/1505.04597, (accessed on 18 May 2015); He, K., Zhang, X., Ren, S., Sun, J., Deep Residual Learning for Image Recognition (2016) In Proceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778. , Las Vegas, NV, USA, 12 December; Lõuk, R., Tepljakov, A., Riid, A., A Two-Stream Context-Aware ConvNet for Pavement Distress Detection (2020) In Proceedings of the 43rd International Conference on Telecommunications and Signal Processing (TSP), Milan, Italy, 6-8 July., , in press; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., Imagenet large scale visual recognition challenge (2015) Int. J. Comput. Vis., 115, pp. 211-252; Kornblith, S., Shlens, J., Le, Q.V., Do Better ImageNet Models Transfer Better?. (2018) arXiv, , https://arxiv.org/abs/1805.08974, (accessed on 17 June 2019); Alhaija, H., Mustikovela, S., Mescheder, L., Geiger, A., Rother, C., Augmented Reality Meets Computer Vision: Efficient Data Generation for Urban Driving Scenes (2018) Int. J. Comput. Vis., 126, pp. 961-972; Shi, Y., Cui, L., Qi, Z., Meng, F., Chen, Z., Automatic road crack detection using random structured forests (2016) IEEE Trans. Intell. Transp. Syst., 17, pp. 3434-3445; Augustauskas, R., Lipnickas, A., Improved Pixel-Level Pavement-Defect Segmentation Using a Deep Autoencoder (2020) Sensors., 20; Everingham, M., Van Gool, L., Williams, C.K., Winn, J., Zisserman, A., The pascal visual object classes (voc) challenge (2010) Int. J. Comput. Vis., 88, pp. 303-338; (2020) PyQt Reference Guide, , https://www.riverbankcomputing.com/static/Docs/PyQt5/, (accessed on 13 August 2020); Torbert, S., (2016) Applied Computer Science, , Springer International Publishing: Fairfax, VA, USA; (2020) DATM Annotation Tool GitHub Page, , https://github.com/is-centre/datm-annotation-tool, (accessed on 13 August 2020); Sener, O., Savarese, S., Active learning for convolutional neural networks: A core-set approach. (2017) arXiv, , https://arxiv.org/abs/1708.00489, (accessed on 13 August 2020); Ducoffe, M., Precioso, F., Adversarial Active Learning for Deep Networks: a Margin Based Approach. (2018) arXiv, , https://arxiv.org/abs/1802.09841, (accessed on 13 August 2020); Rahman, M.A., Wang, Y., Optimizing intersection-over-union in deep neural networks for image segmentation (2016) In Proceedings of the International Symposium on Visual Computing, pp. 234-244. , Las Vegas, NV, USA, 12-14 December; van Beers, F., Lindström, A., Okafor, E., Wiering, M.A., Deep Neural Networks with Intersection over Union Loss for Binary Image Segmentation (2019) In Proceedings of the ICPRAM, pp. 438-445. , Prague, Czech Republic, 19-21 February; Smith, L., Topin, N., Super-convergence: very fast training of neural networks using large learning rates. (2019) arXiv, , https://doi.org/10.1117/12.2520589, (accessed on 13 August 2020); Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Antiga, L., PyTorch: An Imperative Style, High-Performance Deep Learning Library (2019) In Proceedings of the In Advances in Neural Information Processing Systems 32, pp. 8024-8035. , Vancouver, BC, Canada, 8-14 December; Kingma, D.P., Ba, J., Adam: A method for stochastic optimization. (2014) arXiv, , https://arxiv.org/abs/1412.6980, (accessed on 30 January 2017); Buslaev, A., Parinov, A., Khvedchenya, E., Iglovikov, V.I., Kalinin, A.A., Albumentations: fast and flexible image augmentations. (2018) arXiv, , https://arxiv.org/abs/1809.06839, (accessed on 18 September 2018); Yakubovskiy, P., Segmentation Models Pytorch., , https://github.com/qubvel/segmentation_models.pytorch, (accessed on 30 June 2020); Hu, J., Shen, L., Sun, G., Squeeze-and-Excitation Networks (2018) In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 7132-7141. , Salt Lake City, UT, USA, 18-23 June; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning (2017) In Proceedings of the Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, pp. 4278-4284. , San Fransisco, CA, USA, 4-9 February; Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., Densely Connected Convolutional Networks (2017) In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2261-2269. , Honolulu, HI, USA, 21-26 July; Nowling, R.J., Bukowy, J., McGarry, S.D., Nencka, A.S., Blasko, O., Urbain, J., Lowman, A., Iczkowski, K.A., Classification before Segmentation: Improved U-Net Prostate Segmentation (2019) In Proceedings of the IEEE EMBS International Conference on Biomedical Health Informatics (BHI), pp. 1-4. , Chicago, IL, USA, 19-22 May},
correspondence_address1={Riid, A.; Department of Software Science, Estonia; email: andri.riid@ttu.ee},
publisher={MDPI AG},
issn={19994893},
language={English},
abbrev_source_title={Algorithms},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Singh2020,
author={Singh, A. and Chakraborty, S.},
title={Deep Active Transfer Learning for Image Recognition},
journal={Proceedings of the International Joint Conference on Neural Networks},
year={2020},
doi={10.1109/IJCNN48605.2020.9207391},
art_number={9207391},
note={cited By 0; Conference of 2020 International Joint Conference on Neural Networks, IJCNN 2020 ; Conference Date: 19 July 2020 Through 24 July 2020;  Conference Code:163566},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093847844&doi=10.1109%2fIJCNN48605.2020.9207391&partnerID=40&md5=677705860bec6bc42fc9c56f9702fda5},
affiliation={Florida State University, Department of Computer Science, United States},
abstract={In recent years, deep learning has revolutionized the field of computer vision and has achieved state-of-the-art performance in a variety of applications. However, training a robust deep neural network necessitates a large amount of hand-labeled training data, which is time-consuming and labor-intensive to acquire. Active learning and transfer learning are two popular methodologies to address the problem of learning with limited labeled data. Active learning attempts to select the salient and exemplar instances from large amounts of unlabeled data; transfer learning leverages knowledge from a labeled source domain to develop a model for a (related) target domain, where labeled data is scarce. In this paper, we propose a novel active transfer learning algorithm with the objective of learning informative feature representations from a given dataset using a deep convolutional neural network, under the constraint of weak supervision. We formulate a loss function relevant to the research task and exploit the gradient descent algorithm to optimize the loss and train the deep network. To the best of our knowledge, this is the first research effort to propose a task-specific loss function integrating active and transfer learning, with the goal of learning informative feature representations using a deep neural network, under weak human supervision. Our extensive empirical studies on a variety of challenging, real-world applications depict the merit of our framework over competing baselines. © 2020 IEEE.},
author_keywords={active learning;  deep learning;  image recognition;  transfer learning},
keywords={Convolutional neural networks;  Deep neural networks;  Gradient methods;  Image recognition;  Labeled data;  Learning algorithms;  Learning systems;  Transfer learning, Empirical studies;  Feature representation;  Gradient descent algorithms;  Human supervision;  Labeled training data;  Research efforts;  Specific loss function;  State-of-the-art performance, Deep learning},
references={Krizhevsky, A., Sutskever, I., Hinton, G., Imagenet classification with deep convolutional neural networks (2012) Neural Information Processing Systems (NIPS); Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Ranganathan, H., Chakraborty, S., Panchanathan, S., Multimodal emotion recognition using deep learning architectures (2016) IEEE Winter Conference on Applications of Computer Vision (WACV); Badrinarayanan, V., Kendall, A., Cipolla, R., Segnet: A deep convolutional encoder-decoder architecture for image segmentation (2015) IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Settles, B., (2010) Active Learning Literature Survey, , Technical Report: University of Wisconsin-Madison; Pan, S., Yang, Q., A survey on transfer learning (2010) IEEE Transactions on Knowledge and Data Engineering (TKDE), 22 (10); Tzeng, E., Hoffman, J., Saenko, K., Darrell, T., Adversarial discriminative domain adaptation (2017) IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Liu, M., Breuel, T., Kautz, J., Unsupervised image-to-image translation networks (2017) Advances of Neural Information Processing Systems (NIPS); Chakraborty, S., Balasubramanian, V., Sun, Q., Panchanathan, S., Ye, J., Active batch selection via convex relaxations with guaranteed solution bounds (2015) IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 37 (10), pp. 1945-1958; Hoi, S., Jin, R., Zhu, J., Lyu, M., Batch mode active learning and its application to medical image classification (2006) International Conference on Machine Learning (ICML); Holub, A., Perona, P., Burl, M., Entropy-based active learning for object recognition (2008) IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPR-W); Tong, S., Chang, E., Support vector machine active learning for image retrieval Proceedings of the Ninth ACM International Conference; Freund, Y., Seung, S., Shamir, E., Tishby, N., Selective sampling using the query by committee algorithm (1997) Machine Learning, 28 (2-3), pp. 133-168; Cai, W., Zhang, Y., Zhou, J., Maximizing expected model change for active learning in regression (2013) IEEE International Conference on Data Mining (ICDM); Shen, D., Zhang, J., Su, J., Zhou, G., Tan, C., Multi-criteria based active learning for named entity recognition (2004) Association for Computational Linguistics (ACL); Guo, Y., Active instance sampling via matrix partition (2010) Advances of Neural Information Processing Systems (NIPS); Zhu, J., Bento, J., Generative adversarial active learning (2017) Advances of Neural Information Processing Systems (NIPS) Workshops; Ruchansky, N., Crovella, M., Terzi, E., Matrix completion with queries (2015) ACM Conference on Knowledge Discovery and Data Mining (KDD); Molino, A., Boix, X., Lim, J., Tan, A., Active video summarization: Customized summaries via on-line interaction with the user (2017) Association for the Advancement of Artificial Intelligence (AAAI); Xiong, S., Pei, Y., Rosales, R., Fern, X., Active learning from relative comparisons (2015) IEEE Transactions on Knowledge and Data Engineering, 27 (12); Yan, S., Chaudhuri, K., Active learning from imperfect labelers (2016) Advances of Neural Information Processing Systems (NIPS); Pan, S., Tsang, I., Kwok, J., Yang, Q., Domain adaptation via transfer component analysis (2009) International Joint Conference on Artificial Intelligence (IJCAI); Pardoe, D., Stone, P., Boosting for regression transfer (2010) International Conference on Machine Learning (ICML); Long, M., Cao, Y., Wang, J., Jordan, M., Learning transferable features with deep adaptation networks (2015) International Conference on Machine Learning (ICML); Long, M., Zhu, H., Wang, J., Jordan, M., Unsupervised domain adaptation with residual transfer networks (2016) Advances of Neural Information Processing Systems (NIPS); Venkateswara, H., Eusebio, J., Chakraborty, S., Panchanathan, S., Deep hashing network for unsupervised domain adaptation (2017) IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Advances OfNeural Information Processing Systems (NIPS); Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Lavi-Olette, F., Marchand, M., Lempitsky, V., Domain-adversarial training of neural networks (2016) Journal OfMachine Learning Research (JMLR), 17; Kingma, D., Welling, M., (2013) Auto-encoding Variational Bayes; Shen, J., Qu, Y., Zhang, W., Yu, Y., Wasserstein distance guided representation learning for domain adaptation (2018) Association for the Advancement of Artificial Intelligence (AAAI); Chan, Y., Ng, H., Domain adaptation with active learning for word sense disambiguation (2007) Association of Computational Linguistics (ACL); Shi, X., Fan, W., Ren, J., Actively transfer domain knowledge (2008) European Conference on Machine Learning (ECML); Rai, P., Saha, A., Daume, H., Venkatasubramanian, S., Domain adaptation meets active learning (2010) NAACL HLT 2010 Workshop on Active Learning for Natural Language Processing; Saha, A., Rai, P., Daume, H., Venkatasubramanian, S., DuVall, S., Active supervised domain adaptation (2011) European Conference on Machine Learning (ECML); Yang, L., Hanneke, S., Carbonell, J., A theory of transfer learning with applications to active learning (2012) Machine Learning, 90 (2); Chattopadhyay, R., Fan, W., Davidson, I., Panchanathan, S., Ye, J., Joint transfer and batch mode active learning (2013) International Conference on Machine Learning (ICML); Kale, D., Liu, Y., Accelerating active learning with transfer learning (2013) IEEE International Conference on Data Mining (ICDM); Kale, D., Ghazvininejad, M., Ramakrishna, A., He, J., Liu, Y., Hierarchical active transfer learning (2015) SIAM Data Mining Conference (SDM); Zhao, L., Pan, S., Xiang, E., Zhong, E., Lu, Z., Yang, Q., Active transfer learning for cross-system recommendation (2013) Association for the Advancement of Artificial Intelligence (AAAI); Wang, X., Huang, T., Schneider, J., Active transfer learning under model shift (2014) International Conference on Machine Learning (ICML); Saenko, K., Kulis, B., Fritz, M., Darrell, T., Adapting visual category models to new domains (2010) European Conference on Computer Vision (ECCV); LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings OfIEEE},
sponsors={IEEE Computational Intelligence Society (CIS)},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728169262},
coden={85OFA},
language={English},
abbrev_source_title={Proc Int Jt Conf Neural Networks},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Xu20204057,
author={Xu, G. and Zhu, X. and Tapper, N.},
title={Using convolutional neural networks incorporating hierarchical active learning for target-searching in large-scale remote sensing images},
journal={International Journal of Remote Sensing},
year={2020},
volume={41},
number={11},
pages={4057-4079},
doi={10.1080/01431161.2020.1714774},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079059047&doi=10.1080%2f01431161.2020.1714774&partnerID=40&md5=867e86855e95006390a96e97bfcc82e2},
affiliation={School of Earth, Atmosphere and Environment, Monash University, Clayton, Australia; Cooperative Research Centre for Water Sensitive Cities, Melbourne, Australia},
abstract={Satellite images are important information sources of the earth environment. Automatic classification of satellite images has always been an important research topic. With the recent advancement of deep learning, the convolutional neural network (CNN) approach has shown great potential in object detection in high resolution images. However, insufficient labelled samples and constrained input image sizes have limited the wide application of CNN for remote sensing. In this study, the Hierarchical Active Learning (HAL) framework is proposed by incorporating transfer learning, tile map service (TMS), and active learning to enable effective scene classification with very few manually labelled samples. A case study of vehicle detection with HAL has been conducted and shows that HAL can achieve the accuracy of more than 80% with only 50 training samples for a large area. Moreover, its ability to extend to incorporation of different TMS image sources and CNN models makes it useful for various object detection tasks. © 2020, © 2020 Informa UK Limited, trading as Taylor & Francis Group.},
keywords={Convolution;  Deep learning;  Neural networks;  Object detection;  Object recognition, Automatic classification;  Convolutional neural network;  Earth environment;  High resolution image;  Information sources;  Remote sensing images;  Scene classification;  Transfer learning, Remote sensing, artificial neural network;  computer simulation;  detection method;  image classification;  machine learning;  numerical model;  remote sensing;  satellite data;  satellite imagery},
references={Alhichri, H., Othman, E., Zuair, M., Ammour, N., Bazi, Y., Tile-Based Semisupervised Classification of Large-Scale VHR Remote Sensing Images (2018) Journal of Sensors, 2018, pp. 1-14; Audebert, N., Le Saux, B., Lefèvre, S., Segment-before-detect: Vehicle Detection and Classification through Semantic Segmentation of Aerial Images (2017) Remote Sensing, 9 (4), p. 368; Aytekin, Ö., Zöngür, U., Halici, U., Texture-based Airport Runway Detection (2013) IEEE Geoscience and Remote Sensing Letters, 10 (3), pp. 471-475; Bazi, Y., Melgani, F., Semisupervised PSO-SVM Regression for Biophysical Parameter Estimation (2007) IEEE Transactions on Geoscience and Remote Sensing, 45 (6), pp. 1887-1895; Bazi, Y., Alajlan, N., Melgani, F., Improved Estimation of Water Chlorophyll Concentration with Semisupervised Gaussian Process Regression (2012) IEEE Transactions on Geoscience and Remote Sensing, 50 (7), pp. 2733-2743; Bejiga, M., Zeggada, A., Nouffidj, A., Melgani, F., A Convolutional Neural Network Approach for Assisting Avalanche Search and Rescue Operations with Uav Imagery (2017) Remote Sensing, 9 (2), p. 100; Bergado, J.R., Persello, C., Gevaert, C., A Deep Learning Approach to the Classification of Sub-decimetre Resolution Aerial Images (2016) Paper presented at the Geoscience and Remote Sensing Symposium (IGARSS), 2016 IEEE International, Beijing, China; Bhagavathy, S., Manjunath, B.S., Modeling and Detection of Geospatial Objects Using Texture Motifs (2006) IEEE Transactions on Geoscience and Remote Sensing, 44 (12), pp. 3706-3715; Bruzzone, L., Persello, C., Recent Trends in Classification of Remote Sensing Data: Active and Semisupervised Machine Learning Paradigms (2010) Paper presented at the Geoscience and Remote Sensing Symposium (IGARSS), 2010 IEEE International, Honolulu, HI; Caruana, R., Learning Many Related Tasks at the Same Time with Backpropagation (1995) In NIPS'94: Proceedings of the 7th International Conference on Neural Information Processing Systems, Denver, CO, pp. 657-664. , –,. Cambridge, MA: MIT Press; Castelluccio, M., Poggi, G., Sansone, C., Verdoliva, L., Land Use Classification in Remote Sensing Images by Convolutional Neural Networks (2015) arXiv preprint arXiv:1508.00092; Chen, X., Xiang, S., Liu, C.-L., Pan, C.-H., Vehicle Detection in Satellite Images by Hybrid Deep Convolutional Neural Networks (2014) IEEE Geoscience and Remote Sensing Letters, 11 (10), pp. 1797-1801; Chen, Y., Lin, Z., Zhao, X., Wang, G., Gu, Y., Deep Learning-based Classification of Hyperspectral Data (2014) IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 7 (6), pp. 2094-2107; Cheng, G., Ma, C., Zhou, P., Yao, X., Han, J., Scene Classification of High Resolution Remote Sensing Images Using Convolutional Neural Networks (2016) Paper presented at the 2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS), , July, 10–15, and,. Beijing, China; Cheng, G., Han, J., Guo, L., Liu, Z., Bu, S., Ren, J., Effective and Efficient Midlevel Visual Elements-oriented Land-use Classification Using VHR Remote Sensing Images (2015) IEEE Transactions on Geoscience and Remote Sensing, 53 (8), pp. 4238-4249; Cheng, G., Han, J., Zhou, P., Guo, L., Multi-class Geospatial Object Detection and Geographic Image Classification Based on Collection of Part Detectors (2014) ISPRS Journal of Photogrammetry and Remote Sensing, 98, pp. 119-132; Cheng, G., Han, J., Lu, X., Remote Sensing Image Scene Classification: Benchmark and State of the Art (2017) Proceedings of the IEEE, 105 (10), pp. 1865-1883; Cheng, G., Guo, L., Zhao, T., Han, J., Li, H., Fang, J., Automatic Landslide Detection from Remote-sensing Imagery Using a Scene Classification Method Based on BoVW and pLSA (2013) International Journal of Remote Sensing, 34 (1), pp. 45-59; Cheng, G., Zhou, P., Han, J., Learning Rotation-Invariant Convolutional Neural Networks for Object Detection in VHR Optical Remote Sensing Images (2016) IEEE Transactions on Geoscience and Remote Sensing, 54 (12), pp. 7405-7415; Cheriyadat, A.M., Unsupervised Feature Learning for Aerial Scene Classification (2014) IEEE Transactions on Geoscience and Remote Sensing, 52 (1), pp. 439-451; Cireşan, D., Meier, U., Schmidhuber, J., Multi-column Deep Neural Networks for Image Classification (2012) arXiv preprint arXiv:1202.2745; Crawford, M.M., Tuia, D., Yang, H.L., Active Learning: Any Value for Classification of Remotely Sensed Data? (2013) Proceedings of the IEEE, 101 (3), pp. 593-608; Cui, S., Dumitru, C.O., Datcu, M., Semantic Annotation in Earth Observation Based on Active Learning (2013) International Journal of Image and Data Fusion, 5 (2), pp. 1-23; Dalal, N., Triggs, B., (2005) Histograms of Oriented Gradients for Human Detection, pp. 886-893. , 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognitio, n, (CVPR05), , San Diego, CA. IEEE; Demir, B., Bovolo, F., Bruzzone, L., Detection of Land-cover Transitions in Multitemporal Remote Sensing Images with Active-learning-based Compound Classification (2012) IEEE Transactions on Geoscience and Remote Sensing, 50 (5), pp. 1930-1941; Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., Darrell, T., Decaf: A Deep Convolutional Activation Feature for Generic Visual Recognition (2014) Paper presented at the International conference on machine learning, Beijing, China; Ferecatu, M., Boujemaa, N., Interactive Remote-sensing Image Retrieval Using Active Relevance Feedback (2007) IEEE Transactions on Geoscience and Remote Sensing, 45 (4), pp. 818-826; (2018) GDAL - Geospatial Data Abstraction Library, Version 1.11.3, , http://www.gdal.org; Gianinetto, M., Rusmini, M., Candiani, G., Via, G.D., Frassy, F., Maianti, P., Marchesi, A., Dini, L., Hierarchical Classification of Complex Landscape with VHR Pan-sharpened Satellite Data and OBIA Techniques (2014) European Journal of Remote Sensing, 47 (1), pp. 229-250; Gong, X., Xie, Z., Liu, Y., Shi, X., Zheng, Z., Deep Salient Feature Based Anti-Noise Transfer Network for Scene Classification of Remote Sensing Imagery (2018) Remote Sensing, 10 (3), p. 410; Han, J., Zhang, D., Cheng, G., Guo, L., Ren, J., Object Detection in Optical Remote Sensing Images Based on Weakly Supervised Learning and High-level Feature Learning (2015) IEEE Transactions on Geoscience and Remote Sensing, 53 (6), pp. 3325-3337; Han, J., Zhou, P., Zhang, D., Cheng, G., Guo, L., Liu, Z., Bu, S., Wu, J., Efficient, Simultaneous Detection of Multi-class Geospatial Targets Based on Visual Saliency Modeling and Discriminative Learning of Sparse Coding (2014) ISPRS Journal of Photogrammetry and Remote Sensing, 89, pp. 37-48; Haralick, R.M., Shanmugam, K., Textural Features for Image Classification (1973) IEEE Transactions on Systems, Man, and Cybernetics, (6), pp. 610-621; Hinton, G.E., Salakhutdinov, R.R., Reducing the Dimensionality of Data with Neural Networks (2006) Science, 313 (5786), p. 504; Hu, F., Xia, G.-S., Hu, J., Zhang, L., Transferring Deep Convolutional Neural Networks for the Scene Classification of High-Resolution Remote Sensing Imagery (2015) Remote Sensing, 7 (11), p. 14680; Hu, J., Xia, G.-S., Hu, F., Sun, H., Zhang, L., A Comparative Study of Sampling Analysis in Scene Classification of High-resolution Remote Sensing Imagery (2015) Paper presented at the Geoscience and Remote Sensing Symposium (IGARSS), 2015 IEEE International, Milan, Italy; Jain, A.K., Ratha, N.K., Lakshmanan, S., Object Detection Using Gabor Filters (1997) Pattern Recognition, 30 (2), pp. 295-309; Jolliffe, I.T., Jolliffe, I.T., (2002) Principal Component Analysis, , 2nd, New York, NY: Springer, and, ed. Edited by; Kellenberger, B., Marcos, D., Tuia, D., Detecting Mammals in UAV Images: Best Practices to Address a Substantially Imbalanced Dataset with Deep Learning (2018) Remote Sensing of Environment, 216, pp. 139-153; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet Classification with Deep Convolutional Neural Networks (2012) Paper presented at the Advances in neural information processing systems, Lake Tahoe, NV; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based Learning Applied to Document Recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; LeCun, Y., Bengio, Y., Hinton, G., Deep Learning (2015) Nature, 521 (7553), p. 436; Lee, H., Grosse, R., Ranganath, R., Ng, A.Y., Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations (2009) Paper presented at the Proceedings of the 26th annual international conference on machine learning, Montreal, Canada; Lowe, D.G., Distinctive Image Features from Scale-invariant Keypoints (2004) International Journal of Computer Vision, 60 (2), pp. 91-110; Ma, C., Dai, Q., Liu, J., Liu, S., Yang, J., An Improved SVM Model for Relevance Feedback in Remote Sensing Image Retrieval (2014) International Journal of Digital Earth, 7 (9), pp. 725-745; Maggiori, E., Tarabalka, Y., Charpiat, G., Alliez, P., Convolutional Neural Networks for Large-scale Remote-sensing Image Classification (2017) IEEE Transactions on Geoscience and Remote Sensing, 55 (2), pp. 645-657; Marmanis, D., Datcu, M., Esch, T., Stilla, U., Deep Learning Earth Observation Classification Using ImageNet Pretrained Networks (2016) IEEE Geoscience and Remote Sensing Letters, 13 (1), pp. 105-109; Moranduzzo, T., Melgani, F., Mekhalfi, M.L., Bazi, Y., Alajlan, N., Multiclass Coarse Analysis for UAV Imagery (2015) IEEE Transactions on Geoscience and Remote Sensing, 53 (12), pp. 6394-6406; Moranduzzo, T., Mekhalfi, M.L., Melgani, F., LBP-based Multiclass Classification Method for UAV Imagery (2015) Paper presented at the Geoscience and Remote Sensing Symposium (IGARSS), 2015 IEEE International, Milan, Italy; Nogueira, K., Penatti, O.A.B., dos Santos, J.A., Towards Better Exploiting Convolutional Neural Networks for Remote Sensing Scene Classification (2017) Pattern Recognition, 61, pp. 539-556; Ogami, R., Yamamoto, H., Kato, T., Utsunomiya, E., Harmful Wildlife Detection System Utilizing Deep Learning for Radio Wave Sensing on Multiple Frequency Bands (2019) Paper presented at the 2019 International Conference on Artificial Intelligence in Information and Communication (ICAIIC), Okinawa, Japan; Ojala, T., Pietikainen, M., Maenpaa, T., Multiresolution Gray-scale and Rotation Invariant Texture Classification with Local Binary Patterns (2002) IEEE Transactions on Pattern Analysis and Machine Intelligence, 24 (7), pp. 971-987; Oliva, A., Torralba, A., Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope (2001) International Journal of Computer Vision, 42 (3), pp. 145-175; Olshausen, B.A., Field, D.J., Sparse Coding with an Overcomplete Basis Set: A Strategy Employed by V1? (1997) Vision Research, 37 (23), pp. 3311-3325; Penatti, O.A.B., Nogueira, K., dos Santos, J.A., Do Deep Features Generalize from Everyday Objects to Remote Sensing and Aerial Scenes Domains? (2015) Paper presented at the 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), , June, 7–12, and,. Boston, MA; Popescu, A.A., Gavat, I., Datcu, M., Contextual Descriptors for Scene Classes in Very High Resolution SAR Images (2012) IEEE Geoscience and Remote Sensing Letters, 9 (1), pp. 80-84; Redmon, J., Divvala, S., Girshick, R., Farhadi, A., You Only Look Once: Unified, Real-time Object Detection (2016) Paper presented at the Proceedings of the IEEE conference on computer vision and pattern recognition, Las Vegas, NV; Ren, S., He, K., Girshick, R., Sun, J., Faster R-cnn: Towards Real-time Object Detection with Region Proposal Networks (2015) Paper presented at the Advances in neural information processing systems, Montreal, Canada; Rottensteiner, F., Sohn, G., Jung, J., Gerke, M., Baillard, C., Benitez, S., Breitkopf, U., The Isprs Benchmark on Urban Object Classification and 3D Building Reconstruction (2012) ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, 1, pp. 293-298; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., Imagenet Large Scale Visual Recognition Challenge (2015) International Journal of Computer Vision, 115 (3), pp. 211-252; Sermanet, P., Eigen, D., Zhang, X., Mathieu, M., Fergus, R., LeCun, Y., Overfeat: Integrated Recognition, Localization and Detection Using Convolutional Networks (2013) arXiv preprint arXiv:1312.6229; Swain, M.J., Ballard, D.H., Color Indexing (1991) International Journal of Computer Vision, 7 (1), pp. 11-32; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the Inception Architecture for Computer Vision (2016) Paper presented at the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, NV; Tao, C., Tan, Y., Cai, H., Tian, J., Airport Detection from Large IKONOS Images Using Clustered SIFT Keypoints and Region Information (2011) IEEE Geoscience and Remote Sensing Letters, 8 (1), pp. 128-132; Tokarczyk, P., Wegner, J.D., Walk, S., Schindler, K., Features, Color Spaces, and Boosting: New Insights on Semantic Classification of Remote Sensing Images (2015) IEEE Transactions on Geoscience and Remote Sensing, 53 (1), pp. 280-295; Torney, C.J., Lloyd-Jones, D.J., Chevallier, M., Moyer, D.C., Maliti, H.T., Mwita, M., Kohi, E.M., Hopcraft, G.C., A Comparison of Deep Learning and Citizen Science Techniques for Counting Wildlife in Aerial Survey Images (2019) Methods in Ecology and Evolution, 10 (6), pp. 779-787; Tuia, D., Ratle, F., Pacifici, F., Kanevski, M.F., Emery, W.J., Active Learning Methods for Remote Sensing Image Classification (2009) IEEE Transactions on Geoscience and Remote Sensing, 47 (7), pp. 2218-2232; Tuia, D., Muñoz-Marí, J., Camps-Valls, G., Remote Sensing Image Segmentation by Active Queries (2012) Pattern Recognition, 45 (6), pp. 2180-2192; Vakalopoulou, M., Karantzalos, K., Komodakis, N., Paragios, N., Building Detection in Very High Resolution Multispectral Data with Deep Learning Features (2015) Paper presented at the Geoscience and Remote Sensing Symposium (IGARSS), 2015 IEEE International, Milan, Italy; Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., Manzagol, P.-A., Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion (2010) Journal of Machine Learning Research, 11 (Dec), pp. 3371-3408; Wang, Z., Nasrabadi, N.M., Huang, T.S., Semisupervised Hyperspectral Classification Using Task-driven Dictionary Learning with Laplacian Regularization (2015) IEEE Transactions on Geoscience and Remote Sensing, 53 (3), pp. 1161-1173; Yang, Y., Newsam, S., Geographic Image Retrieval Using Local Invariant Features (2013) IEEE Transactions on Geoscience and Remote Sensing, 51 (2), pp. 818-832; Yao, X., Han, J., Cheng, G., Qian, X., Guo, L., Semantic Annotation of High-resolution Satellite Images via Weakly Supervised Learning (2016) IEEE Transactions on Geoscience and Remote Sensing, 54 (6), pp. 3660-3671; Yao, X., Han, J., Guo, L., Bu, S., Liu, Z., A Coarse-to-fine Model for Airport Detection from Remote Sensing Images Using Target-oriented Visual Saliency and CRF (2015) Neurocomputing, 164, pp. 162-172; Yin, X., Yang, W., Xia, G.-S., Dong, L., Semi-supervised Feature Learning for Remote Sensing Image Classification (2014) Paper presented at the Geoscience and Remote Sensing Symposium (IGARSS), 2014 IEEE International, Quebec City, Canada; Yong, S.-P., Yeong, Y.-C., Human Object Detection in Forest with Deep Learning Based on Drone’s Vision (2018) Paper presented at the 2018 4th International Conference on Computer and Information Sciences (ICCOINS), Kuala Lumpur, Malaysia; Zhang, F., Du, B., Zhang, L., Saliency-guided Unsupervised Feature Learning for Scene Classification (2015) IEEE Transactions on Geoscience and Remote Sensing, 53 (4), pp. 2175-2184; Zhang, Y., Zheng, X., Liu, G., Sun, X., Wang, H., Fu, K., Semi-supervised Manifold Learning Based Multigraph Fusion for High-resolution Remote Sensing Image Classification (2014) IEEE Geoscience and Remote Sensing Letters, 11 (2), pp. 464-468; Zhao, W., Du, S., Learning Multiscale and Deep Representations for Classifying Remotely Sensed Imagery (2016) ISPRS Journal of Photogrammetry and Remote Sensing, 113, pp. 155-165; Zhao, W., Du, S., Scene Classification Using Multi-scale Deeply Described Visual Words (2016) International Journal of Remote Sensing, 37 (17), pp. 4119-4131; Zhong, Y., Fei, F., Zhang, L., Large Patch Convolutional Neural Networks for the Scene Classification of High Spatial Resolution Imagery (2016) Journal of Applied Remote Sensing, 10 (2), p. 025006; Zou, Q., Ni, L., Zhang, T., Wang, Q., Deep Learning Based Feature Selection for Remote Sensing Scene Classification (2015) IEEE Geoscience and Remote Sensing Letters, 12 (11), pp. 2321-2325},
correspondence_address1={Xu, G.; School of Earth, Australia; email: xg1990@gmail.com},
publisher={Taylor and Francis Ltd.},
issn={01431161},
coden={IJSED},
language={English},
abbrev_source_title={Int. J. Remote Sens.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Shi2020,
author={Shi, H. and Wang, H. and Qin, C. and Zhao, L. and Liu, C.},
title={An incremental learning system for atrial fibrillation detection based on transfer learning and active learning},
journal={Computer Methods and Programs in Biomedicine},
year={2020},
volume={187},
doi={10.1016/j.cmpb.2019.105219},
art_number={105219},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075581200&doi=10.1016%2fj.cmpb.2019.105219&partnerID=40&md5=57b32d499b7dd9c1e6b360badfe0f330},
affiliation={School of Mechanical Engineering, Shanghai Jiao Tong University, 800 Dongchuan Road, Shanghai, 200240, China; Department of Cardiology, Shanghai First People's Hospital Affiliated to Shanghai Jiao Tong University, 100, Haining Road, Shanghai, 200080, China},
abstract={Background and objective: Atrial fibrillation (AF) is a type of arrhythmia with high incidence. Automatic AF detection methods have been studied in previous works. However, a model cannot be used all the time without any improvement. And updating model requires adequate data and cost. Therefore, this study aims at finding a low-cost way to choose learning samples and developing an incremental learning system for AF detection. Methods: Based on transfer learning and active learning, this paper proposed a loop-locked framework integrating AF diagnose, label query, and model fine-tuning. In the pre-training stage, a novel multiple-input deep neural network (MIDNN) is pre-trained using labeled samples from an original training set. In practical application, the model can be used for AF detection. Meanwhile, continuous data is collected to form the candidate set. In the incremental learning stage, the model was fine-tuned continuously by the most informative samples in the candidate set. These samples are selected from the candidate set based on the pre-trained model and a new active learning strategy. The strategy combines the features and the uncertainty of the predicted results. Results: In order to evaluate the method, the MIT-BIH atrial fibrillation database was used for pre-training and samples of the MIT-BIH arrhythmia database were taken as candidate set. The initial values of Acc, Sen, and PPV were 87.40%, 97.46%, and 81.11%. These indexes reached to the top values of 97.53%, 100.00%, and 95.29% after 14 iterations. Hence, the number of queries was saved by 90.67%. Conclusions: The proposed system is able to update the model continuously and reduce the labeling cost over 90%. The comparisons demonstrated the effectiveness of MIDNN model and the suitability of novel learning strategy for AF. Moreover, this framework can be extended to other biomedical applications. © 2019},
author_keywords={Active learning;  Atrial fibrillation;  Deep neural network;  Electrocardiogram (ECG);  Transfer learning},
keywords={Artificial intelligence;  Diseases;  Electrocardiography;  Medical applications;  Query processing, Active Learning;  Active learning strategies;  Atrial fibrillation;  Biomedical applications;  Detection methods;  Incremental learning;  Learning strategy;  Transfer learning, Deep neural networks, active learning;  Article;  atrial fibrillation;  controlled study;  convolutional neural network;  data base;  detection algorithm;  diagnostic accuracy;  health care cost;  human;  incremental learning;  learning;  learning algorithm;  long short term memory network;  predictive value;  sensitivity and specificity;  transfer of learning;  algorithm;  atrial fibrillation;  cardiology;  computer assisted diagnosis;  diagnostic imaging;  electrocardiography;  factual database;  machine learning;  problem based learning;  signal processing;  software, Algorithms;  Atrial Fibrillation;  Cardiology;  Databases, Factual;  Diagnosis, Computer-Assisted;  Electrocardiography;  Humans;  Machine Learning;  Neural Networks, Computer;  Problem-Based Learning;  Signal Processing, Computer-Assisted;  Software},
funding_details={National Key Research and Development Program of ChinaNational Key Research and Development Program of China, NKRDPC, SQ2018YFB130700},
funding_text 1={This work was supported by the National Key R&D Program of China (No. SQ2018YFB130700).},
funding_text 2={This work was supported by the National Key R&D Program of China (No. SQ2018YFB130700 ) .},
references={World Health Organization, (2017), http://www.who.int/mediacentre/factsheets/fs317/en/, Cardiovascular Diseases (CVDs); Zoni-Berisso, M., Lercari, F., Carazza, T., Domenicucci, S., Epidemiology of atrial fibrillation: European perspective (2014) Clin. Epidemiol., 6, pp. 213-220; Petrėnas, A., Sörnmo, L., Lukoševicius, A., Marozas, V., Detection of occult paroxysmal atrial fibrillation (2015) Med. Biol. Eng. Comput., 53, pp. 287-297; Pasolli, E., Melgani, F., Active learning methods for electrocardiographic signal classification (2010) IEEE Trans. Inf. Technol. Biomed., 14, pp. 1405-1416; Zhou, Z., Shin, J., Zhang, L., Gurudu, S., Gotway, M., Liang, J., Fine-tuning convolutional neural networks for biomedical image analysis: actively and incrementally (2017) IEEE Conference on Computer Vision and Pattern Recognition, pp. 7340-7351; Xia, Y., Xie, Y., A novel wearable electrocardiogram classification system using convolutional neural networks and active learning (2019) IEEE Access, 7, pp. 7989-8001; Oquab, M., Bottou, L., Laptev, I., Sivic, J., Learning and transferring mid-level image representations using convolutional neural networks (2014) IEEE Conference on Computer Vision and Pattern Recognition; Hagiwara, Y., Fujita, H., Oh, S.L., Tan, J.H., Tan, R.S., Ciaccio, E.J., Acharya, U.R., Computer-aided diagnosis of atrial fibrillation based on ECG Signals: a review (2018) Inf. Sci., 467, pp. 99-114; Dash, S., Chou, K.H., Lu, S., Raeder, E.A., Automatic real time detection of atrial fibrillation (2009) Ann. Biomed. Eng., 37, pp. 1701-1709; Zhou, X., Ding, H., Ung, B., Pickwell-MacPherson, E., Zhang, Y., Automatic online detection of atrial fibrillation based on symbolic dynamics and Shannon entropy (2014) Biomed. Eng. Online, 13, p. 18; Petrenas, A., Marozas, V., Jarusevicius, G., Sornmo, L., A modified Lewis ECG lead system for ambulatory monitoring of atrial arrhythmias (2015) J. Electrocardiol., 48, pp. 157-163; Garcia, M., Rodenas, J., Alcaraz, R., Rieta, J.J., Application of the relative wavelet energy to heart rate independent detection of atrial fibrillation (2016) Comput. Methods Programs Biomed., 131, pp. 157-168; Martis, R.J., Acharya, U.R., Prasad, H., Chua, C.K., Lim, C.M., Suri, J.S., Application of higher order statistics for atrial arrhythmia classification (2013) Biomed. Signal Process. Control, 8, pp. 888-900; Martis, R.J., Acharya, U.R., Adeli, H., Prasad, H., Tan, J.H., Chua, K.C., Computer aided diagnosis of atrial arrhythmia using dimensionality reduction methods on transform domain representation (2014) Biomed. Signal Process. Control, 13, pp. 295-305; Ladavich, S., Ghoraani, B., Rate-independent detection of atrial fibrillation by statistical modeling of atrial activity (2015) Biomed. Signal Process. Control, 18, pp. 274-281; Goodfellow, S.D., Goodwin, A., Greer, R., Laussen, P.C., Mazwi, M., Eytan, D., Classification of atrial fibrillation using multidisciplinary features and gradient boosting (2017) Computing in Cardiology Conference, pp. 1-4; Chetan, A., Tripathy, R.K., Dandapat, S., A diagnostic system for detection of atrial and ventricular arrhythmia episodes from electrocardiogram (2018) J. Med. Biol. Eng., 38, pp. 304-315; Faust, O., Hagiwara, Y., Hong, T.J., Lih, O.S., Acharya, U.R., Deep learning for healthcare applications based on physiological signals: a review (2018) Comput. Methods Programs Biomed., 161, pp. 1-13; Acharya, U.R., Fujita, H., Lih, O.S., Adam, M., Tan, J.H., Chua, C.K., Automated detection of coronary artery disease using different durations of ECG segments with convolutional neural network (2017) Knowl.-Based Syst., 132, pp. 62-71; Hannun, A.Y., Rajpurkar, P., Haghpanahi, M., Tison, G.H., Bourn, C., Turakhia, M.P., Ng, A.Y., Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep neural network (2019) Nat. Med., 25, pp. 65-69; Yildirim, O., Baloglu, U.B., Tan, R., Ciaccio, E.J., Acharya, U.R., A new approach for arrhythmia classification using deep coded features and LSTM networks (2019) Comput. Methods Programs Biomed., 176, pp. 121-133; Mathews, S.M., Kambhamettu, C., Barner, K.E., A novel application of deep learning for single-lead ECG classification (2018) Comput. Biol. Med., 99, pp. 53-62; Yildirim, O., Tan, R.S., Acharya, U.R., An efficient compression of ECG signals using deep convolutional autoencoders (2018) Cognit. Syst. Res., 52, pp. 198-211; Acharya, U.R., Fujita, H., Lih, O.S., Hagiwara, Y., Tan, J.H., Adam, M., Automated detection of arrhythmias using different intervals of tachycardia ECG segments with convolutional neural network (2017) Inf. Sci., 415-416, pp. 190-198; Pyakillya, B., Kazachenko, N., Mikhailovsky, N., Deep learning for ECG classification (2017) J. Phys., p. 913; Pourbabaee, B., Roshtkhari, M.J., Khorasani, K., Deep Convolutional neural networks and learning ECG features for screening paroxysmal atrial fibrillation patients (2018) IEEE Trans. Syst. Man Cybern, 48, pp. 2095-2104; Xia, Y., Wulan, N., Wang, K., Zhang, H., Detecting atrial fibrillation by deep convolutional neural networks (2018) Comput. Biol. Med., 93, pp. 84-92; He, R., Wang, K., Zhao, N., Liu, Y., Yuan, Y., Li, Q., Zhang, H., Automatic detection of atrial fibrillation based on continuous wavelet transform and 2d convolutional neural networks (2018) Front. Physiol., 9, p. 11; Fausta, O., Shenfielda, A., Kareema, M., Sanb, T.R., Fujitac, H., Acharya, U.R., Automated detection of atrial fibrillation using long short-term memory network with RR interval signals (2018) Comput. Biol. Med., 102, pp. 327-335; Andersen, R.S., Peimankar, A., Puthusserypady, S., A deep learning approach for real-time detection of atrial fibrillation (2019) Expert Syst. Appl., 115, pp. 465-473; Yao, Z., Zhu, Z., Chen, Z., Atrial fibrillation detection by multi-scale convolutional neural networks (2017) Proceedings of the International Conference on Information Fusio, Xi'an, China; Annavarapu, A., Kora, P., ECG-based atrial fibrillation detection using different orderings of conjugate symmetric-complex Hadamard transform (2016) Int. J. Cardiovas. Acad., 2, pp. 151-154; Sun, S., Ping, Z., Xiao, H., Wang, R., An MRF model-based active learning framework for the spectral-spatial classification of hyperspectral imagery (2015) IEEE J. Sel. Top. Signal Process., 9, pp. 1074-1088; Gosselin, P.H., Cord, M., Active learning methods for interactive image retrieval (2008) IEEE Trans. Image Process., 17, pp. 1200-1211; Luo, T., Kramer, K., Goldgof, D.B., Active learning to recognize multiple types of plankton (2005) J. Mach. Learn. Res., 6, pp. 589-613; Seung, H.S., Opper, M., Sompolinski, H., Query by committee (1992) Proc. Annu. Workshop Comput. Learn. Theory, pp. 287-294; Wang, D., Shang, Y., A new active labeling method for deep learning (2014) International Joint Conference on Neural Networks, pp. 112-119; Bressan, R.S., Camargo, G., Bugatti, P.H., Saito, P.T.M., Exploring active learning based on representativeness and uncertainty for biomedical data classification (2018) IEEE J. Biomed. Health – Spec. Issue; Chen, H., Ni, D., Qin, J., Li, S., Yang, X., Wang, T., Heng, P.A., Standard plane localization in fetal ultrasound via domain transferred deep neural networks (2015) IEEE J. Biomed. Health, 19, pp. 1627-1636; Nishio, M., Sugiyama, O., Yakami, M., Ueno, S., Kubo, T., Kuroda, T., Togashi, K., Computer-aided diagnosis of lung nodule classification between benign nodule, primary lung cancer, and metastatic lung cancer at different image size using deep convolutional neural network with transfer learning (2018) PLoS One, 13 (7), p. 12; Talo, M., Baloglu, U.B., Yilirima, O., Acharya, U.R., Application of deep transfer learning for automated brain abnormality classification using MR images (2019) Cognit. Syst. Res., 54, pp. 176-188; Wang, G., Zhang, C., Liu, Y., Yang, H., Fu, D., W, H., Zhang, P., A global and updatable ECG beat classification system based on recurrent neural networks and active learning (2019) Inf. Sci., 501, pp. 523-542; Wiens, J., Guttag, J.V., Patient-adaptive ectopic beat classification using active learning (2010) Computing in Cardiology Conference, pp. 109-112; Bashir, M.E.A., Shon, H.S., Lee, D.G., Kim, H., Ryu, K.H., Real-time automated cardiac health monitoring by combination of active learning and adaptive feature selection (2013) KSII Trans. Internet Inf., 7, pp. 99-118; Sayantan, G., Kien, P.T., Kadambari, K.V., Classification of ECG beats using deep belief network and active learning (2018) Med. Biol. Eng. Comput., 56, pp. 1887-1898; Goldberger, A.L., Amaral, L.A.N., Glass, L., Hausdorff, J.M., Ivanov, P.C., Mark, R.G., Mietus, J.E., Stanley, H.E., Physiobank, physiotoolkit, and physionet: components of a new research resource for complex physi- ologic signals (2000) Circulation, 101, pp. 215-220. , http://www.physionet.org/, database and tools available at:; Pan, J., Tompkins, W.J., A real-time QRS detection algorithm (1985) IEEE Trans.Biomed. Eng., 32 (3), pp. 230-236; Fukushima, K., (1980), Neocognitron: a self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position, Biol. Cybern.36 193–202, doi: 10.1007/bf00344251; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput., 9, pp. 1735-1780; Acharya, U.R., Fujita, H., Adam, M., Oh, S.L., Tan, J.H., Sudarshan, V.K., Koh, J.E.W., Automated characterization of arrhythmias using nonlinear features from tachycardia ECG beats (2016) Proceedings of the IEEE International Conference on Systems, Man, and Cybernetics, Budapest, Hungary; Tripathy, R.K., Paternina, M.R.A., Arrieta, J.G., Pattanaik, P., Automated detection of atrial fibrillation ECG signals using two stage VMD and atrial fibrillation diagnosis index (2017) J. Mech. Med. Biol., 17 (7). , (20 pages); Al Rahhal, M.M., Bazi, Y., AlHichri, H., Alajlan, N., Melgani, F., Yager, R.R., Deep learning approach for active classification of electrocardiogram signals (2016) Inf. Sci., 345, pp. 340-354},
correspondence_address1={Liu, C.; School of Mechanical Engineering, 800 Dongchuan Road, China; email: chlliu@sjtu.edu.cn},
publisher={Elsevier Ireland Ltd},
issn={01692607},
coden={CMPBE},
pubmed_id={31786450},
language={English},
abbrev_source_title={Comput. Methods Programs Biomed.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Weidner2020,
author={Weidner, L. and Walton, G. and Kromer, R.},
title={Generalization considerations and solutions for point cloud hillslope classifiers},
journal={Geomorphology},
year={2020},
volume={354},
doi={10.1016/j.geomorph.2020.107039},
art_number={107039},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077919094&doi=10.1016%2fj.geomorph.2020.107039&partnerID=40&md5=d46d20aa106baf8c869298420a83d4d2},
affiliation={Colorado School of Mines, 1500 Illinois Street, Golden, CO  48640, United States},
abstract={Point cloud classifiers have the potential to rapidly perform landscape characterization for a variety of applications. The generalization (i.e., transferability to new sites) of such classifiers could improve their accessibility and usefulness for both engineers and researchers alike, but guidelines for classifier generalization are lacking in the literature. This study develops and applies a Random Forest machine learning classifier for Terrestrial Laser Scanning (TLS) point clouds, and generalizes the classifier to point clouds from several different locations. The classifier is trained to identify basic hillslope topographic features, including vegetation, soil, talus, and bedrock using multi-scale geometric features of the point cloud. Four rock and soil slopes in western Colorado were scanned using TLS. Generalization experiments were performed testing point density, occlusion, and between-site domain variance factors, and all factors showed a significant influence on generalization accuracy. Several methods for improving classifier generalization accuracy were tested and compared, including combining training data from multiple sites, imposing probability thresholds, and a Domain Adaptation methodology known as Active Learning. It was found that incorporating data from multiple sites resulted in improved generalization accuracy, but in most cases the largest improvements in accuracy were associated with adding new training data from the target site. In this case, using Active Learning resulted in significant accuracy improvements with an over 90% reduction in the number of added training points. The results suggest that scanning characteristics are important factors in classifier generalization accuracy, but their effects can be mitigated by using the techniques described herein. © 2020 Elsevier B.V.},
author_keywords={Classification;  Domain adaptation;  Machine learning;  Point cloud},
keywords={accuracy assessment;  ground-based measurement;  hillslope;  image classification;  literature review;  machine learning;  remote sensing;  slope dynamics;  topographic mapping, Colorado;  United States},
funding_details={Colorado Department of TransportationColorado Department of Transportation, CDOT},
funding_text 1={We would like to acknowledge the Colorado Department of Transportation for funding the data collection for this project. We would also like to thank all those who have assisted in data collection field trips for this work, including Michelle Mullane, Amber Hill, Caroline Lefeuvre, Heather Schovanec, and Brian Gray.},
references={Abellán, A., Oppikofer, T., Jaboyedoff, M., Rosser, N.J., Lim, M., Lato, M.J., Terrestrial laser scanning of rock slope instabilities (2014) Earth Surf. Process. Landf., 39, pp. 80-97; Becker, C., Rosinskaya, E., Häni, N., D'Angelo, E., Strecha, C., Classification of aerial photogrammetric 3D point clouds (2018) Photogramm. Eng. Remote. Sens., 84, pp. 287-295; Beretta, F., Rodrigues, A.L., Peroni, R.L., Costa, J.F.C.L., Automated lithological classification using UAV and machine learning on an open cast mine (2019) Appl. Earth Sci., 128, pp. 79-88; Bond, C.E., Shipton, Z.K., Jones, R.R., Butler, R.W.H., Gibbs, A.D., Knowledge transfer in a digital world: field data acquisition, uncertainty, visualization, and data management (2007) Geosphere, 3, pp. 568-576; Bonneau, D.A., Hutchinson, D.J., The use of terrestrial laser scanning for the characterization of a cliff-talus system in the Thompson River Valley, British Columbia, Canada (2019) Geomorphology, 327, pp. 598-609; Brodu, N., Lague, D., 3D terrestrial lidar data classification of complex natural scenes using a multi-scale dimensionality criterion: applications in geomorphology (2012) ISPRS J. Photogramm. Remote Sens., 68, pp. 121-134; Carter, R., (2018) Identifying Rockfall Hazards in the Fraser Canyon, British Columbia: A Semi-automated Approach to the Classification and Assessment of Topographic Information From Airborne LiDAR and Orthoimagery, , MSc Thesis Queen's University Kingston, Ontario, Canada; Crawford, M.M., Tuia, D., Yang, H.L., Active learning: any value for classification of remotely sensed data? (2013) Proceedings of the IEEE 2013, 101, pp. 593-608; Cruden, D.M., Varnes, D.J., Landslides: investigation and mitigation. Chapter 3 - landslide types and processes (1996) Transportation Research Board Special Report, 247, pp. 36-75. , https://trid.trb.org/view/462501; Dunham, L., Wartman, J., Olsen, M.J., O'Banion, M., Cunningham, K., Rockfall Activity Index (RAI): a lidar-derived, morphology-based method for hazard assessment (2017) Eng. Geol., 221, pp. 184-192; Eitel, J.U.H., Höfle, B., Vierling, L.A., Abellán, A., Asner, G.P., Deems, J.S., Glennie, C.L., Vierling, K.T., Beyond 3-D: the new spectrum of lidar applications for earth and ecological sciences (2016) Remote Sens. Environ., 186, pp. 372-392; Eltner, A., Baumgart, P., Accuracy constraints of terrestrial lidar data for soil erosion measurement: application to a Mediterranean field plot (2015) Geomorphology, 245, pp. 243-254; Fernandez-Delgado, M., Cernadas, E., Barro, S., Amorim, D., Do we need hundreds of classifiers to solve real world classification problems? (2014) J. Mach. Learn. Res., 15, pp. 3133-3181. , http://jmlr.org/papers/v15/delgado14a.html; Girardeau-Montaut, D., CloudCompare 3D Point Cloud and Mesh Processing Software (Version 2.10) (2018), http://www.cloudcompare.org/, GPL software; Jaboyedoff, M., Oppikofer, T., Abellán, A., Derron, M.-H., Loye, A., Metzger, R., Pedrazzini, A., Use of LIDAR in landslide investigations: a review (2012) Nat. Hazards, 61, pp. 5-28; Kirkham, R.M., Streufert, R.K., Cappa, J.A., Shaw, C.A., Allen, J.L., Schroeder, T.J.I., Geologic Map of the Glenwood Springs Quadrangle, Garfield County, Colorado. MS-38. Scale 1:24,000 (2009), Colorado Geological Survey; Kromer, R., Walton, G., Gray, B., Lato, M., Group, R, Development and optimization of an automated fixed-location time lapse photogrammetric rock slope monitoring system (2019) Remote Sens., 11, p. 1890; Kromer, R.A., Abellan, A., Hutchinson, D.J., Lato, M., Chanut, M.-A., Dubois, L., Jaboyedoff, M., Automated terrestrial laser scanning with near real-time change detection - monitoring of the Séchilienne landslide (2017) Earth Surface Dynamics Discussions, pp. 1-33; Lan, H., Martin, C.D., Zhou, C., Lim, C.H., Rockfall hazard analysis using LiDAR and spatial modeling (2010) Geomorphology, 118, pp. 213-223; Lary, D.J., Alavi, A.H., Gandomi, A.H., Walker, A.L., Machine learning in geosciences and remote sensing (2016) Geoscience Frontiers, Special Issue: Progress of Machine Learning in Geosciences, 7, pp. 3-10; Lato, M.J., Vöge, M., Automated mapping of rock discontinuities in 3D lidar and photogrammetry models (2012) Int. J. Rock Mech. Min. Sci., 54, pp. 150-158; Lin, C.-H., Chen, J.-Y., Su, P.-L., Chen, C.-H., Eigen-feature analysis of weighted covariance matrices for LiDAR point cloud classification (2014) ISPRS J. Photogramm. Remote Sens., 94, pp. 70-79; Maiora, J., Ayerdi, B., Graña, M., Random forest active learning for AAA thrombus segmentation in computed tomography angiography images (2014) Neurocomputing, Recent Trends in Intelligent Data Analysis, 126, pp. 71-77; Mayr, A., Rutzinger, M., Bremer, M., Elberink, S.O., Stumpf, F., Geitner, C., Object-based classification of terrestrial laser scanning point clouds for landslide monitoring (2017) Photogramm. Rec., 32, pp. 377-397; Mejía-Navarro, M., Wohl, E.E., Oaks, S.D., Geological hazards, vulnerability, and risk assessment using GIS: model for Glenwood Springs, Colorado (1994) Geomorphology, 10, pp. 331-354; Mills, G., Numerical Tools for Interpreting Rock Surface Roughness (2015), https://qspace.library.queensu.ca/handle/1974/13097, PhD Thesis Queen's University Kingston, Ontario, Canada; Mills, G., Fotopoulos, G., Rock surface classification in a mine drift using multiscale geometric features (2015) IEEE Geosci. Remote Sens. Lett., 12, pp. 1322-1326; Pan, S.J., Yang, Q., A survey on transfer learning (2010) IEEE Trans. Knowl. Data Eng., 22, pp. 1345-1359; Qi, C.R., Su, H., Mo, K., Guibas, L.J., PointNet: deep learning on point sets for 3D classification and segmentation (2017) The IEEE Conference on Computer Vision and Pattern Recognition, pp. 652-660; Reichenbach, P., Rossi, M., Malamud, B.D., Mihir, M., Guzzetti, F., A review of statistically-based landslide susceptibility models (2018) Earth Sci. Rev., 180, pp. 60-91; Tarolli, P., High-resolution topography for understanding Earth surface processes: opportunities and challenges (2014) Geomorphology, 216, pp. 295-312; Telling, J., Lyda, A., Hartzell, P., Glennie, C., Review of Earth science research using terrestrial laser scanning (2017) Earth Sci. Rev., 169, pp. 35-68; Tuia, D., Persello, C., Bruzzone, L., Domain adaptation for the classification of remote sensing data: an overview of recent advances (2016) IEEE Geosci. Remote Sens. Mag., 4, pp. 41-57; Van Den Eeckhaut, M., Kerle, N., Poesen, J., Hervás, J., Object-oriented identification of forested landslides with derivatives of single pulse LiDAR data (2012) Geomorphology, 173-174, pp. 30-42; van Veen, M., Hutchinson, D.J., Kromer, R., Lato, M., Edwards, T., Effects of sampling interval on the frequency - magnitude relationship of rockfalls detected from terrestrial laser scanning using semi-automated methods (2017) Landslides, 14, pp. 1579-1592; Wagner, W., Lague, D., Mohrig, D., Passalacqua, P., Shaw, J., Moffett, K., Elevation change and stability on a prograding delta (2017) Geophys. Res. Lett., 44, pp. 1786-1794; Walton, G., Mills, G., Fotopoulos, G., Radovanovic, R., Stancliffe, R.P.W., An approach for automated lithological classification of point clouds (2016) Geosphere, 12, pp. 1833-1841; Walton, G., Fotopoulos, G., Radovanovic, R., Extraction and comparison of spatial statistics for geometric parameters of sedimentary layers from static and mobile terrestrial laser scanning data (2019) Environ. Eng. Geosci., 25, pp. 155-168; Wang, Z., Zhang, L., Fang, T., Mathiopoulos, P.T., Tong, X., Qu, H., Xiao, Z., Chen, D., A multiscale and hierarchical feature extraction method for terrestrial laser scanning point cloud classification (2015) IEEE Trans. Geosci. Remote Sens., 53, pp. 2409-2425; Weidner, L., DePrekel, K., Oommen, T., Vitton, S., Investigating large landslides along a river valley using combined physical, statistical, and hydrologic modeling (2019) Eng. Geol., 259, pp. 1-12; Weidner, L., Walton, G., Kromer, R., Classification methods for point clouds in rock slope monitoring: a novel machine learning approach and comparative analysis (2019) Eng. Geol., 263, p. 105326; Weinmann, M., Jutzi, B., Hinz, S., Mallet, C., Semantic point cloud interpretation based on optimal neighborhoods, relevant features and efficient classifiers (2015) ISPRS J. Photogramm. Remote Sens., 105, pp. 286-304; Westoby, M.J., Brasington, J., Glasser, N.F., Hambrey, M.J., Reynolds, J.M., ‘Structure-from-motion’ photogrammetry: a low-cost, effective tool for geoscience applications (2012) Geomorphology, 179, pp. 300-314; White, J.L., The Debeque Canyon landslide at Interstate 70, Mesa County, West-central Colorado (2005) 2005 Rocky Mountain Section, Geological Society of America, Field Trip Guidebook, pp. 1-8},
correspondence_address1={Weidner, L.; Colorado School of Mines, 1500 Illinois Street, United States; email: weidner@mines.edu},
publisher={Elsevier B.V.},
issn={0169555X},
language={English},
abbrev_source_title={Geomorphology},
document_type={Article},
source={Scopus},
}

@ARTICLE{Qian2020819,
author={Qian, P. and Chen, Y. and Kuo, J.-W. and Zhang, Y.-D. and Jiang, Y. and Zhao, K. and Al Helo, R. and Friel, H. and Baydoun, A. and Zhou, F. and Heo, J.U. and Avril, N. and Herrmann, K. and Ellis, R. and Traughber, B. and Jones, R.S. and Wang, S. and Su, K.-H. and Muzic, R.F.},
title={MDixon-Based Synthetic CT Generation for PET Attenuation Correction on Abdomen and Pelvis Jointly Using Transfer Fuzzy Clustering and Active Learning-Based Classification},
journal={IEEE Transactions on Medical Imaging},
year={2020},
volume={39},
number={4},
pages={819-832},
doi={10.1109/TMI.2019.2935916},
art_number={8804223},
note={cited By 25},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075776948&doi=10.1109%2fTMI.2019.2935916&partnerID=40&md5=64a01e242bd65fc9f28a79e639e1cb66},
affiliation={School of Digital Media, Jiangnan University, Wuxi, China; Case Center for Imaging Research, Case Western Reserve University, Cleveland, OH, United States; Department of Informatics, University of Leicester, Leicester, United Kingdom; Philips Healthcare, Cleveland, OH, United States; Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH, United States; Department of Radiology, University Hospitals Cleveland Medical Center, Cleveland, OH, United States; Department of Radiation Oncology, University Hospitals Cleveland Medical Center, Cleveland, OH, United States; Department of Radiation Oncology, Case Western Reserve University, Cleveland, OH, United States; Department of Radiation Oncology, University Hospitals Seidman Cancer Center, Cleveland, OH, United States; Department of Radiation Oncology, Louis Stokes Cleveland VA Medical Center, Cleveland, OH, United States},
abstract={We propose a new method for generating synthetic CT images from modified Dixon (mDixon) MR data. The synthetic CT is used for attenuation correction (AC) when reconstructing PET data on abdomen and pelvis. While MR does not intrinsically contain any information about photon attenuation, AC is needed in PET/MR systems in order to be quantitatively accurate and to meet qualification standards required for use in many multi-center trials. Existing MR-based synthetic CT generation methods either use advanced MR sequences that have long acquisition time and limited clinical availability or use matching of the MR images from a newly scanned subject to images in a library of MR-CT pairs which has difficulty in accounting for the diversity of human anatomy especially in patients that have pathologies. To address these deficiencies, we present a five-phase interlinked method that uses mDixon MR acquisition and advanced machine learning methods for synthetic CT generation. Both transfer fuzzy clustering and active learning-based classification (TFC-ALC) are used. The significance of our efforts is fourfold: 1) TFC-ALC is capable of better synthetic CT generation than methods currently in use on the challenging abdomen using only common Dixon-based scanning. 2) TFC partitions MR voxels initially into the four groups regarding fat, bone, air, and soft tissue via transfer learning; ALC can learn insightful classifiers, using as few but informative labeled examples as possible to precisely distinguish bone, air, and soft tissue. Combining them, the TFC-ALC method successfully overcomes the inherent imperfection and potential uncertainty regarding the co-registration between CT and MR images. 3) Compared with existing methods, TFC-ALC features not only preferable synthetic CT generation but also improved parameter robustness, which facilitates its clinical practicability. Applying the proposed approach on mDixon-MR data from ten subjects, the average score of the mean absolute prediction deviation (MAPD) was 89.78±8.76 which is significantly better than the 133.17±9.67 obtained using the all-water (AW) method (p=4.11E-9) and the 104.97±10.03 obtained using the four-cluster-partitioning (FCP, i.e., external-Air, internal-Air, fat, and soft tissue) method (p=0.002). 4) Experiments in the PET SUV errors of these approaches show that TFC-ALC achieves the highest SUV accuracy and can generally reduce the SUV errors to 5% or less. These experimental results distinctively demonstrate the effectiveness of our proposed TFCALC method for the synthetic CT generation on abdomen and pelvis using only the commonly-Available Dixon pulse sequence. © 1982-2012 IEEE.},
author_keywords={abdomen;  active learning-based classification (ALC);  attenuation correction (AC);  Dixon-based MR;  Synthetic CT generation;  transfer fuzzy clustering (TFC)},
keywords={Computerized tomography;  Fuzzy clustering;  Learning systems;  Magnetic resonance imaging;  Tissue, abdomen;  Active Learning;  Attenuation correction;  Dixon-based MR;  Synthetic CT generation;  transfer fuzzy clustering (TFC), Transfer learning, abdominal radiography;  Article;  computer assisted tomography;  controlled study;  data compression;  feature extraction;  fuzzy c means clustering;  fuzzy clustering;  human;  image analysis;  image reconstruction;  learning based classification;  machine learning;  nuclear magnetic resonance imaging;  pelvis radiography;  photon;  positron emission tomography;  quantitative analysis;  radiation attenuation;  soft tissue;  support vector machine;  transfer of learning;  abdomen;  cluster analysis;  diagnostic imaging;  fuzzy logic;  image processing;  pelvis;  positron emission tomography;  procedures;  support vector machine;  x-ray computed tomography, Abdomen;  Cluster Analysis;  Fuzzy Logic;  Humans;  Image Processing, Computer-Assisted;  Magnetic Resonance Imaging;  Pelvis;  Positron-Emission Tomography;  Support Vector Machine;  Tomography, X-Ray Computed},
tradenames={Gemini TF},
funding_details={61702225, 61772241},
funding_details={WX18IVJN002},
funding_details={National Institutes of HealthNational Institutes of Health, NIH, R01CA196687},
funding_details={National Cancer InstituteNational Cancer Institute, NCI},
funding_details={Natural Science Foundation of Jiangsu ProvinceNatural Science Foundation of Jiangsu Province, BK20160187},
funding_details={Six Talent Peaks Project in Jiangsu ProvinceSix Talent Peaks Project in Jiangsu Province, 2016-XYDXXJS-014},
funding_text 1={Manuscript received July 23, 2019; revised August 8, 2019; accepted August 12, 2019. Date of publication August 16, 2019; date of cur- rent version April 1, 2020. This work was supported by the National Cancer Institute of the National Institutes of Health, USA, under Grant R01CA196687. It was also supported in part by the National Natural Sci- ence Foundation of China under Grant 61772241 and Grant 61702225, in part by the Natural Science Foundation of Jiangsu Province under Grant BK20160187, in part by the 2016 Six Talent Peaks Project of Jiangsu Province under Grant 2016-XYDXXJS-014, in part by the Science and Technology Demonstration Project of Social Development of Wuxi under Grant WX18IVJN002. (Corresponding author: Raymond F. Muzic.) P. Qian, Y. Chen, Y. Jiang, K. Zhao, and S. Wang are with the School of Digital Media, Jiangnan University, Wuxi 214122, China, and also with the Jiangsu Key Laboratory of Media Design and Soft- ware Technology, Jiangnan University, Wuxi 214122, China (e-mail: qianpjiang@jiangnan.edu.cn; chenyangyang0620@163.com; yzjiang@ jiangnan.edu.cn; zhaokaifa@live.com; wxwangst@aliyun.com). J.-W. Kuo, R. Al Helo, F. Zhou, N. Avril, K.-H. Su, and R. F. Muzic, Jr., are with the Case Center for Imaging Research, Case Western Reserve University, Cleveland, OH 44106 USA, and also with the Department of Radiology University Hospitals, Case Western Reserve University, Cleveland, OH 44106 USA (e-mail: jung-wen.kuo@case.edu; rose.alhelo3@case.edu; feifei.zhou@case.edu; norbert.avril@case. edu; kuan-hao.su@case.edu; raymond.muzic@case.edu). Y.-D. Zhang is with the Department of Informatics, University of Leices- ter, Leicester LE1 7RH, U.K. (e-mail: yudongzhang@ieee.org). H. Friel is with Philips Healthcare, Cleveland, OH 44143 USA (e-mail: harry.friel@philips.com). A. Baydoun is with the Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH 44106 USA, and also with the Department of Internal Medicine, Louis Stokes Cleveland VA Medical Center, Cleveland, OH 44106 USA (e-mail: atallah.baydoun@va.gov). J. U. Heo is with the Department of Biomedical Engineering, Case Western Reserve University, Cleveland, OH 44106 USA (e-mail: jinuk.heo@case.edu). K. Herrmann and R. S. Jones are with the Department of Radiology, University Hospitals Cleveland Medical Center, Cleve- land, OH 44106 USA (e-mail: karin.herrmann@uhhospitals.org; robert. jones@uhhospitals.org). R. Ellis was with the Department of Radiation Oncology, University Hos- pitals Cleveland Medical Center, Cleveland, OH 44106 USA. He is now with the Department of Radiation Oncology, Penn State Cancer Institute, Hershey, PA 17033 USA (e-mail: rellis@pennstatehealth.psu.edu). B. Traughber is with the Case Center for Imaging Research, Case West- ern Reserve University, Cleveland, OH 44106 USA, also with the Department of Radiation Oncology, Case Western Reserve University, Cleveland, OH 44106 USA, also with the Department of Radiation Oncology, University Hospitals Seidman Cancer Center, Cleveland, OH 44106 USA, and also with the Department of Radiation Oncology, Louis Stokes Cleveland VA Medical Center, Cleveland, OH 44106 USA (e-mail: bryan.traughber@case.edu). Color versions of one or more of the figures in this article are available online at http://ieeexplore.ieee.org. Digital Object Identifier 10.1109/TMI.2019.2935916 0278-0062 © 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications_standards/publications/rights/index.html for more information.},
references={Souvatzoglou, M., Comparison of integrated whole-body [11C]choline PET/MR with PET/CT in patients with prostate cancer (2013) Eur. J. Nucl. Med. Mol. Imag, 40 (10), pp. 1486-1499. , Oct; Afshar-Oromieh, A., Comparison of PET/CT and PET/MRI hybrid systems using a 68Ga-labelled PSMA ligand for the diagnosis of recurrent prostate cancer: Initial experience (2014) Eur. J. Nucl. Med. Mol. Imag, 41 (5), pp. 887-897. , May; Aznar, M.C., Whole-body PET/MRI: The effect of bone attenuation during MR-based attenuation correction in oncology imaging (2014) Eur. J. Radiol, 83 (7), pp. 1177-1183. , Jul; Sunderland, J.J., Christian, P.E., Quantitative PET/CT scanner performance characterization based upon the clinical trials network oncology clinical simulator phantom (2015) J. Nucl. Med, 56 (1), pp. 145-152. , Dec; Wagenknecht, G., Kaiser, H.-J., Mottaghy, F.M., Herzog, H., MRI for attenuation correction in PET: Methods and challenges (2013) Magn. Reson. Mater. Phys., Biol. Med, 26 (1), pp. 99-113. , Feb; Hofmann, M., Pichler, B., Schölkopf, B., Beyer, T., Towards quantitative PET/MRI: A review of MR-based attenuation correction techniques (2009) Eur. J. Nucl. Med. Mol. Imag, 36 (1), pp. S93-S104. , Mar; Martinez-Möller, A., Tissue classification as a potential approach for attenuation correction in whole-body PET/MRI: Evaluation with PET/CT Data (2009) J. Nucl. Med, 50 (4), pp. 520-526. , Apr; Beyer, T., MR-based attenuation correction for torso-PET/MR imaging: Pitfalls in mapping MR to CT data (2008) Eur. J. Nucl. Med. Mol. Imag, 35 (6), pp. 1142-1146. , Jun; Heremans, A., Verschakelen, J.A., Van Fraeyenhoven, L., Demedts, M., Measurement of lung density by means of quantitative CT scanning: A study of correlations with pulmonary function tests (1992) Chest, 102 (3), pp. 805-811. , Sep; Dickson, J.C., Omeara, C., Barnes, A., A comparison of CT-And MR-based attenuation correction in neurological PET (2014) Eur. J. Nucl. Med. Mol. Imag, 41 (6), pp. 1176-1189. , Jun; Keereman, V., Fierens, Y., Broux, T., De Deene, Y., Lonneux, M., Vandenberghe, S., MRI-based attenuation correction for PET/MRI using ultrashort echo time sequences (2010) J. Nucl. Med, 51 (5), pp. 812-818. , May; Aklan, B., Toward simultaneous PET/MR breast imaging: Systematic evaluation and integration of a radiofrequency breast coil Med. Phys, 40 (2). , Feb. 2013, Art. no 024301; Hitz, S., Systematic comparison of the performance of integrated whole-body PET/MR imaging to conventional PET/CT for 18F-FDG brain imaging in patients examined for suspected dementia (2014) J. Nucl. Med, 55 (6), pp. 923-931. , Jun; Berker, Y., MRI-based attenuation correction for hybrid PET/MRI systems: A 4-class tissue segmentation technique using a combined ultrashort-echo-Time/dixon MRI sequence (2012) J. Nucl. Med, 53 (5), pp. 796-804. , May; Schramm, G., Erratum to: Quantitative accuracy of attenuation correction in the philips ingenuity TF whole-body PET/MR system: A direct comparison with transmission-based attenuation correction (2013) Magn. Reson. Mater. Phys. Biol. Med, 26, pp. 115-126. , Apr; Samarin, A., PET/MR imaging of bone lesions-Implications for PET quantification from imperfect attenuation correction (2012) Eur. J. Nucl. Med. Mol. Imag, 39 (7), pp. 1154-1160. , Jul; Arabi, H., Rager, O., Alem, A., Varoquaux, A., Becker, M., Zaidi, H., Clinical assessment of MR-guided 3-Class and 4-class attenuation correction in PET/MR (2015) Mol. Imag. Biol, 17 (2), pp. 264-276. , Apr; Izquierdo-Garcia, D., Comparison of MR-based attenuation correction and CT-based attenuation correction of whole-body PET/MR imaging (2014) Eur. J. Nucl. Med. Mol. Imag, 41 (8), pp. 1574-1584. , Aug; Bezrukov, I., MR-based attenuation correction methods for improved pet quantification in lesions within bone and susceptibility artifact regions (2013) J. Nucl. Med, 54 (10), pp. 1768-1774. , Oct; Catana, C., Towards implementing an MR-based PET attenuation correction method for neurological studies on the MR-PET brain prototype (2010) J. Nucl. Med, 51 (9), pp. 1431-1438; Hu, L., K-space sampling optimization for ultrashort TE imaging of cortical bone: Applications in radiation therapy planning and MR-based PET attenuation correction Med. Phys, 41 (10). , Oct. 2014, Art. no 102301; Sekine, T., Clinical evaluation of zero-echo-Time attenuation correction for brain 18F-FDG PET/MRI: Comparison with atlas attenuation correction (2016) J. Nucl. Med, 57 (12), pp. 1927-1932. , Dec; Delso, G., Clinical evaluation of zero-echo-Time MR imaging for the segmentation of the skull (2015) J. Nucl. Med, 56 (3), pp. 417-422. , Mar; Leynes, A.P., Hybrid ZTE/Dixon MR-based attenuation correction for quantitative uptake estimation of pelvic lesions in PET/MRI Med. Phys, 44 (3), pp. 902-913. , Mar. 2017; Navalpakkam, B.K., Braun, H., Kuwert, T., Quick, H.H., Magnetic resonance-based attenuation correction for PET/MR hybrid imaging using continuous valued attenuation maps (2013) Investigative Radiol, 48 (5), pp. 323-332. , May; Johansson, A., Karlsson, M., Nyholm, T., CT substitute derived from MRI sequences with ultrashort echo time (2011) Med. Phys, 38 (5), pp. 2708-2714; Hsu, S.H., Cao, Y., Huang, K., Feng, M., Balter, J.M., Investigation of a method for generating synthetic CT models from MRI scans of the head and neck for radiation therapy (2013) Phys. Med. Biol, 58 (23), pp. 8419-8435. , Nov; Su, K.-H., Generation of brain pseudo-CTs using an undersampled, single-Acquisition UTE-mDixon pulse sequence and unsupervised clustering (2015) Med. Phys, 42 (8), pp. 4974-4986. , Aug; Johansson, A., Karlsson, M., Yu, J., Asklund, T., Nyholm, T., Voxelwise uncertainty in CT substitute derived from MRI (2012) Med. Phys, 39 (6), pp. 3283-3290. , Jun; Andreasen, D., Van Leemput, K., Edmund, J.M., A patch-based pseudo-CT approach for MRI-only radiotherapy in the pelvis (2016) Med. Phys, 43 (8), pp. 4742-4752. , Aug; Andreasen, D., Van Leemput, K., Hansen, R.H., Andersen, J.A.L., Edmund, J.M., Patch-based generation of a pseudo CT from conventional MRI sequences for MRI-only radiotherapy of the brain (2015) Med. Phys, 42 (4), pp. 1596-1605. , Apr; Han, X., MR-based synthetic CT generation using a deep convolutional neural network method (2017) Med. Phys, 44 (4), pp. 1408-1419; Bezdek, J.C., Full, W., Ehrlich, R., FCM: The fuzzy c-means clustering algorithm (1984) Comput. Geosci, 10 (2-3), pp. 191-203; Qian, P., Jiang, Y., Deng, Z., Hu, L., Sun, S., Wang, S., Muzic, R.F., Cluster prototypes and fuzzy memberships jointly leveraged crossdomain maximum entropy clustering (2016) IEEE Trans. Cybern, 46 (1), pp. 181-193. , Jan; Qian, P., Knowledge-leveraged transfer fuzzy c-means for texture image segmentation with self-Adaptive cluster prototype matching Knowledge-Based Syst, 130 (2017), pp. 33-50. , Aug; Qian, P., Cross-domain, soft-partition clustering with diversity measure and knowledge reference (2016) Pattern Recognit, 50, pp. 155-177. , Feb; Boopathi, G., Arockiasamy, S., Image compression: An approach using wavelet transform and modified FCM (2011) Int. J. Comput. Appl, 28 (2), pp. 7-12. , Aug; Chen, S., Zhang, D., Robust image segmentation using FCM with spatial constraints based on new kernel-induced distance measure (2004) IEEE Trans. Syst., Man, Cybern. B, Cybern, 34 (4), pp. 1907-1916. , Aug; Fan, L., Wang, H., Wang, H., A solution of multi-Target tracking based on FCM algorithm in WSN (2006) Proc. 4th Annu IEEE Int. Conf. Pervasive Comput. Commun. Workshops, p. 294. , Pisa, Italy Mar; Anusuya, S., Bhanu, N.U., Kasthuri, E., Yeast gene expression analysis using K means and FCM (2015) Int. J. Pharma Bio Sci, 6 (3), pp. B395-B400. , Jan; Pan, S.J., Yang, Q., A survey on transfer learning (2010) IEEE Trans. Knowl. Data Eng, 22 (10), pp. 1345-1359. , Oct; Schölkopf, B., Herbrich, R., Smola, A.J., A generalized representer theorem (2001) Computational Learning Theory, 2111, pp. 416-426. , Berlin, Germany Springer; Qian, P., SSC-EKE: Semi-supervised classification with extensive knowledge exploitation (2018) Inf. Sci, 422, pp. 51-76. , Jan; Chen, Y., Jiang, H., Li, C., Jia, X., Ghamisi, P., Deep feature extraction and classification of hyperspectral images based on convolutional neural networks (2016) IEEE Trans. Geosci. Remote Sens, 54 (10), pp. 6232-6251. , Oct; Eggers, H., Brendel, B., Duijndam, A., Herigault, G., Dual-echo Dixon imaging with flexible choice of echo times (2011) Magn. Reson. Med, 65 (1), pp. 96-107. , Jan; Kuo, J.-W., Algorithm and parameter optimization for wholebody deformable registration between MR T1-weighted and Dixon images (for PET/MR) (2017) Proc. Radiol. Soc. North Amer. Sci. Assem. Annu. Meeting, , Chicago IL, USA, Nov./Dec; Schneider, W., Bortfeld, T., Schlegel, W., Correlation between CT numbers and tissue parameters needed for Monte Carlo simulations of clinical dose distributions (2000) Phys. Med. Biol, 45 (2), pp. 459-478. , Feb; Tsang, I.W., Kwok, J.T., Cheung, P.-M., Core vector machines: Fast SVM training on very large data sets (2005) J. Mach. Learn. Res, 6, pp. 363-392. , Apr; Arlot, S., Celisse, A., A survey of cross-validation procedures for model selection (2010) Statist. Surv, 4, pp. 40-79; Hooijmans, M.T., Fast multistation water/fat imaging at 3T using DREAM-based RF shimming (2014) J. Magn. Reson. Imag, 42 (1), pp. 217-223. , Jul; Zaidi, H., Design and performance evaluation of a whole-body Ingenuity TF PET-MRI system (2011) Phys. Med. Biol, 56 (10), pp. 3091-3106. , Apr; Kalemis, A., Delattre, B.M., Heinzer, S., Sequential whole-body PET/MR scanner: Concept, clinical use, and optimisation after two years in the clinic.The manufacturer?s perspective (2013) Magn. Reson. Mater. Phys., Biol. Med, 26 (1), pp. 5-23. , Feb; Surti, S., Kuhn, A., Werner, M.E., Perkins, A.E., Kolthammer, J., Karp, J.S., Performance of philips gemini TF PET/CT scanner with special consideration for its time-of-flight imaging capabilities (2007) J. Nucl. Med, 48 (3), pp. 471-480. , Mar; Janssens, G., Jacques, L., De Xivry, J.O., Geets, X., Macq, B., Diffeomorphic registration of images with variable contrast enhancement (2011) Int. J. Biomed. Imag, 2011. , Jan, Art 891585; Lavalle, S.M., Branicky, M.S., Lindemann, S.R., On the relationship between classical grid search and probabilistic roadmaps (2004) Int. J. Robot. Res, 23, pp. 673-692. , Aug; Andreasen, D., Computed tomography synthesis from magnetic resonance images in the pelvis using multiple random forests and autocontext features (2016) Proc. SPIE, 9784. , Mar, Art 978417; Edmund, J.M., Nyholm, T., A review of substitute CT generation for MRI-only radiation therapy Radiat. Oncol, 12 (1), pp. 28-43. , Jan. 2017; Dowling, J.A., An atlas-based electron density mapping method for magnetic resonance imaging (MRI)-Alone treatment planning and adaptive MRI-based prostate radiation therapy (2012) Int. J. Radiat. Oncol. Biol. Phys, 83 (1), pp. e6-e11. , May; Liu, F., Jang, H., Kijowski, R., Bradshaw, T., McMillan, A.B., Deep learning MR imaging-based attenuation correction for PET/MR imaging Radiology, 286 (2), pp. 676-684. , Sep. 2018; Leynes, A.L., Zero-echo-Time and Dixon deep pseudo-CT (ZeDD CT): Direct generation of pseudo-CT images for pelvic PET/MRI attenuation correction using deep convolutional neural networks with multiparametric MRI J. Nucl. Med, 59 (5), pp. 852-858. , May 2018; Huang, Y., Shao, L., Frangi, A.F., Cross-modality image synthesis via weakly coupled and geometry co-regularized joint dictionary learning IEEE Trans. Med. Imag, 37 (3), pp. 815-827. , Mar. 2018; Liang, F., Abdominal, multi-organ, auto-contouring method for online adaptive magnetic resonance guided radiotherapy: An intelligent, multi-level fusion approach (2018) Artif. Intell. Med, 90, pp. 34-41. , Aug; Qian, P., Zhou, J., Jiang, Y., Liang, F., Zhao, K., Wang, S., Su, K., Muzic, R., Multi-view maximum entropy clustering by jointly leveraging inter-view collaborations and intraview-weighted attributes (2018) IEEE Access, 6, pp. 28594-28610; Hu, L., Shao, L., Muzic, R.F., Su, K.-H., Qian, P., (2017) Systems and Methods for Translation of Medical Imaging Using Machine Learning, 28. , U.S Patent 20 170 372 497 A1 Dec; Qian, P., Affinity and penalty jointly constrained spectral clustering with all-compatibility, flexibility, and robustness IEEE Trans. Neural Netw. Learn. Syst, 28 (5), pp. 1123-1138. , May 2017; Su, K.-H., A multi-echo stack-of-stars UTE-based thoracic Dixon imaging (2018) Radiological Society of North America, 28. , Chicago IL, USA Nov; Akbarzadeh, A., Ay, M.R., Ahmadian, A., Alam, N.R., Zaidi, H., MRI-guided attenuation correction in whole-body PET/MR: Assessment of the effect of bone attenuation (2013) Ann. Nucl. Med, 27 (2), pp. 152-162. , Feb},
correspondence_address1={Muzic, R.F.; Case Center for Imaging Research, United States; email: raymond.muzic@case.edu},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={02780062},
coden={ITMID},
pubmed_id={31425065},
language={English},
abbrev_source_title={IEEE Trans. Med. Imaging},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Hamrouni2020242,
author={Hamrouni, Y. and Paillassa, E. and Cheret, V. and Monteil, C. and Sheeren, D.},
title={From Local to Global: A Transfer Learning-Based Approach for Mapping Poplar Plantations at Large Scale},
journal={2020 Mediterranean and Middle-East Geoscience and Remote Sensing Symposium, M2GARSS 2020 - Proceedings},
year={2020},
pages={242-245},
doi={10.1109/M2GARSS47143.2020.9105218},
art_number={9105218},
note={cited By 0; Conference of 2020 Mediterranean and Middle-East Geoscience and Remote Sensing Symposium, M2GARSS 2020 ; Conference Date: 9 March 2020 Through 11 March 2020;  Conference Code:160621},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086724615&doi=10.1109%2fM2GARSS47143.2020.9105218&partnerID=40&md5=699ebef508c73e4f8d934cb83827e891},
affiliation={Université de Toulouse, INRAE, UMR DYNAFOR, Castanet-Tolosan, France; Conseil National du Peuplier, Paris, France; Institut Pour le Développement Forestier, Centre National de la Propriété Forestière, Bordeaux, France},
abstract={Within the current context of availability of Earth Observation satellites at high spatial and temporal resolutions, mapping large areas become doable. To this end, supervised classification of remote sensing images is the commonly adopted approach. Having a high-quality and representative training set is always the key to a successful classification result. However, this is often a tedious task that involves samples gathering from field surveys or photointerpretation. The larger the area to map, the more challenging this exercise becomes. In this letter we present an active learning-based technique to address this issue by optimizing the training set required for classification while providing a generic classifier suitable for large scale. Experiments were carried out to identify poplar plantations in France using Sentine1-2 time series. The results are promising and show the good capacities of the proposed approach to be adapted at the national scale. © 2020 IEEE.},
author_keywords={active learning;  large-scale;  mapping;  Poplar plantations;  Sentine1-2},
keywords={Classification (of information);  Forestry;  Geology;  Mapping;  Transfer learning, Active Learning;  Classification results;  Earth observation satellites;  Field surveys;  Generic classifier;  Learning-based approach;  Spatial and temporal resolutions;  Supervised classification, Remote sensing},
references={Chardenon, J., Flouzat, G., The application of remote sensing to poplar growing [identification and inventory of poplar groves, prediction of timber production; France, Italy] (1981) Revue Forestiere Francaise (France), 33 (6), pp. 478-493; Borry, F.C., De Roover, B.P., Leysen, M.M., De Wulf, R.R., Goossens, R.E., Evaluation of spot and tm data for forest stratification: A case study for smallsize poplar stands (1993) IEEE Transactions on Geoscience and Remote Sensing, 31 (2), pp. 483-490. , Mar; Heyman, O., Gaston, G.G., Kimerling, A.J., Campbell, J.T., A per-segment approach to improving aspen mapping from high-resolution remote sensing imagery (2003) Journal of Forestry, 101 (4), pp. 29-33. , June; Tuia, D., Volpi, M., Copa, L., Kanevski, M., Munoz-Mari, J., A survey of active learning algorithms for supervised remote sensing image classification (2011) IEEE Journal of Selected Topics in Signal Processing, 5 (3), pp. 606-617. , June; Tuia, D., Ratle, F., Pacifici, F., Kanevski, M.F., Emery, W.J., Active learning methods for remote sensing image classification (2009) IEEE Transactions on Geoscience and Remote Sensing, 47 (7), pp. 2218-2232. , July; Amor, I.B.S.B., Chehata, N., Bailly, J., Farah, I.R., Lagacherie, P., Parcel-based active learning for large extent cultivated area mapping (2018) IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 11 (1), pp. 79-88. , Jan; Tuia, D., Pasolli, E., Emery, W.J., Using active learning to adapt remote sensing image classifiers (2011) Remote Sensing of Environment, 115 (9), pp. 2232-2242. , Sept; Matasci, G., Tuia, D., Kanevski, M., SVM-based boosting of active learning strategies for efficient domain adaptation (2012) IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 5 (5), pp. 1335-1343. , Oct; Alajlan, N., Pasolli, E., Melgani, F., Franzoso, A., Large-scale image classification using active learning (2014) IEEE Geoscience and Remote Sensing Letters, 11 (1), pp. 259-263. , Jan; Tuia, D., Persello, C., Bruzzone, L., Domain adaptation for the classification of remote sensing data: An overview of recent advances (2016) IEEE Geoscience and Remote Sensing Magazine, 4 (2), pp. 41-57. , June; Settles, B., (2010) Active Learning Literature Survey, , Tech. Rep. 1648, Jan},
sponsors={The Institute of Electrical and Electronics Engineers Geoscience and Remote Sensing Society (IEEE GRSS)},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728121901},
language={English},
abbrev_source_title={Mediterr. Middle-East Geosci. Remote Sens. Sym., M2GARSS - Proc.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Hemelings2020e94,
author={Hemelings, R. and Elen, B. and Barbosa-Breda, J. and Lemmens, S. and Meire, M. and Pourjavan, S. and Vandewalle, E. and Van de Veire, S. and Blaschko, M.B. and De Boever, P. and Stalmans, I.},
title={Accurate prediction of glaucoma from colour fundus images with a convolutional neural network that relies on active and transfer learning},
journal={Acta Ophthalmologica},
year={2020},
volume={98},
number={1},
pages={e94-e100},
doi={10.1111/aos.14193},
note={cited By 13},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075333149&doi=10.1111%2faos.14193&partnerID=40&md5=9a790842e33b029e4734bcb738bba6bc},
affiliation={Research Group Ophthalmology, KU Leuven, Leuven, Belgium; VITO NV, Mol, Belgium; TC CS-ADVISE, KU Leuven, Geel, Belgium; Chirec Hospitals, Brussel, Belgium; Ophthalmology Department, UZ Leuven, Leuven, Belgium; AZ Sint-Jan, Brugge, Belgium; ESAT-PSI, KU Leuven, Leuven, Belgium; Hasselt University, Diepenbeek, Belgium},
abstract={Purpose: To assess the use of deep learning (DL) for computer-assisted glaucoma identification, and the impact of training using images selected by an active learning strategy, which minimizes labelling cost. Additionally, this study focuses on the explainability of the glaucoma classifier. Methods: This original investigation pooled 8433 retrospectively collected and anonymized colour optic disc-centred fundus images, in order to develop a deep learning-based classifier for glaucoma diagnosis. The labels of the various deep learning models were compared with the clinical assessment by glaucoma experts. Data were analysed between March and October 2018. Sensitivity, specificity, area under the receiver operating characteristic curve (AUC), and amount of data used for discriminating between glaucomatous and non-glaucomatous fundus images, on both image and patient level. Results: Trained using 2072 colour fundus images, representing 42% of the original training data, the trained DL model achieved an AUC of 0.995, sensitivity and specificity of, respectively, 98.0% (CI 95.5%–99.4%) and 91% (CI 84.0%–96.0%), for glaucoma versus non-glaucoma patient referral. Conclusions: These results demonstrate the benefits of deep learning for automated glaucoma detection based on optic disc-centred fundus images. The combined use of transfer and active learning in the medical community can optimize performance of DL models, while minimizing the labelling cost of domain-specific mavens. Glaucoma experts are able to make use of heat maps generated by the deep learning classifier to assess its decision, which seems to be related to inferior and superior neuroretinal rim (within ONH), and RNFL in superotemporal and inferotemporal zones (outside ONH). © 2019 Acta Ophthalmologica Scandinavica Foundation. Published by John Wiley & Sons Ltd},
author_keywords={artificial intelligence;  deep learning;  fundus image;  glaucoma detection},
keywords={adult;  anthropometric parameters;  Article;  computer aided design;  convolutional neural network;  deep learning;  diagnostic accuracy;  diagnostic test accuracy study;  disease classification;  glaucoma;  health care cost;  human;  inferotemporal zone;  major clinical study;  optic nerve;  patient referral;  prediction;  priority journal;  retinal nerve fiber layer;  retrospective study;  sensitivity and specificity;  superior neuroretinal rim;  superotemporal zone;  transfer of learning;  computer assisted diagnosis;  eye fundus;  follow up;  glaucoma;  optic disk;  pathology;  procedures;  receiver operating characteristic, Deep Learning;  Diagnosis, Computer-Assisted;  Follow-Up Studies;  Fundus Oculi;  Glaucoma;  Humans;  Optic Disk;  Retrospective Studies;  ROC Curve},
manufacturers={Carl Zeiss Meditec, Germany; Heidelberg Engineering, Germany},
references={Ahn, J.M., Kim, S., Ahn, K.S., Cho, S.H., Lee, K.B., Kim, U.S., A deep learning model for the detection of both advanced and early glaucoma using fundus photography (2018) PLoS ONE, 13 (11). , &; Asaoka, R., Murata, H., Iwase, A., Araie, M., Detecting preperimetric glaucoma with standard automated perimetry using a deep learning classifier (2016) Ophthalmology, 123 (9), pp. 1974-1980. , &; Burlina, P.M., Joshi, N., Pacheco, K.D., Freund, D.E., Kong, J., Bressler, N.M., Use of deep learning for detailed severity characterization and estimation of 5-year risk among patients with age-related macular degeneration (2018) JAMA Ophthalmol, 136 (12), pp. 1359-1366. , &; Burr, J., Hernández, R., Ramsay, C., Is it worthwhile to conduct a randomized controlled trial of glaucoma screening in the United Kingdom? (2014) J Health Serv Res Policy, 19 (1), pp. 42-51; Chen, X., Xu, Y., Kee Wong, D.W., Wong, T.Y., Liu, J., (2015) Glaucoma detection based on deep convolutional neural network, , https://doi.org/10.1109/embc.2015.7318462, &, 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), Milan 715–718; Christopher, M., Belghith, A., Bowd, C., Performance of deep learning architectures and transfer learning for detecting glaucomatous optic neuropathy in fundus photographs (2018) Sci Rep, 8 (1), p. 16685; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., (2009) ImageNet: A Large-Scale Hierarchical Image Database, , https://doi.org/10.1109/cvpr.2009.5206848, &, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Miami, FL 248–255; Ervin, A.M., Boland, M.V., Myrowitz, E.H., (2012) Screening for Glaucoma: Comparative Effectiveness, , Rockville (MD), Agency for Healthcare Research and Quality (US), (Comparative Effectiveness Reviews, 59.); Fu, H., Cheng, J., Xu, Y., Wong, D.W.K., Liu, J., Cao, X., Joint optic disc and cup segmentation based on multi-label deep network and polar transformation (2018) IEEE Trans Med Imaging, 37 (7), pp. 1597-1605. , &; Grassmann, F., Mengelkamp, J., Brandl, C., A deep learning algorithm for prediction of age-related eye disease study severity scale for age-related macular degeneration from color fundus photography (2018) Ophthalmology, 125 (9), pp. 1410-1420; Gulshan, V., Peng, L., Coram, M., Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs (2016) JAMA, 316 (22), pp. 2402-2410; He, K., Zhang, X., Ren, S., Sun, J., (2016) Deep residual learning for image recognition, , &, Proceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Piscataway, NJ 771–778; van der Heijden, A.A., Abramoff, M.D., Verbraak, F., Hecke, M.V., Liem, A., Nijpels, G., Validation of automated screening for referable diabetic retinopathy with the IDx-DR device in the Hoorn Diabetes Care System (2018) Acta Ophthalmol, 96, pp. 63-68. , &; Jones, E., Oliphant, E., Peterson, P., (2001) SciPy: Open Source Scientific Tools for Python, , http://www.scipy.org/, &; Joshi, A.J., Porikli, F., Papanikolopoulos, N., (2009) Multi-class active learning for image classification, , https://doi.org/10.1109/cvpr.2009.5206627, &, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Miami, FL, 2372-2379; Kapetanakis, V.V., Chan, M.P.Y., Foster, P.J., Global variations and time trends in the prevalence of primary open angle glaucoma (POAG): a systematic review and meta-analysis (2006) Br J Ophthalmol, 100, pp. 86-93; Kingma, D.P., Ba, J., (2015) Adam: A method for stochastic optimization, , &, International Conference on Learning Representations (ICLR); Kotikalapudi, R., (2017) keras-vis, , https://github.com/raghakot/keras-vis; Li, Z., He, Y., Keel, S., Meng, W., Chang, R., He, M., Efficacy of a deep learning system for detecting glaucomatous optic neuropathy based on color fundus photographs (2018) Ophthalmology, 125 (8), pp. 1199-1206. , &; Li, Z., Keel, S., Liu, C., He, M., Can artificial intelligence make screening faster, more accurate, and more accessible? (2018) Asia Pac J Ophthalmol (Phila), 7, pp. 436-441. , &; Maheshwari, S., Pachori, R.B., Acharya, U.R., Automated diagnosis of glaucoma using empirical wavelet transform and correntropy features extracted from fundus images (2017) IEEE J Biomed Health Inform, 21 (3), pp. 803-813. , &; Matsopoulos, G.K., Asvestas, P.A., Delibasis, K.K., Mouravliansky, N.A., Zeyen, T.G., Detection of glaucomatous change based on vessel shape analysis (2008) Comput Med Imaging Graph, 32 (3), pp. 183-192. , &; Muhammad, H., Fuchs, T.J., De Cuir, N., Hybrid deep learning on single wide-field optical coherence tomography scans accurately classifies glaucoma suspects (2017) J Glaucoma, 26 (12), pp. 1086-1094; Settles, B., (2009) Active Learning Literature Survey, , Computer Sciences Technical Report 1648, University of Wisconsin–Madison; Shibata, N., Tanito, M., Mitsuhashi, K., Development of a deep residual learning algorithm to screen for glaucoma from fundus photography (2018) Sci Rep, 8 (1), p. 14665; Simonyan, K., Vedaldi, A., Zisserman, A., (2014) Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps, , &, Proceedings of the 2014 International Conference on Learning Representations (ICLR); Tham, Y., Li, X., Wong, T., Quigley, H., Aung, T., Cheng, C., Global Prevalence of Glaucoma and Projections of Glaucoma Burden through 2040 (2014) Ophthalmology, 121 (11), pp. 2081-2090. , &; Ting, D.S.W., Pasquale, L.R., Peng, L., Artificial intelligence and deep learning in ophthalmology (2019) Br J Ophthalmol, 103, pp. 167-175; Tuulonen, A., Cost-effectiveness of screening for open angle glaucoma in developed countries (2011) Indian J Ophthalmol, 59 (Suppl1), pp. S24-S30; Wen, J.C., Lee, C.S., Keane, P.A., (2018) Forecasting Future Humphrey Visual Fields Using Deep Learning, , arXiv e-prints},
correspondence_address1={Hemelings, R.; Research Group Ophthalmology, Belgium; email: ruben.hemelings@kuleuven.be},
publisher={Blackwell Publishing Ltd},
issn={1755375X},
pubmed_id={31344328},
language={English},
abbrev_source_title={Acta Ophthalmol.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zheng202097503,
author={Zheng, D. and Zhang, K. and Lu, J. and Jing, J. and Xiong, Z.},
title={Active discriminative cross-domain alignment for low-resolution face recognition},
journal={IEEE Access},
year={2020},
volume={8},
pages={97503-97515},
doi={10.1109/ACCESS.2020.2996796},
art_number={9098902},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086077447&doi=10.1109%2fACCESS.2020.2996796&partnerID=40&md5=c4a81ca1e5644fb3d9aeb8eedf7bb354},
affiliation={School of Electronics and Information, Xi'An Polytechnic University, Xi'an, 710048, China; School of Computer and Information Science, Hubei Engineering University, Xiaogan, 432000, China},
abstract={In real application scenarios, the face images captured by cameras often incur blur, illumination variation, occlusion, and low-resolution (LR), which leads to a challenging problem for many real-time face recognition systems due to a big distribution difference between the captured degraded images and the high-resolution (HR) gallery images. As widespread application of transfer learning in across-visual recognition, we propose a novel active discriminative cross-domain alignment (ADCDA) technique for LR face recognition method by jointly exploring both geometrical and statistical properties of the source domain and the target domain in a unique way. Specifically, the proposed ADCDA-based method contains three key components: 1) it simultaneously reduces the domain shift in both marginal distribution and conditional distribution between the source domain and the target domain; 2) it aligns the data of two domains in the common latent subspace by discriminant locality alignment (DLA); 3) it selects the representative and the diverse samples with an active learning strategy to further improve classification performance. Extensive experiments on six benchmark databases verify that the proposed method significantly outperforms other state-of-the-art predecessors. © 2013 IEEE.},
author_keywords={active learning;  discriminant locality alignment (DLA);  domain adaptation;  low-resolution (LR) face recognition;  Transfer learning},
keywords={Learning systems;  Real time systems;  Transfer learning, Active learning strategies;  Classification performance;  Conditional distribution;  Face recognition methods;  Illumination variation;  Low resolution face recognition;  Real-time face recognition system;  Statistical properties, Face recognition},
funding_details={T201410},
funding_details={BS1616, CHX2020016},
funding_details={National Natural Science Foundation of ChinaNational Natural Science Foundation of China, NSFC, 61471161, 61971339, 61972136},
funding_details={Natural Science Foundation of Shaanxi ProvinceNatural Science Foundation of Shaanxi Province, 2018GY-173, 2018JZ6002},
funding_details={Xi'an Polytechnic UniversityXi'an Polytechnic University, XPU},
funding_text 1={This work was supported in part by the National Natural Science Foundation of China under Grant 61971339, Grant 61972136, and Grant 61471161, in part by the Key Project of the Natural Science Foundation of Shaanxi Province under Grant 2018JZ6002 and Grant 2018GY-173, in part by the Hubei Provincial Department of Education Outstanding Youth Scientific Innovation Team Support Foundation under Grant T201410, in part by the Graduate Innovation Foundation of Xi'an Polytechnic University under Grant CHX2020016, and in part by the Doctoral Startup Foundation of Xi'an Polytechnic University under Grant BS1616.},
funding_text 2={This work was supported in part by the National Natural Science Foundation of China under Grant 61971339, Grant 61972136, and Grant 61471161, in part by the Key Project of the Natural Science Foundation of Shaanxi Province under Grant 2018JZ6002 and Grant 2018GY-173, in part by the Hubei Provincial Department of Education Outstanding Youth Scientific Innovation Team Support Foundation under Grant T201410, in part by the Graduate Innovation Foundation of Xi’an Polytechnic University under Grant CHX2020016, and in part by the Doctoral Startup Foundation of Xi’an Polytechnic University under Grant BS1616.},
references={Li, W., Duan, L., Xu, D., Tsang, I.W., Learning with augmented features for supervised and semi-supervised heterogeneous domain adaptation (2014) IEEE Trans. Pattern Anal. Mach. Intell., 36 (6), pp. 1134-1148. , Jun; Yan, K., Kou, L., Zhang, D., Learning domain-invariant subspace using domain features and independence maximization (2018) IEEE Trans. Cybern., 48 (1), pp. 288-299. , Jan; Sanodiya, R.K., Mathew, J., Saha, S., Thalakottur, M.D., A new trans-fer learning algorithm in semi-supervised setting (2019) IEEE Access, 7, pp. 42956-42967; Long, M., Ding, G., Wang, J., Sun, J., Guo, Y., Yu, P.S., Transfer sparse coding for robust image representation (2013) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 407-414. , Jun; Long, M., Wang, J., Ding, G., Pan, S.J., Yu, P.S., Adaptation regular-ization: A general framework for transfer learning (2014) IEEE Trans. Knowl. Data Eng., 26 (5), pp. 1076-1089. , May; Tahmoresnezhad, J., Hashemi, S., Visual domain adaptation via trans-fer feature learning (2017) Knowl. Inf. Syst., 50 (2), pp. 585-605. , Feb; Courty, N., Flamary, R., Tuia, D., Rakotomamonjy, A., Optimal transport for domain adaptation (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39 (9), pp. 1853-1865. , Sep; Zhong, X., Guo, S., Shan, H., Gao, L., Xue, D., Zhao, N., Feature-based transfer learning based on distribution similarity (2018) IEEE Access, 6, pp. 35551-35557; Zhuang, F., Qi, Z., Duan, K., Xi, D., Zhu, Y., Zhu, H., Xiong, H., He, Q., (2019) A Comprehensive Survey on Transfer Learning, , http://arxiv.org/abs/1911.02685; Duan, L., Xu, D., Tsang, I.W., Domain adaptation from multiple sources: A domain-dependent regularization approach (2012) IEEE Trans. Neu-ral Netw. Learn. Syst., 23 (3), pp. 504-518. , Mar; Duan, L., Tsang, I.W., Xu, D., Domain transfer multiple kernel learn-ing (2012) IEEE Trans. Pattern Anal. Mach. Intell., 34 (3), pp. 465-479. , Mar; Ren, C.-X., Dai, D.-Q., Huang, K.-K., Lai, Z.-R., Transfer learning of structured representation for face recognition (2014) IEEE Trans. Image Process., 23 (12), pp. 5440-5454. , Dec; Wang, J., Chen, Y., Hao, S., Feng, W., Shen, Z., Balanced distribution adaptation for transfer learning (2017) Proc. IEEE Int. Conf. Data Mining (ICDM), pp. 1129-1134. , Nov., New Orleans, LA, USA; Liu, X., Liu, Z., Wang, G., Cai, Z., Zhang, H., Ensemble transfer learning algorithm (2018) IEEE Access, 6, pp. 2389-2396; Shao, M., Kit, D., Fu, Y., Generalized transfer subspace learning through low-rank constraint (2014) Int. J. Comput. Vis., 109 (1-2), pp. 74-93. , Aug; Fernando, B., Tommasi, T., Tuytelaars, T., Joint cross-domain clas-sification and subspace learning for unsupervised adaptation (2015) Pattern Recognit. Lett., 65, pp. 60-66. , Nov; Sun, H., Liu, S., Zhou, S., Discriminative subspace alignment for unsupervised visual domain adaptation (2016) Neural Process. Lett., 44 (3), pp. 779-793. , Dec; Zhang, L., Wang, S., Huang, G.-B., Zuo, W., Yang, J., Zhang, D., Manifold criterion guided transfer learning via intermediate domain generation (2019) IEEE Trans. Neural Netw. Learn. Syst., 30 (12), pp. 3759-3773. , Dec; Zhang, L., Fu, J., Wang, S., Zhang, D., Dong, Z., Chen, C.L.P., Guide subspace learning for unsupervised domain adaptation (2019) IEEE Trans. Neural Netw. Learn. Syst., Early Access, , Nov. 1; Pan, S.J., Tsang, I.W., Kwok, J.T., Yang, Q., Domain adaptation via transfer component analysis (2011) IEEE Trans. Neural Netw., 22 (2), pp. 199-210. , Feb; Gong, B., Shi, Y., Sha, F., Grauman, K., Geodesic flow kernel for unsu-pervised domain adaptation (2012) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2066-2073. , Jun., Providence, RI, USA; Long, M., Wang, J., Ding, G., Sun, J., Yu, P.S., Transfer feature learning with joint distribution adaptation (2013) Proc. IEEE Int. Conf. Comput. Vis. (ICCV), pp. 2200-2207. , Dec., Sydney, NSW, Australia; Fernando, B., Habrard, A., Sebban, M., Tuytelaars, T., Unsupervised visual domain adaptation using subspace alignment (2013) Proc. IEEE Int. Conf. Comput. Vis. (ICCV), pp. 2960-2967. , Dec., Sydney, NSW, Australia; Long, M., Wang, J., Ding, G., Sun, J., Yu, P.S., Transfer joint matching for unsupervised domain adaptation (2014) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 1410-1417. , Jun; Sun, B., Saenko, K., Subspace distribution alignment for unsupervised domain adaptation (2015) Proc. Brit. Mach. Vis. Conf., Swansea, Wales, pp. 241-2410; Xu, Y., Fang, X., Wu, J., Li, X., Zhang, D., Discriminative transfer subspace learning via low-rank and sparse representation (2016) IEEE Trans. Image Process., 25 (2), pp. 850-863. , Feb; Tuia, D., Camps-Valls, G., Kernel manifold alignment for domain adaptation (2016) PLoS ONE, 11 (2). , Feb; Ghifary, M., Balduzzi, D., Kleijn, W.B., Zhang, M., Scatter compo-nent analysis: A unified framework for domain adaptation and domain generalization (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39 (7), pp. 1414-1430. , Jul; Zhang, J., Li, W., Ogunbona, P., Joint geometrical and statistical alignment for visual domain adaptation (2017) Proc. IEEE Conf. Com-put. Vis. Pattern Recognit. (CVPR), pp. 5150-5158. , Jul., Honolulu, HI, USA; Wang, S., Zhang, L., Zuo, W., Zhang, B., Class-specific recon-struction transfer learning for visual recognition across domains (2019) IEEE Trans. Image Process., 29, pp. 2424-2438. , Nov; Ghifary, M., Kleijn, W.B., Zhang, M., Domain adaptive neural net-works for object recognition (2014) Proc. Pacific Rim Int. Conf. Artif. Intell., pp. 898-904. , Gold Coast, QLD, Australia; Long, M., Cao, Y., Cao, Z., Wang, J., Jordan, M.I., Transfer-able representation learning with deep adaptation networks (2019) IEEE Trans. Pattern Anal. Mach. Intell., 41 (12), pp. 3071-3085. , Dec; Chen, C., Chen, Z., Jiang, B., Jin, X., Joint domain alignment and discriminative feature learning for unsupervised deep domain adapta-tion (2019) Proc. AAAI Conf. Artif. Intell., pp. 3296-3303. , Honolulu, HI, USA; Tzeng, E., Hoffman, J., Zhang, N., Saenko, K., Darrell, T., (2014) Deep Domain Confusion: Maximizing for Domain Invariance, , http://arxiv.org/abs/1412.3474; Sun, B., Saenko, K., Deep CORAL: Correlation alignment for deep domain adaptation (2016) Proc. Eur. Conf. Comput. Vis. Workshops (ECCVW), pp. 443-450. , Amsterdam, The Netherlands; Sun, B., Feng, J., Saenko, K., Return of frustratingly easy domain adaptation (2016) Proc. AAAI Conf. Artif. Intell., pp. 2058-2065. , Phoenix, AZ, USA; Tzeng, E., Hoffman, J., Saenko, K., Darrell, T., Adversarial discrim-inative domain adaptation (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2962-2971. , Jul., Honolulu, HI, USA; Long, M., Cao, Z., Wang, J., Jordan, M.I., Conditional adversarial domain adaptation (2018) Proc. Annu. Conf. Neural Inf. Process. Syst., pp. 1640-1650. , Montreal, QC, Canada; Kang, G., Jiang, L., Yang, Y., Hauptmann, A.G., Contrastive adap-tation network for unsupervised domain adaptation (2019) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 4893-4902. , Jun., Long Beach, CA, USA; Gretton, A., Borgwardt, K., Rasch, M.J., Scholkopf, B., Smola, A.J., (2008) A Kernel Method for the Two-sample Problem, , http://arxiv.org/abs/0805.2368; Zhang, T., Tao, D., Yang, J., Discriminative locality alignment (2008) Proc. Eur. Conf. Comput. Vis. (ECCV), pp. 725-738; Bouboulis, P., Slavakis, K., Theodoridis, S., Adaptive learning in complex reproducing kernel Hilbert spaces employingWirtinger's subgra-dients (2012) IEEE Trans. Neural Netw. Learn. Syst., 23 (3), pp. 425-438. , Mar; Li, B., Chang, H., Shan, S., Chen, X., Low-resolution face recognition via coupled locality preserving mappings (2010) IEEE Signal Process. Lett., 17 (1), pp. 20-23. , Jan; Jiang, J., Hu, R., Wang, Z., Cai, Z., CDMMA: Coupled discriminant multi-manifold analysis for matching low-resolution face images (2016) Signal Process., 124, pp. 162-172. , Jul; Bhatt, H.S., Singh, R., Vatsa, M., Ratha, N.K., Improving cross-resolution face matching using ensemble-based co-transfer learn-ing (2014) IEEE Trans. Image Process., 23 (12), pp. 5654-5669. , Dec; Nie, F., Xu, D., Tsang, I.W.-H., Zhang, C., Flexible manifold embed-ding: A framework for semi-supervised and unsupervised dimension reduction (2010) IEEE Trans. Image Process., 19 (7), pp. 1921-1932. , Jul},
correspondence_address1={Zhang, K.; School of Electronics and Information, China; email: xihua_0169@163.com},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={21693536},
language={English},
abbrev_source_title={IEEE Access},
document_type={Article},
source={Scopus},
}

@ARTICLE{Pan2020,
author={Pan, X. and Zhao, Y. and Chen, H. and Wei, D. and Zhao, C. and Wei, Z.},
title={Fully Automated Bone Age Assessment on Large-Scale Hand X-Ray Dataset},
journal={International Journal of Biomedical Imaging},
year={2020},
volume={2020},
doi={10.1155/2020/8460493},
art_number={8460493},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082884252&doi=10.1155%2f2020%2f8460493&partnerID=40&md5=0979087362d49b843fffedf1bb96198e},
affiliation={School of Computer Science and Technology, Xi'an University of Posts and Telecommunications, Xi'an, Shaanxi, 710121, China; School of Computing Sciences and Computer Engineering, University of Southern Mississippi, Hattiesburg, MS  39406, United States; Department of Computer Science, New Jersey Institute of Technology, Newark, NJ  07102, United States},
abstract={Bone age assessment (BAA) is an essential topic in the clinical practice of evaluating the biological maturity of children. Because the manual method is time-consuming and prone to observer variability, it is attractive to develop computer-aided and automated methods for BAA. In this paper, we present a fully automatic BAA method. To eliminate noise in a raw X-ray image, we start with using U-Net to precisely segment hand mask image from a raw X-ray image. Even though U-Net can perform the segmentation with high precision, it needs a bigger annotated dataset. To alleviate the annotation burden, we propose to use deep active learning (AL) to select unlabeled data samples with sufficient information intentionally. These samples are given to Oracle for annotation. After that, they are then used for subsequential training. In the beginning, only 300 data are manually annotated and then the improved U-Net within the AL framework can robustly segment all the 12611 images in RSNA dataset. The AL segmentation model achieved a Dice score at 0.95 in the annotated testing set. To optimize the learning process, we employ six off-the-shell deep Convolutional Neural Networks (CNNs) with pretrained weights on ImageNet. We use them to extract features of preprocessed hand images with a transfer learning technique. In the end, a variety of ensemble regression algorithms are applied to perform BAA. Besides, we choose a specific CNN to extract features and explain why we select that CNN. Experimental results show that the proposed approach achieved discrepancy between manual and predicted bone age of about 6.96 and 7.35 months for male and female cohorts, respectively, on the RSNA dataset. These accuracies are comparable to state-of-the-art performance. © 2020 Xiaoying Pan et al.},
keywords={Convolutional neural networks;  Deep learning;  Deep neural networks;  Image segmentation;  Large dataset;  Learning systems;  Transfer learning, Automated methods;  Bone age assessment;  Clinical practices;  Learning techniques;  Observer variability;  Regression algorithms;  Segmentation models;  State-of-the-art performance, Image enhancement, adult;  article;  bone age determination;  convolutional neural network;  female;  human;  male;  noise;  transfer of learning;  X ray},
references={Vanderwilde, R., Staheli, L.T., Chew, D.E., Malagon, V., Measurements on radiographs of the foot in normal infants and children (1988) The Journal of Bone and Joint Surgery, 70 (3), pp. 407-415; University, S., Radiographic atlas of skeletal development of the hand and wrist (1951) Journal of Anatomy, 85, p. 103; Tanner, J.M., Whitehouse, R.H., Cameron, N., Marshall, W.A., Healy, M.J., Goldstein, H., (1975) Assessment of skeletal maturity and prediction of adult height (TW2 method, , London: Academic Press; Lin, S.W., Ying, K.C., Chen, S.C., Lee, Z.J., Particle swarm optimization for parameter determination and feature selection of support vector machines (2008) Expert Systems with Applications, 35 (4), pp. 1817-1824; Harmsen, M., Fischer, B., Schramm, H., Seidl, T., Deserno, T.M., Support vector machine classification based on correlation prototypes applied to bone age assessment (2013) IEEE Journal of Biomedical and Health Informatics, 17 (1), pp. 190-197; Somkantha, K., Theera-Umpon, N., Auephanwiriyakul, S., Bone age assessment in young children using automatic carpal bone feature extraction and support vector regression (2011) Journal of Digital Imaging, 24 (6), pp. 1044-1058; Thodberg, H.H., Kreiborg, S., Juul, A., Pedersen, K.D., The BoneXpert method for automated determination of skeletal maturity (2009) IEEE Transactions on Medical Imaging, 28 (1), pp. 52-66; Rucci, M., Coppini, G., Nicoletti, I., Cheli, D., Valli, G., Automatic analysis of hand radiographs for the assessment of skeletal age: A subsymbolic approach (1995) Computers and Biomedical Research, 28 (3), pp. 239-256; Mansourvar, M., Raj, R.G., Ismail, M.A., Automated web based system for bone age assessment using histogram technique (2012) Malaysian Journal of Computer Science, 25 (3), pp. 107-121; Spampinato, C., Palazzo, S., Giordano, D., Aldinucci, M., Leonardi, R., Deep learning for automated skeletal bone age assessment in X-ray images (2017) Medical Image Analysis, 36, pp. 41-51; Larson, D.B., Chen, M.C., Lungren, M.P., Halabi, S.S., Stence, N.V., Langlotz, C.P., Performance of a deep-learning neural network model in assessing skeletal maturity on pediatric hand radiographs (2018) Radiology, 287 (1), pp. 313-322; Lee, H., Tajmir, S., Lee, J., Fully automated deep learning system for bone age assessment (2017) Journal of Digital Imaging, 30 (4), pp. 427-441; Ronneberger, O., Fischer, P., Brox, T., U-net: Convolutional networks for biomedical image segmentation (2015) International Conference on Medical Image Computing and Computer-Assisted Intervention, N. Navab, J. Hornegger, W. Wells, and A. Frangi, Eds., pp. 234-241. , Springer; Seung, H.S., Opper, M., Sompolinsky, H., Query by committee (1992) Proceedings of the Fifth Annual Workshop on Computational Learning Theory, pp. 287-294; Cohn, D.A., Ghahramani, Z., Jordan, M.I., Active learning with statistical models (1996) Journal of Artificial Intelligence Research, 4, pp. 129-145; Fu, H., Xu, Y., Wong, D.W.K., Liu, J., Retinal vessel segmentation via deep learning network and fully-connected conditional random fields (2016) 2016 IEEE 13th International Symposium on Biomedical Imaging ISBI, pp. 698-701. , Prague, Czech Republic; Ding, Z., Nasrabadi, N.M., Fu, Y., Task-driven deep transfer learning for image classification (2016) 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP, pp. 2414-2418. , Shanghai, China; Shin, H.C., Roth, H.R., Gao, M., Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning (2016) IEEE Transactions on Medical Imaging, 35 (5), pp. 1285-1298; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014), https://arxiv.org/abs/1409.1556; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR, pp. 770-778. , Las Vegas, NV, USA, June 2016; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the inception architecture for computer vision 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR, pp. 2818-2826. , Las Vegas, NV, USA, June 2016; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence (AAAI'17, pp. 4278-4284. , San Francisco, CA, USA; Chollet, F., Xception: Deep learning with depthwise separable convolutions 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR, pp. 1251-1258. , Honolulu, HI, USA, July 2017; Dagher, I., Incremental pca-lda algorithm (2010) 2010 IEEE International Conference on Computational Intelligence for Measurement Systems and Applications, pp. 97-101. , Taranto, Italy; Scholkopf, B., Smola, A., Muller, K.R., Kernel principal component analysis (1997) International Conference on Artificial Neural Networks, W. Gerstner, A. Germond, pp. 583-588. , Springer M. Hasler, and J. D. Nicoud, Eds; Drucker, H., Burges, C.J., Kaufman, L., Smola, A.J., Vapnik, V., Support vector regression machines (1997) Advances in Neural Information Processing Systems, pp. 155-161. , MIT Press; Vovk, V., Kernel ridge regression (2013) Empirical Inference, pp. 105-116. , Springer; Halabi, S.S., Prevedello, L.M., Kalpathy-Cramer, J., The RSNA pediatric bone age machine learning challenge (2019) Radiology, 290 (2), pp. 498-503; Pizer, S.M., Johnston, R.E., Ericksen, J.P., Yankaskas, B.C., Muller, K.E., Contrast-limited adaptive histogram equalization: Speed and effectiveness (1990) Proceedings of the First Conference on Visualization in Biomedical Computing, pp. 337-345. , Atlanta, Georgia; Lawrence, I., Lin, K., A concordance correlation coefficient to evaluate reproducibility (1989) Biometrics, 45 (1), pp. 255-268; Breiman, L., Bagging predictors (1996) Machine Learning, 24 (2), pp. 123-140; Iglovikov, V.I., Rakhlin, A., Kalinin, A.A., Shvets, A.A., Paediatric bone age assessment using deep convolutional neural networks (2018) Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, pp. 300-308. , Springer, D. Stoyanov, Ed; Wu, E., Kong, B., Wang, X., Residual attention based network for hand bone age assessment (2019) 2019 IEEE 16th International Symposium on Biomedical Imaging ISBI, 2019, pp. 1158-1161. , Venice, Italy, Italy; Han, J., Jia, Y., Zhao, C., Gou, F., Automatic bone age assessment combined with transfer learning and support vector regression (2018) 2018 9th International Conference on Information Technology in Medicine and Education (ITME, pp. 61-66. , Hangzhou, China; Tajmir, S.H., Lee, H., Shailam, R., Artificial intelligenceassisted interpretation of bone age radiographs improves accuracy and decreases variability (2019) Skeletal Radiology, 48 (2), pp. 275-283; He, K., Sun, J., Convolutional neural networks at constrained time cost 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR, pp. 5353-5360. , Boston, MA, USA, June 2015},
correspondence_address1={Zhao, C.; School of Computing Sciences and Computer Engineering, United States; email: 1603210019@stu.xupt.edu.cn},
publisher={Hindawi Limited},
issn={16874188},
language={English},
abbrev_source_title={Int. J. Biomed. Imaging},
document_type={Article},
source={Scopus},
}

@ARTICLE{Tong20202056,
author={Tong, X. and Pan, H. and Liu, S. and Li, B. and Luo, X. and Xie, H. and Xu, X.},
title={A Novel Approach for Hyperspectral Change Detection Based on Uncertain Area Analysis and Improved Transfer Learning},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
year={2020},
volume={13},
pages={2056-2069},
doi={10.1109/JSTARS.2020.2990481},
art_number={9080097},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085660602&doi=10.1109%2fJSTARS.2020.2990481&partnerID=40&md5=7704c1d54e0cd889961fbb732b509cb7},
affiliation={College of Surveying and Geo-Informatics, Tongji University, Shanghai, 200092, China},
abstract={Although a number of change detection (CD) methods have been proposed during the past years, most of them are developed based on the assumption that there are either training samples or no training samples for both the pretime and posttime images. Few studies have addressed the scenario of only small amounts of training samples are available only in a single-time image. In this article, we propose a novel approach that can detect multiple changes in bitemporal hyperspectral images when only a few training samples are available in one of the images (the source image). The proposed method consists of four main steps: first, unsupervised CD based on uncertain area analysis to generate the binary change map; second, classification of the source image (X1) according to active learning; third, classification of the target image (X2) by the use of improved transfer learning; and fourth, generation of the multiclass change map by postclassification comparison. The proposed method was tested on one simulated dataset and two pairs of real bitemporal hyperspectral images. Experimental results demonstrate that: first, uncertain area analysis can improve the binary CD accuracy; while active learning and improved transfer learning can enhance the classification accuracy of the source and target images, the multiple CD accuracy is increased by the use of the proposed method; and second, compared with the state-of-the-art methods, the proposed method produced best results. © 2008-2012 IEEE.},
author_keywords={Change detection (CD);  hyperspectral (HS) images;  multiple changes;  transfer learning;  uncertain area analysis},
keywords={Image analysis;  Image classification;  Image enhancement;  Learning systems;  Sampling;  Spectroscopy, Active Learning;  Change detection;  Classification accuracy;  HyperSpectral;  Multiple changes;  Post-classification comparisons;  State-of-the-art methods;  Training sample, Transfer learning, accuracy assessment;  classification;  data set;  detection method;  experimental study;  image analysis;  learning;  remote sensing;  spectral analysis;  training;  uncertainty analysis},
funding_details={2018YFB0505000, 2018YFB0505400},
funding_details={National Natural Science Foundation of ChinaNational Natural Science Foundation of China, NSFC, 41601354, 41601414, 41631178, 41971299},
funding_text 1={Manuscript received August 27, 2019; revised January 12, 2020, March 22, 2020, and April 21, 2020; accepted April 21, 2020. Date of publication April 28, 2020; date of current version May 22, 2020. This work was supported in part by the National Natural Science Foundation of China under Project 41631178, Project 41601354, Project 41601414, and Project 41971299 and in part by the National Key R&D Program of China under Project 2018YFB0505400 and Project 2018YFB0505000. (Corresponding author: Xiaohua Tong.) The authors are with the College of Surveying and Geo-Informatics, Tongji University, Shanghai 200092, China (e-mail: xhtong@tongji.edu.cn; hypan@tongji.edu.cn; sicong.liu@tongji.edu.cn; libinbin@tongji.edu.cn; huanxie@tongji.edu.cn; xvxiong@tongji.edu.cn). Digital Object Identifier 10.1109/JSTARS.2020.2990481},
references={Bruzzone, L., Bovolo, F., A novel framework for the design of changedetection systems for very-high-resolution remote sensing images (2013) Proc. IEEE, 101 (3), pp. 609-630. , Mar; Li, X., Gong, P., Liang, L., A 30-year (1984-2013) record of annual urban dynamics of Beijing City derived from Landsat data (2015) Remote Sens. Environ, 166, pp. 78-90; Mertes, C., Schneider, A., Sulla-Menashe, D., Tatem, A., Tan, B., Detecting change in urban areas at continental scales with MODIS data (2015) Remote Sens. Environ, 158, pp. 331-347; Xiao, P., Zhang, X., Wang, D., Yuan, M., Feng, X., Kelly, M., Change detection of built-up land: A framework of combining pixel-based detection and object-based recognition (2016) ISPRS J. Photogramm. Remote Sens, 119, pp. 402-414; Deng, J., Wang, K., Deng, Y., Qi, G., PCA-based land-use change detection and analysis using multitemporal andmultisensor satellite data (2008) Int. J. Remote Sens, 29 (16), pp. 4823-4838; He, C., Wei, A., Shi, P., Zhang, Q., Zhao, Y., Detecting land-use/landcover change in rural-urban fringe areas using extended change-vector analysis (2011) Int. J. Appl. Earth Observ. Geoinf, 13 (4), pp. 572-585; Zhang, X., Sun, R., Zhang, B., Tong, Q., Land cover classification of the North China Plain usingMODIS-EVI time series (2008) ISPRS J. Photogramm. Remote Sens, 63, pp. 476-484; Li, Z., Shi, W., Lu, P., Yan, L., Wang, Q., Miao, Z., Landslide mapping from aerial photographs using change detection-based Markov random field (2016) Remote Sens. Environ, 187, pp. 76-90; Liu, S., Chi, M., Zou, Y., Samat, A., Benediktsson, J.A., Plaza, A., Oil spill detection via multitemporal optical remote sensing images: A change detection perspective (2017) IEEE Geosci. Remote Sens. Lett, 14 (3), pp. 324-328. , Mar; Qi, Z., Yeh, A., Li, X., Zhang, X., A three-component method for timely detection of land cover changes using polarimetric SAR images (2015) ISPRS J. Photogramm. Remote Sens, 107, pp. 3-21; Liu, S., Bruzzone, L., Bovolo, F., Du, P., Unsupervised multitemporal spectral unmixing for detecting multiple changes in hyperspectral images (2016) IEEE Trans. Geosci. Remote Sens, 54 (5), pp. 2733-2748. , May; Bruzzone, L., Serpico, S., An iterative technique for the detection of land-cover transitions in multitemporal remote-sensing images (1997) IEEE Trans. Geosci. Remote Sens, 35 (4), pp. 858-867. , Jul; Liu, S., Bruzzone, L., Bovolo, F., Zanetti, M., Du, P., Sequential spectral change vector analysis for iteratively discovering and detecting multiple changes in hyperspectral images (2015) IEEE Trans. Geosci. Remote Sens, 53 (8), pp. 4363-4378. , Aug; Bovolo, F., Bruzzone, L., A theoretical framework for unsupervised change detection based on change vector analysis in the polar domain (2007) IEEE Trans. Geosci. Remote Sens, 45 (1), pp. 218-236. , Jan; Liu, S., Bruzzone, L., Bovolo, F., Du, P., Hierarchical unsupervised change detection in multitemporal hyperspectral images (2015) IEEE Trans. Geosci. Remote Sens, 53 (1), pp. 244-260. , Jan; Celik, T., Unsupervised change detection in satellite images using principal component analysis and k-means clustering (2009) IEEE Geosci. Remote Sens. Lett, 6 (4), pp. 772-776. , Oct; Nielsen, A.A., The regularized iteratively reweighted MAD method for change detection in multi-and hyperspectral data (2007) IEEE Trans. Image Process, 16 (2), pp. 463-478. , Feb; Wu, C., Du, B., Zhang, L., A subspace-based change detection method for hyperspectral images (2013) IEEE J. Sel. Topics. Appl. Earth Observ. Remote Sens, 6 (2), pp. 815-830. , Apr; Lu, J., Li, J., Chen, G., Zhao, L., Xiong, B., Kuang, G., Improving pixel-based change detection accuracy using an object-based approach in multitemporalSARflood images (2015) IEEE J. Sel. Topics. Appl. Earth Observ. Remote Sens, 8 (7), pp. 3486-3496. , Jul; Wang, Q., Yuan, Z., Du, Q., Li, X., GETNET: A general end-to-end 2-D CNN framework for hyperspectral image change detection (2019) IEEE Trans. Geosci. Remote Sens, 57 (1), pp. 3-13. , Jan; Li, X., Yuan, Z., Wang, Q., Unsupervised deep noise modeling for hyperspectral image change detection (2019) Remote Sens, 11 (3), pp. 258-274; Zhang, P., Gong, M., Su, L., Liu, J., Li, Z., Change detection based on deep feature representation and mapping transformation for multi-spatialresolution remote sensing images (2016) ISPRS J. Photogramm. Remote Sens, 116, pp. 24-41; Ertürk, A., Plaza, A., Informative change detection by unmixing for hyperspectral images (2015) IEEE Geosci. Remote Sens. Lett, 12 (6), pp. 1252-1256. , Jun; Bazi, Y., Melgani, F., Al-Sharari, H., Unsupervised change detection in multispectral remotely sensed imagery with level set methods (2010) IEEE Trans. Geosci. Remote Sens, 48 (8), pp. 3178-3187. , Aug; Bruzzone, L., Prieto, D., Automatic analysis of the difference image for unsupervised change detection (2000) IEEE Trans. Geosci. Remote Sens, 38 (3), pp. 1171-1182. , May; Du, P., Liu, S., Gamba, P., Tan, K., Xia, J., Fusion of difference images for change detection over urban areas (2012) IEEE J. Sel. Topics. Appl. Earth Observ. Remote Sens, 5 (4), pp. 1076-1086. , Aug; Du, P., Liu, S., Xia, J., Zhao, Y., Information fusion techniques for change detection frommulti-temporal remote sensing images (2013) Inf. Fusion, 14 (1), pp. 19-27; Le Hégarat-Mascle, S., Seltz, R., Automatic change detection by evidential fusion of change indices (2004) Remote Sens. Environ, 91 (3), pp. 390-404; Nemmour, H., Chibani, Y., Multiple support vector machines for land cover change detection: An application for mapping urban extensions (2006) ISPRS J. Photogramm. Remote Sens, 61 (2), pp. 125-133; Tarantino, C., Adamo, M., Lucas, R., Blonda, P., Detection of changes in semi-natural grasslands by cross correlation analysis withWorldView-2 images and new Landsat 8 data (2016) Remote Sens. Environ, 175, pp. 65-72; Tewkesbury, A.P., Comber, A.J., Tate, N.J., Lamb, A., Fisher, P., A critical synthesis of remotely sensed optical image change detection techniques (2015) Remote Sens. Environ, 160, pp. 1-14; Wen, D., Huang, X., Zhang, L., Benediktsson, J., A novel automatic change detection method for urban high-resolution remotely sensed imagery based on multi-index scene representation (2016) IEEE Trans. Geosci. Remote Sens, 54 (1), pp. 609-625. , Jan; Yuan, Y., Lv, H., Lu, X., Semi-supervised change detection method for multi-temporal hyperspectral images (2015) Neurocomputing, 148, pp. 363-375; Bovolo, F., A multilevel parcel-based approach to change detection in very high resolution multitemporal images (2009) IEEE Geosci. Remote Sens. Lett, 6 (1), pp. 33-37. , Jan; He, P., Shi, W., Zhang, H., Hao, M., A novel dynamic threshold method for unsupervised change detection from remotely sensed images (2014) Remote Sens. Lett, 5 (4), pp. 396-403; Melgani, F., Bazi, Y., Markovian fusion approach to robust unsupervised change detection in remotely sensed imagery (2006) IEEE Geosci. Remote Sens. Lett, 3 (4), pp. 457-461. , Oct; Zhuang, H., Deng, K., Fan, H., Yu, M., Strategies combining spectral anglemapper and change vector analysis to unsupervised change detection in multispectral images (2016) IEEE Geosci. Remote Sens. Lett, 13 (5), pp. 681-685. , May; Carvalho, O., Guimares, R., Gillespie, A., Silva, N., Gomes, R., A new approach to change vector analysis using distance and similarity measures (2011) Remote Sens, 3 (11), pp. 2473-2493; Zakeri, F., Huang, B., Saradjian, M., Fusion of change vector analysis in posterior probability space and post classification comparison for change detection from multispectral remote sensing data (2019) Remote Sens, 11 (13), pp. 1151-1524; Castellana, L., D'Addabbo, A., Pasquariello, G., A composed supervised/unsupervised approach to improve change detection from remote sensing (2007) Pattern Recognit. Lett, 28 (4), pp. 405-413; Yu, W., Zhou, W., Qian, Y., Yan, J., A new approach for land cover classification and change analysis: Integrating backdating and an objectbased method (2016) Remote Sens. Environ, 177, pp. 37-47; Zurita-Milla, R., Gómez-Chova, L., Guanter, L., Clevers, J., Camps-Valls, G., Multitemporal unmixing of medium-spatial-resolution satellite images: A case study using MERIS images for land-cover mapping (2011) IEEE Trans. Geosci. Remote Sens, 49 (11), pp. 4308-4317. , Nov; Bovolo, F., Marchesi, S., Bruzzone, L., A framework for automatic and unsupervised detection of multiple changes in multitemporal images (2012) IEEE Trans. Geosci. Remote Sens, 50 (6), pp. 2196-2212. , Jun; Marinelli, D., Bovolo, F., Bruzzone, L., A novel change detection method for multitemporal hyperspectral images based on binary hyperspectral change vectors (2019) IEEE Trans.Geosci. Remote Sens, 57 (7), pp. 4928-4931. , Jul; Demir, B., Bovolo, F., Bruzzone, L., Updating land-cover maps by classification of image time series: A novel change-detection-driven transfer learning approach (2013) IEEE Trans. Geosci. Remote Sens, 51 (1), pp. 300-312. , Jan; Xian, G., Homer, C., Fry, J., Updating the 2001 National Land Cover Database land cover classification to 2006 by using Landsat imagery change detection methods (2009) Remote Sens. Environ, 113 (6), pp. 1133-1147; Xian, G., Homer, C., Updating the 2001 National Land CoverDatabase impervious surface products to 2006 using Landsat imagery change detection methods (2010) Remote Sens. Environ, 114 (8), pp. 1676-1686; Bovolo, F., Bruzzone, L., Marconcini, M., A novel approach to unsupervised change detection based on a semisupervised SVM and a similarity measure (2008) IEEE Trans. Geosci. Remote Sens, 46 (7), pp. 2070-2082. , Jul; Otsu, N., A threshold selection method from gray-level histograms (1975) Automatica, 11, pp. 285-296; Rajan, S., Ghosh, J., Crawford, M., An active learning approach to hyperspectral data classification (2008) IEEE Trans. Geosci. Remote Sens, 46 (4), pp. 1231-1242. , Apr; Demir, B., Bovolo, F., Bruzzone, L., Detection of land-cover transitions in multitemporal remote sensing images with active-learning-based compound classification (2012) IEEE Trans. Geosci. Remote Sens, 50 (5), pp. 1930-1941. , May; Li, M., Sethi, I., Confidence-based active learning (2006) IEEE Trans. Pattern Anal, 28 (8), pp. 1251-1261. , Aug; Sharma Andmbilgic, M., Evidence-based uncertainty sampling for active learning (2016) Data Mining Knowl. Discovery, 31 (1), pp. 1-39; Xu, H., Wang, X., Liao, Y., Zheng, C., An uncertainty sampling-based active learning approach for support vector machines (2009) Proc. Int. Conf. Artif. Intell. Comput. Intell, pp. 208-213. , Washington, DC, USA; MacKay, D., Information-based objective functions for active data selection (1992) Neural Comput, 4 (4), pp. 590-604; Gu, Q., Zhang, T., Han, J., Ding, C., Selective labeling via error bound minimization (2012) Proc. Adv. Neural Inf. Process. Syst, pp. 323-331; Pan, S., Yang, Q., A survey on transfer learning (2010) IEEE Trans. Knowl. Data Eng, 22 (10), pp. 1345-1359. , Oct; Tan, K., Hu, J., Li, J., Du, P., A novel semi-supervised hyperspectral image classification approach based on spatial neighborhood information and classifier combination (2015) ISPRS J. Photogramm. Remote Sens, 105, pp. 19-29},
correspondence_address1={Tong, X.; College of Surveying and Geo-Informatics, China; email: xhtong@tongji.edu.cn},
publisher={Institute of Electrical and Electronics Engineers},
issn={19391404},
language={English},
abbrev_source_title={IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Kellenberger20199524,
author={Kellenberger, B. and Marcos, D. and Lobry, S. and Tuia, D.},
title={Half a percent of labels is enough: Efficient animal detection in UAV imagery using deep CNNs and active learning},
journal={IEEE Transactions on Geoscience and Remote Sensing},
year={2019},
volume={57},
number={12},
pages={9524-9533},
doi={10.1109/TGRS.2019.2927393},
art_number={8807383},
note={cited By 19},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075681789&doi=10.1109%2fTGRS.2019.2927393&partnerID=40&md5=9dc54f5690e84064404035fb9cca2691},
affiliation={Laboratory of GeoInformation Science and Remote Sensing, Wageningen University, Wageningen, 6708 PB, Netherlands},
abstract={We present an Active Learning (AL) strategy for reusing a deep Convolutional Neural Network (CNN)-based object detector on a new data set. This is of particular interest for wildlife conservation: Given a set of images acquired with an Unmanned Aerial Vehicle (UAV) and manually labeled ground truth, our goal is to train an animal detector that can be reused for repeated acquisitions, e.g., in follow-up years. Domain shifts between data sets typically prevent such a direct model application. We thus propose to bridge this gap using AL and introduce a new criterion called Transfer Sampling (TS). TS uses Optimal Transport (OT) to find corresponding regions between the source and the target data sets in the space of CNN activations. The CNN scores in the source data set are used to rank the samples according to their likelihood of being animals, and this ranking is transferred to the target data set. Unlike conventional AL criteria that exploit model uncertainty, TS focuses on very confident samples, thus allowing quick retrieval of true positives in the target data set, where positives are typically extremely rare and difficult to find by visual inspection. We extend TS with a new window cropping strategy that further accelerates sample retrieval. Our experiments show that with both strategies combined, less than half a percent of oracle-provided labels are enough to find almost 80% of the animals in challenging sets of UAV images, beating all baselines by a margin. © 1980-2012 IEEE.},
author_keywords={Active Learning (AL);  animal census;  convolutional neural networks;  domain adaptation;  object detection;  Optimal Transport (OT);  unmanned aerial vehicles},
keywords={Animals;  Antennas;  Conservation;  Convolution;  Deep neural networks;  Neural networks;  Object detection;  Uncertainty analysis;  Unmanned aerial vehicles (UAV), Active Learning;  Animal census;  Convolutional neural network;  Domain adaptation;  Optimal transport, Aircraft detection, aerial survey;  data acquisition;  data set;  detection method;  imagery;  machine learning;  numerical model;  uncertainty analysis, Animalia},
funding_details={Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen ForschungSchweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung, SNF, PP00P2_150593},
funding_text 1={Manuscript received January 18, 2019; revised June 26, 2019; accepted July 2, 2019. Date of publication August 20, 2019; date of current version November 25, 2019. This work was supported by the Swiss National Science Foundation under Grant PP00P2_150593. (Corresponding author: Devis Tuia.) The authors are with the Laboratory of GeoInformation Science and Remote Sensing, Wageningen University, 6708 PB Wageningen, The Netherlands (e-mail: devis.tuia@wur.nl).},
references={Hodgson, A., Kelly, N., Peel, D., Unmanned aerial vehicles (UAVs) for surveying marine fauna: A dugong case study (2013) PloS One, 8 (11). , Art. no. e79556; Yang, Z., Wang, T., Skidmore, A.K., Leeuw, J.D., Said, M.Y., Freer, J., Spotting east African mammals in open savannah from space (2014) PloS One, 9 (12). , Art. no. e115989; Bayliss, P., Yeomans, K.M., Distribution and abundance of feral livestock in the 'Top End' of the Northern Territory (1985-86), and their relation to population control (1989) Wildlife Res., 16 (6), pp. 651-676; Norton-Griffiths, M., Counting animals (1978) Serengeti Ecological Monitoring Programme, (1). , Nairobi, Kenya: African Wildlife Leadership Foundation; Linchant, J., Lisein, J., Semeki, J., Lejeune, P., Vermeulen, C., Are unmanned aircraft systems (UASs) the future of wildlife monitoring? A review of accomplishments and challenges (2015) Mammal Rev., 45 (4), pp. 239-252. , Oct; Hodgson, J.C., Drones count wildlife more accurately and precisely than humans (2018) Methods Ecology Evol., 9, pp. 1160-1167. , May; Rey, N., Volpi, M., Joost, S., Tuia, D., Detecting animals in African Savanna with UAVs and the crowds (2017) Remote Sens. Environ., 200, pp. 341-351. , Oct; Kellenberger, B., Marcos, D., Tuia, D., Detecting mammals in UAV images: Best practices to address a substantially imbalanced dataset with deep learning (2018) Remote Sens. Environ., 216, pp. 139-153. , Oct; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Towards realtime object detection with region proposal networks (2015) Proc. Adv. Neural Inf. Process. Syst., pp. 1-10; Redmon, J., Divvala, S., Girshick, R., Farhadi, A., You only look once: Unified, real-time object detection (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 779-788. , Jun; Redmon, J., Farhadi, A., YOLO9000: Better, faster, stronger (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 7263-7271. , Jul; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Proc. Adv. Neural Inf. Process. Syst., pp. 1097-1105; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521, p. 436. , May; Tuia, D., Persello, C., Bruzzone, L., Domain adaptation for the classification of remote sensing data: An overview of recent advances (2016) IEEE Geosci. Remote Sens. Mag., 4 (2), pp. 41-57. , Jun; Tuia, D., Volpi, M., Copa, L., Kanevski, M., Munoz-Mari, J., A survey of active learning algorithms for supervised remote sensing image classification (2011) IEEE J. Sel. Topics Signal Process., 5 (3), pp. 606-617. , Jun; Settles, B., Active learning (2012) Synth. Lectures Artif. Intell. Mach. Learn., 6 (1), pp. 1-114; Luo, T., Active learning to recognize multiple types of plankton (2005) J. Mach. Learn. Res., 6, pp. 589-613. , Apr; Schon, G., Cohn, D., Less is more: Active learning with support vector machines (2000) Proc. 7th Int. Conf. Mach. Learn., pp. 839-846. , Jun; Cai, W., Zhang, Y., Zhou, J., Maximizing expected model change for active learning in regression (2013) Proc. IEEE 13th Int. Conf. Data Mining, pp. 51-60. , Dec; Gal, Y., Islam, R., Ghahramani, Z., Deep Bayesian active learning with image data (2017) Proc. Adv. Neural Inf. Process. Syst., pp. 1183-1192; Santoro, A., Bartunov, S., Botvinick, M., Wierstra, D., Lillicrap, T., (2016) One-shot Learning with Memory-augmented Neural Networks, , https://arxiv.org/abs/1605.06065, May; Cuturi, M., Sinkhorn distances: Lightspeed computation of optimal transport (2013) Proc. Adv. Neural Inf. Process. Syst., pp. 2292-2300. , Jun; Van Der Maaten, L., Hinton, G., Visualizing high-dimensional data using t-SNE (2008) J. Mach. Learn. Res., 9, pp. 2579-2605. , Nov; Cortes, C., Vapnik, V., Support vector machine (1995) Mach. Learn., 20 (3), pp. 273-297; Courty, N., Flamary, R., Tuia, D., Rakotomamonjy, A., Optimal transport for domain adaptation (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39 (9), pp. 1853-1865. , Sep; Ofli, F., Combining human computing and machine learning to make sense of big (aerial) data for disaster response (2016) Big Data, 4 (1), pp. 47-59. , Mar; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 770-778. , Jun; Russakovsky, O., ImageNet large scale visual recognition challenge (2015) Int. J. Comput. Vis., 115 (3), pp. 211-252. , Dec; Ulyanov, D., Vedaldi, A., Lempitsky, V., (2016) Instance Normalization: The Missing Ingredient for Fast Stylization, , https://arxiv.org/abs/1607.08022, Jul; Kao, C.-C., Lee, T.-Y., Sen, P., Liu, M.-Y., Localization-aware active learning for object detection (2019) Proc. Asian Conf. Comput. Vis., pp. 506-522. , May; Tuia, D., Munoz-Mari, J., Learning User's confidence for active learning (2013) IEEE Trans. Geosci. Remote Sens., 51 (2), pp. 872-880. , Feb},
correspondence_address1={Tuia, D.; Laboratory of GeoInformation Science and Remote Sensing, Netherlands; email: devis.tuia@wur.nl},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={01962892},
coden={IGRSD},
language={English},
abbrev_source_title={IEEE Trans Geosci Remote Sens},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Cincovic2019,
author={Cincovic, J. and Tartalja, I.},
title={Experience in Developing Multiplatform Educational Video-Game},
journal={27th Telecommunications Forum, TELFOR 2019},
year={2019},
doi={10.1109/TELFOR48224.2019.8971353},
art_number={8971353},
note={cited By 0; Conference of 27th Telecommunications Forum, TELFOR 2019 ; Conference Date: 26 November 2019 Through 27 November 2019;  Conference Code:157254},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079329570&doi=10.1109%2fTELFOR48224.2019.8971353&partnerID=40&md5=6fb1b079f81483b12b414e385d2ee9fb},
affiliation={Bulevar Kralja Aleksandra, 73 Elektrotehnički fakultet u Beogradu, Beograd, 11120, Serbia},
abstract={Pre-school and school institutions, as the main sources of education, have constant challenges to follow the speed of technology development and to make knowledge transfer effective and efficient through an active learning process. The idea of active learning is that every student, in an independent and creative way, comes to the necessary knowledge and gets involved in the work. Video games are exactly the ones that can be used to hold students' attention, and that allow the positive mood during playing the game to be utilized for acquiring new knowledge. As a result of solving this problem, an educational multiplatform 3D video game Olympics of Knowledge was created, consisting of three applications: Portal, application for promoting the game and monitoring the progress of players, Editor, tool for preparation of competitions and Competition, a board game combined with a knowledge quiz. © 2019 IEEE.},
author_keywords={active learning;  education;  knowledge quiz;  question;  question area;  video game},
keywords={Education;  Human computer interaction;  Interactive computer graphics;  Knowledge management;  Students;  Transfer learning, Active Learning;  knowledge quiz;  question;  question area;  Video game, Three dimensional computer graphics},
references={Iijima, S., Carbon nanotube (2007) Innovative Engine, column for NEC researchers; Ivic, I., Pešikani, A., Antic, S., (2001) Aktivno u-enje 2, , Institut za psihologiju; Griffiths, M.D., The educational benefits of videogames (2002) Education and Health, 20 (3), pp. 47-51; Gee, J.P., Good video games and good learning (2005) Phi Kappa Phi Forum, 85 (2), pp. 33-37; Cincovic, J., (2019) Razvoj društvene VIšeplatformske 3D VIdeo-igre sa integrisanim kVIzom znanja, , master rad, Elektrotehni-ki fakultet u Beogradu; Slavkovic, M., Durdevici, D., Tartalja, I., Razvoj visoko prilagodljive obrazovne igre Olimpijada znanja (2011) Info-M, 39, pp. 48-54; Slavkovic, M., Durdevic, D., Tartalja, I., Razvoj obrazovne igre u JavaFX tehnologiji (2014) InfoM, 49, pp. 4-13},
sponsors={"Telekom Srbija" a.d.; et al.; Ministry of Trade, Tourism and Telecommunications; Nokia; Temporary List; VLATACOM d.o.o},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728147895},
language={English},
abbrev_source_title={Telecommun. Forum, TELFOR},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Liu20196121,
author={Liu, Z. and Wang, J. and Gong, S. and Tao, D. and Lu, H.},
title={Deep reinforcement active learning for human-in-the-loop person re-identification},
journal={Proceedings of the IEEE International Conference on Computer Vision},
year={2019},
volume={2019-October},
pages={6121-6130},
doi={10.1109/ICCV.2019.00622},
art_number={9010038},
note={cited By 9; Conference of 17th IEEE/CVF International Conference on Computer Vision, ICCV 2019 ; Conference Date: 27 October 2019 Through 2 November 2019;  Conference Code:158036},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081908739&doi=10.1109%2fICCV.2019.00622&partnerID=40&md5=db35af84b89e3eacd358ca17a9076bc8},
affiliation={Dalian University of Technology, China; UBTECH Sydney AI Center, University of Sydney, Australia; Queen Mary University of London, United Kingdom},
abstract={Most existing person re-identification(Re-ID) approaches achieve superior results based on the assumption that a large amount of pre-labelled data is usually available and can be put into training phrase all at once. However, this assumption is not applicable to most real-world deployment of the Re-ID task. In this work, we propose an alternative reinforcement learning based human-in-the-loop model which releases the restriction of pre-labelling and keeps model upgrading with progressively collected data. The goal is to minimize human annotation efforts while maximizing Re-ID performance. It works in an iteratively updating framework by refining the RL policy and CNN parameters alternately. In particular, we formulate a Deep Reinforcement Active Learning (DRAL) method to guide an agent (a model in a reinforcement learning process) in selecting training samples on-the-fly by a human user/annotator. The reinforcement learning reward is the uncertainty value of each human selected sample. A binary feedback (positive or negative) labelled by the human annotator is used to select the samples of which are used to fine-tune a pre-trained CNN Re-ID model. Extensive experiments demonstrate the superiority of our DRAL method for deep reinforcement learning based human-in-the-loop person Re-ID when compared to existing unsupervised and transfer learning models as well as active learning models. © 2019 IEEE.},
keywords={Computer vision;  Iterative methods;  Learning systems;  Reinforcement learning;  Rhenium compounds;  Transfer learning, Active Learning;  Binary feedback;  Human annotations;  Human-in-the-loop;  Large amounts;  Person re identifications;  Real world deployment;  Training sample, Deep learning},
funding_details={98111-571149},
funding_details={Alan Turing InstituteAlan Turing Institute},
funding_details={Australian Research CouncilAustralian Research Council, ARC, DP-180103424, FL-170100117},
funding_details={National Natural Science Foundation of ChinaNational Natural Science Foundation of China, NSFC, 61725202, 61751212, 61829102},
funding_details={China Scholarship CouncilChina Scholarship Council, CSC},
funding_details={Fundamental Research Funds for the Central UniversitiesFundamental Research Funds for the Central Universities},
funding_text 1={This work is supported by National Natural Science Foundation of China No.61725202, 61829102, 61751212; Fundamental Research Funds for the Central Universities under Grant No.DUT19GJ201; Vision Semantics Limited; the China Scholarship Council; Alan Turing Institute; Innovate UK Industrial Challenge Project on Developing and Commercialising Intelligent Video Analytics Solutions for Public Safety (98111-571149); and the Australian Research Council Projects: FL-170100117, DP-180103424.},
references={Abe, N., Mamitsuka, H., Query learning strategies using boosting and bagging (1998) ICML; Bak, S., Carr, P., Lalonde, J., Domain adaptation through synthesis for unsupervised person re-identification (2018) ECCV; Barz, B., Käding, C., Denzler, J., Information-theoretic active learning for content-based image retrieval (2018) PR; Beluch, W.H., Genewein, T., Nürnberger, A., Köhler, J.M., The power of ensembles for active learning in image classification (2018) CVPR; Chang, X., Hospedales, T.M., Xiang, T., Multi-level factorisation net for person re-identification (2018) CVPR; Chatterjee, M., Leuski, A., An active learning based approach for effective video annotation and retrieval (2015) NIPS; Chen, W., Chen, X., Zhang, J., Huang, K., Beyond triplet loss: A deep quadruplet network for person re-identification (2017) CVPR; Chen, Y., Wang, Z., Peng, Y., Zhang, Z., Yu, G., Sun, J., Cascaded pyramid network for multi-person pose estimation (2018) CVPR; De, C., Gong, Y., Zhou, S., Wang, J., Zheng, N., Person re-identification by multi-channel parts-based cnn with improved triplet loss function (2016) CVPR; Chung, D., Tahboub, K., Delp, E.J., A two stream siamese convolutional neural network for person re-identification (2017) ICCV; Deng, W., Zheng, L., Kang, G., Yang, Y., Ye, Q., Jiao, J., Image-image domain adaptation with preserved self-similarity and domain-dissimilarity for person reidentification (2018) CVPR; Ebert, S., Fritz, M., Schiele, B., RALF: A reinforced active learning formulation for object class recognition (2012) CVPR; Wu, Y., Progressive learning for person re-identification with one example (2019) TIP; Fan, H., Zheng, L., Yan, C., Yang, Y., Unsupervised person re-identification: Clustering and finetuning (2018) ACM; Fang, M., Li, Y., Cohn, T., Learning how to active learn: A deep reinforcement learning approach (2017) EMNLP; En Gad, E., Gadde, A., Salman Avestimehr, A., Ortega, A., Active learning on weighted graphs using adaptive and non-adaptive approaches (2016) ICASSP; Henri Gosselin, P., Cord, M., Active learning methods for interactive image retrieval (2008) TIP; Guo, H., Wang, W., An active learning-based SVM multi-class classification model (2015) PR; Guo, Y., Cheung, N., Efficient and deep person re-identification using multi-level similarity (2018) CVPR; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) CVPR; Hermans, A., Beyer, L., Leibe, B., In defense of the triplet loss for person re-identification (2017) CoRR; Lewis Gale, D.D., Gale, W.A., Training text classifiers by uncertainty sampling (1994) SIGIR; Li, M., Zhu, X., Gong, S., Unsupervised person re-identification by deep learning tracklet association (2018) ECCV; Li, W., Zhao, R., Wang, X., Human reidentification with transfered metric learning (2012) ACCV; Li, W., Zhu, X., Gong, S., Harmonious attention network for person re-identification (2018) CVPR; Li, Y., Yang, F., Liu, Y., Yeh, Y., Du, X., Frank Wang, Y., Adaptation and reidentification network: An unsupervised deep transfer learning approach to person re-identification (2018) CVPR; Liu, X., Song, M., Tao, D., Zhou, X., Chen, C., Bu, J., Semi-supervised coupled dictionary learning for person re-identification (2014) CVPR; Lv, J., Chen, W., Li, Q., Yang, C., Unsupervised cross-dataset person re-identification by transfer learning of spatial-temporal patterns (2018) CVPR; Ma, F., Meng, D., Xie, Q., Li, Z., Dong, X., Self-paced co-training (2017) ICML; Ma, Y., Huang, T., Schneider, J.G., Active search and bandits on graphs using sigma-optimality (2015) UAI; Paul, S., Bappy, J.H., Roy-Chowdhury, A.K., Non-uniform subset selection for active learning in structured data (2017) CVPR; Peng, P., Xiang, T., Wang, Y., Pontil, M., Gong, S., Huang, T., Tian, Y., Unsupervised cross-dataset transfer learning for person reidentification (2016) CVPR; Qian, X., Fu, Y., Jiang, Y., Xiang, T., Xue, X., Multi-scale deep learning architectures for person re-identification (2017) ICCV; Ristani, E., Solera, F., Zou, R.S., Cucchiara, R., Tomasi, C., Performance measures and a data set for multi-target, multi-camera tracking (2016) ECCV Workshops; Saquib Sarfraz, M., Schumann, A., Eberle, A., Stiefelhagen, R., A pose-sensitive embedding for person re-identification with expanded cross neighborhood reranking (2018) CVPR; Shen, Y., Li, H., Yi, S., Chen, D., Wang, X., Person re-identification with deep similarity-guided graph neural network (2018) ECCV; Shi, Z., Hospedales, T.M., Xiang, T., Transferring a semantic representation for person re-identification and search (2015) CVPR; Su, C., Li, J., Zhang, S., Xing, J., Gao, W., Tian, Q., Pose-driven deep convolutional model for person re-identification (2017) ICCV; Su, C., Yang, F., Zhang, S., Tian, Q., Davis, L.S., Gao, W., Multi-task learning with low rank attribute embedding for person re-identification (2015) ICCV; Su, C., Zhang, S., Xing, J., Gao, W., Tian, Q., Deep attributes driven multi-camera person reidentification (2016) ECCV; Su, H., Yin, Z., Kanade, T., Huh, S., Active sample selection and correction propagation on a gradually-augmented graph (2015) CVPR; Taha, A., Chen, Y., Misu, T., Shrivastava, A., Davis, L., Unsupervised data uncertainty learning in visual retrieval systems (2019) CoRR; Wang, H., Gong, S., Zhu, X., Xiang, T., Human-in-the-loop person re-identification (2016) ECCV; Wang, J., Zhu, X., Gong, S., Li, W., Transferable joint attribute-identity deep learning for unsupervised person re-identification (2018) CVPR; Wang, Y., Chen, Z., Wu, F., Wang, G., Person re-identification with cascaded pairwise convolutions (2018) CVPR; Wei, L., Zhang, S., Gao, W., Tian, Q., Person transfer gan to bridge domain gap for person reidentification (2018) CVPR; Woodward, M., Finn, C., Active one-shot learning (2017) CoRR; Yu, H., Wu, A., Zheng, W., Crossview asymmetric metric learning for unsupervised person reidentification (2017) ICCV; Zhang, C., Chaudhuri, K., Beyond disagreement-based agnostic active learning (2014) NIPS; Zhang, L., Xiang, T., Gong, S., Learning a discriminative null space for person re-identification (2016) CVPR; Zhang, Y., Li, B., Lu, H., Irie, A., Ruan, X., Sample-specific SVM learning for person reidentification (2016) CVPR; Zhang, Y., Xiang, T., Hospedales, T.M., Lu, H., Deep mutual learning (2018) CVPR; Zhao, H., Tian, M., Sun, S., Shao, J., Yan, J., Yi, S., Wang, X., Tang, X., Spindle net: Person re-identification with human body region guided feature decomposition and fusion (2017) CVPR; Zheng, L., Shen, L., Tian, L., Wang, S., Wang, J., Tian, Q., Scalable person re-identification: A benchmark (2015) ICCV; Zheng, Z., Zheng, L., Yang, Y., Unlabeled samples generated by gan improve the person re-identification baseline in vitro (2017) ICCV; Zheng, Z., Zheng, L., Yang, Y., Pedestrian alignment network for large-scale person re-identification (2018) TCSVT; Zhong, Z., Zheng, L., Cao, D., Li, S., Reranking person re-identification with k-reciprocal encoding (2017) CVPR; Zhu, J., Wang, H., Tsou, B.K., Ma, M.Y., Active learning with sampling by uncertainty and density for data annotations (2010) TASLP},
correspondence_address1={Liu, Z.; Dalian University of TechnologyChina; email: lzm920316@gmail.com},
sponsors={Computer Vision Foundation; IEEE},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={15505499},
isbn={9781728148038},
coden={PICVE},
language={English},
abbrev_source_title={Proc IEEE Int Conf Comput Vision},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Lin20191900,
author={Lin, Y. and Li, M. and Watanabe, Y. and Kimura, T. and Matsunawa, T. and Nojima, S. and Pan, D.Z.},
title={Data Efficient Lithography Modeling with Transfer Learning and Active Data Selection},
journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
year={2019},
volume={38},
number={10},
pages={1900-1913},
doi={10.1109/TCAD.2018.2864251},
art_number={8428441},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051383319&doi=10.1109%2fTCAD.2018.2864251&partnerID=40&md5=687240422c034f64e1e460dc5f0324df},
affiliation={Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, TX  78741, United States; Memory Lithography Group, Toshiba Memory Corporation, Yokohama, 247-8585, Japan},
abstract={Lithography simulation is one of the key steps in physical verification, enabled by the substantial optical and resist models. A resist model bridges the aerial image simulation to printed patterns. While the effectiveness of learning-based solutions for resist modeling has been demonstrated, they are considerably data-demanding. Meanwhile, a set of manufactured data for a specific lithography configuration is only valid for the training of one single model, indicating low data efficiency. Due to the complexity of the manufacturing process, obtaining enough data for acceptable accuracy becomes very expensive in terms of both time and cost, especially during the evolution of technology generations when the design space is intensively explored. In this paper, we propose a new resist modeling framework for contact layers, utilizing existing data from old technology nodes and active selection of data in a target technology node, to reduce the amount of data required from the target lithography configuration. Our framework based on transfer learning and active learning techniques is effective within a competitive range of accuracy, i.e., 3 \times -10 \times reduction on the amount of training data with comparable accuracy to the state-of-the-art learning approach. © 1982-2012 IEEE.},
author_keywords={Active learning;  convolutional neural networks (CNNs);  lithography modeling;  machine learning;  residual neural networks (ResNet);  transfer learning},
keywords={Data structures;  Lithography;  Microstrip antennas;  Neural networks;  Optical design, Active Learning;  Computational model;  Convolutional neural network;  Lithography modeling;  Optical imaging;  Predictive models;  Resists;  Transfer learning, Learning systems},
funding_details={National Science FoundationNational Science Foundation, NSF, CCF-1718570},
funding_text 1={Manuscript received February 23, 2018; revised May 24, 2018; accepted July 20, 2018. Date of publication August 7, 2018; date of current version September 18, 2019. This work was supported in part by the National Science Foundation under Project CCF-1718570, and in part by Toshiba Memory Corporation. This paper was recommended by Associate Editor I. H.-R. Jiang. (Corresponding author: Yibo Lin.) Y. Lin, M. Li, and D. Z. Pan are with the Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, TX 78741 USA (e-mail: yibolin@utexas.edu).},
references={Liebmann, L., Chu, A., Gutwin, P., The daunting complexity of scaling to 7NM without EUV: Pushing DTCO to the extreme (2015) Proc. SPIE, 9427. , San Jose, CA, USA; Liebmann, L., Overcoming scaling barriers through design technology cooptimization (2016) Proc. IEEE Symp. VLSI Technol., pp. 1-2; Shim, S., Choi, S., Shin, Y., Machine learning-based resist 3D model (2017) Proc. SPIE, , 10147. San Jose, CA, USA; Watanabe, Y., Kimura, T., Matsunawa, T., Nojima, S., Accurate lithography simulation model based on convolutional neural networks (2017) Proc. SPIE Adv. Lithography, , San Jose, CA, USA; Ma, X., Fast lithography aerial image calculation method based on machine learning (2017) Appl. Opt., 56 (23), pp. 6485-6495; Wuu, J.-Y., Pikus, F.G., Marek-Sadowska, M., Efficient approach to early detection of lithographic hotspots using machine learning systems and pattern matching (2011) Proc. SPIE Adv. Lithography, , San Jose, CA, USA; Matsunawa, T., Nojima, S., Kotani, T., Automatic layout feature extraction for lithography hotspot detection based on deep neural network (2016) Proc. SPIE, 9781. , San Jose, CA, USA; Matsunawa, T., Yu, B., Pan, D.Z., Laplacian eigenmaps-and Bayesian clustering-based layout pattern sampling and its applications to hotspot detection and optical proximity correction (2016) J. Micro Nanolithography MEMS MOEMS, 15 (4); Zhang, H., Yu, B., Young, E.F., Enabling online learning in lithography hotspot detection with information-theoretic feature optimization (2016) Proc. 35th Int. Conf. Comput.-Aided Design, p. 47; Shin, M., Lee, J.-H., Accurate lithography hotspot detection using deep convolutional neural networks (2016) J. Micro Nanolithography MEMS MOEMS (JM3), 15 (4); Yang, H., Luo, L., Su, J., Lin, C., Yu, B., Imbalance aware lithography hotspot detection: A deep learning approach (2017) J. Micro Nanolithography MEMS MOEMS, 16 (3); Yang, H., Layout hotspot detection with feature tensor generation and deep biased learning IEEE Trans. Comput.-Aided Design Integr. Circuits Syst., , to be published; Yang, H., Lin, Y., Yu, B., Young, F.E., Lithography hotspot detection: From shallow to deep learning (2017) Proc. IEEE Int. Syst. Chip Conf. (SOCC), pp. 233-238; Zhang, H., Zhu, F., Li, H., Young, E.F., Yu, B., Bilinear lithography hotspot detection (2017) Proc. ACM Int. Symp. Phys. Design, pp. 7-14; Lin, Y., Xu, X., Ou, J., Pan, D.Z., Machine learning for mask/wafer hotspot detection and mask synthesis (2017) Proc. Photomask Technol., , 10451; Yang, H., Li, S., Tabery, C., Lin, B., Yu, B., (2018) Bridging the Gap between Layout Pattern Sampling and Hotspot Detection Via Batch Active Learning, , http://adsabs.harvard.edu/abs/2018arXiv180706446Y, ArXiv e-prints, Jul; Gu, A., Zakhor, A., Optical proximity correction with linear regression (2008) IEEE Trans. Semicond. Manuf., 21 (2), pp. 263-271. , May; Jia, N., Lam, E.Y., Machine learning for inverse lithography: Using stochastic gradient descent for robust photomask synthesis (2010) J. Opt., 12 (4); Luo, R., Optical proximity correction using a multilayer perceptron neural network (2013) J. Opt., 15 (7); Matsunawa, T., Yu, B., Pan, D.Z., Optical proximity correction with hierarchical Bayes model (2016) J. Micro Nanolithography MEMS MOEMS, 15 (2); Xu, X., Subresolution assist feature generation with supervised data learning (2018) IEEE Trans. Comput.-Aided Design Integr. Circuits Syst., 37 (6), pp. 1225-1236. , Jun; Tan, C.B., Koh, K.K., Zhang, D., Foong, Y.M., Sub-resolution assist feature (SRAF) printing prediction using logistic regression (2015) Proc. SPIE; (2008) Calibre Verification User's Manual, Mentor Graphics, , Wilsonville, OR, USA; Liebmann, L.W., TCAD development for lithography resolution enhancement (2001) IBM J. Res. Develop., 45 (5), pp. 651-665; Hanna, J.P., Stone, P., Grounded action transformation for robot learning in simulation (2017) Proc. AAAI, pp. 3834-3840; Rusu, A.A., (2016) Progressive Neural Networks, , http://adsabs.harvard.edu/abs/2016arXiv160604671R, Jun. ArXiv eprints; Pan, S.J., Yang, Q., A survey on transfer learning (2010) IEEE Trans. Knowl. Data Eng., 22 (10), pp. 1345-1359. , Oct; Sener, O., Savarese, S., Active learning for convolutional neural networks: A core-set approach (2018) Proc. Int. Conf. Learn. Represent., , https://openreview.net/forum?id=H1aIuk-RW; Tong, S., Koller, D., Support vector machine active learning with applications to text classification (2001) J. Mach. Learn. Res., 2, pp. 45-66. , Nov; Berlind, C., Urner, R., Active nearest neighbors in changing environments (2015) Proc. Int. Conf. Mach. Learn., pp. 1870-1879; Donahue, J., Krähenbühl, P., Darrell, T., (2016) Adversarial Feature Learning, , http://arxiv.org/abs/1605.09782, CoRR abs/1605. 09782; Demir, B., Bruzzone, L., A multiple criteria active learning method for support vector regression (2014) Pattern Recognit., 47 (7), pp. 2558-2567; Fukumizu, K., Statistical active learning in multilayer perceptrons (2000) IEEE Trans. Neural Netw., 11 (1), pp. 17-26. , Jan; Zhuo, C., Agarwal, K., Blaauw, D., Sylvester, D., Active learning framework for post-silicon variation extraction and test cost reduction (2010) Proc. Int. Conf. Comput.-Aided Design, pp. 508-515; Lin, H., Li, P., Classifying circuit performance using active-learning guided support vector machines (2012) Proc. Int. Conf. Comput.-Aided Design, pp. 187-194; Li, M., Provably secure camouflaging strategy for IC protection IEEE Trans. Comput.-Aided Design Integr. Circuits Syst., , to be published; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning, , Cambridge, MA, USA: MIT Press; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 770-778; Bengio, Y., Simard, P., Frasconi, P., Learning long-term dependencies with gradient descent is difficult (1994) IEEE Trans. Neural Netw., 5 (2), pp. 157-166. , Mar; Glorot, X., Bengio, Y., Understanding the difficulty of training deep feedforward neural networks (2010) Proc. 13th Int. Conf. Artif. Intell. Stat., pp. 249-256; Jin, X., Han, J., K-medoids clustering (2010) Encyclopedia of Machine Learning, pp. 564-565. , C. Sammut and G. I. Webb, Eds. Boston, MA, USA: Springer; Kaufman, L., Rousseeuw, P.J., Partitioning around medoids (program PAM) (1990) Finding Groups in Data: An Introduction to Cluster Analysis, pp. 68-125. , New York, NY, USA: Wiley; Park, H.-S., Jun, C.-H., A simple and fast algorithm for K-medoids clustering (2009) Expert Syst. Appl., 36 (2), pp. 3336-3341; Arthur, D., Vassilvitskii, S., K-means++: The advantages of careful seeding (2007) Proc. 18th Annu. ACM SIAM Symp. Discr. Algorithms, pp. 1027-1035; Pedregosa, F., Scikit-learn: Machine learning in Python (2011) J. Mach. Learn. Res., 12, pp. 2825-2830. , Feb; Abadi, M., (2015) TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems, , https://www.tensorflow.org; (2016) Sentaurus Lithography, Synopsys, , https://www.synopsys.com/silicon/masksynthesis/sentaurus-lithography.html, Mountain View, CA, USA; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , http://arxiv.org/abs/1412.6980, CoRR abs/1412. 6980; Lin, Y., Data efficient lithography modeling with residual neural networks and transfer learning (2018) Proc. ACM Int. Symp. Phys. Design (ISPD), pp. 82-89. , Monterey, CA, USA, Mar},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={02780070},
coden={ITCSD},
language={English},
abbrev_source_title={IEEE Trans Comput Aided Des Integr Circuits Syst},
document_type={Article},
source={Scopus},
}

@ARTICLE{Coletta2019150,
author={Coletta, L.F.S. and Ponti, M. and Hruschka, E.R. and Acharya, A. and Ghosh, J.},
title={Combining clustering and active learning for the detection and learning of new image classes},
journal={Neurocomputing},
year={2019},
volume={358},
pages={150-165},
doi={10.1016/j.neucom.2019.04.070},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066088688&doi=10.1016%2fj.neucom.2019.04.070&partnerID=40&md5=3763d7425300f3d9c794f55e2e79deea},
affiliation={School of Sciences and Engineering, São Paulo State University, Tupã, SP, Brazil; University of São PauloSP, Brazil; Department of Electrical & Computer Engineering, University of Texas, Austin, United States},
abstract={Discriminative classification models often assume all classes are available at the training phase. As such models do not have a strategy to learn new concepts from available unlabeled instances, they usually work poorly when unknown classes emerge from future data to be classified. To address the appearance of new classes, some authors have developed approaches to transfer knowledge from known to unknown classes. Our study provides a more flexible approach to learn new (visual) classes that emerge over time. The key idea is materialized by an iterative classifier that combines Support Vector Machines with clustering via an optimization algorithm. An entropy and density-based selection strategy explores label uncertainty and high-density regions from unlabeled data to be classified. Selected instances from new classes are submitted to get labels and then used to improve the model. The proposed image classifier is consistently better than approaches that select instances randomly or from clusters. We also show that features obtained via Deep Learning methods improve results when compared with shallow features, but only using our selection strategy. Our approach requires fewer iterations to learn new classes, thereby significantly saving labeling costs. © 2019},
author_keywords={Active learning;  Clustering;  Deep learning;  Image classification;  Open set},
keywords={Artificial intelligence;  Clustering algorithms;  Image classification;  Iterative methods, Active Learning;  Classification models;  Clustering;  High density regions;  Image Classifiers;  Learning methods;  Open set;  Optimization algorithms, Deep learning, article;  deep learning;  entropy;  support vector machine;  uncertainty},
funding_details={Fundação de Amparo à Pesquisa do Estado de São PauloFundação de Amparo à Pesquisa do Estado de São Paulo, FAPESP, 2017/00357-7},
funding_text 1={We would like to acknowledge the São Paulo Research Foundation (FAPESP), grant #2017/00357-7 , for providing financial support.},
funding_text 2={None. We would like to acknowledge the S?o Paulo Research Foundation (FAPESP), grant #2017/00357-7, for providing financial support.},
references={(2014), Cisco, Cisco Visual Networking Index: Global Mobile Data Traffic Forecast Update, 2014-2019 White Paper; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition, pp. 580-587; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Proceedings of the Advances in Neural Information Processing Systems 25, pp. 1097-1105. , Curran Associates, Inc; Zhang, J., Marszałek, M., Lazebnik, S., Schmid, C., Local features and kernels for classification of texture and object categories: a comprehensive study (2007) Int. J. Comput. Vis., 73 (2), pp. 213-238; Chapelle, O., Haffner, P., Vapnik, V.N., Support vector machines for histogram-based image classification (1999) IEEE Trans. Neural Netw., 10 (5), pp. 1055-1064; von Luxburg, U., Schölkopf, B., Statistical learning theory: Models, concepts, and results (2011) Inductive Logic, Handbook of the History of Logic, 10, pp. 651-706. , D.M. Gabbay S. Hartmann J. Woods North-Holland; Guillaumin, M., Verbeek, J., Schmid, C., Multimodal semi-supervised learning for image classification (2010) Proceedings of the 2010 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 902-909; Lampert, C., Nickisch, H., Harmeling, S., Learning to detect unseen object classes by between-class attribute transfer (2009) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2009. CVPR 2009, pp. 951-958; Wang, J.G., Cao, Z.D., Yang, B.H., Ma, S.W., Fei, M.R., Wang, H., Yao, Y., Wang, X.F., A mothed of improving identification accuracy via deep learning algorithm under condition of deficient labeled data (2017) Proceedings of the 2017 36th Chinese Control Conference (CCC), pp. 2281-2286; Jun, G., Ghosh, J., Semisupervised learning of hyperspectral data with unknown land-cover classes (2013) IEEE Trans. Geosci. Remote Sens., 51 (1), pp. 273-282; Scheirer, W., Jain, L., Boult, T., Probability models for open set recognition (2014) IEEE Trans. Pattern Anal. Mach. Intell., 36 (11), pp. 2317-2324; Saxena, S., Pandey, S., Khanna, P., A semi-supervised domain adaptation assembling approach for image classification (2017) Pattern Anal. Appl.; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., ImageNet large scale visual recognition challenge (2015) Int. J. Comput. Vis. (IJCV), 115 (3), pp. 211-252; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778; Simonyan, K., Zisserman, A., (2014), Very deep convolutional networks for large-scale image recognition, ArXiv e-prints; Taigman, Y., Yang, M., Ranzato, M., Wolf, L., Deepface: Closing the gap to human-level performance in face verification (2014) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1701-1708; Zhou, S., Chen, Q., Wang, X., Active deep learning method for semi-supervised sentiment classification (2013) Neurocomputing, 120, pp. 536-546; Tuia, D., Volpi, M., Copa, L., Kanevski, M., Munoz-Mari, J., A survey of active learning algorithms for supervised remote sensing image classification (2011) IEEE J. Sel. Top. Signal Process., 5 (3), pp. 606-617; Foody, G.M., Mathur, A., Toward intelligent training of supervised image classifications: directing training data acquisition for SVM classification (2004) Remote Sens. Environ., 93 (1-2), pp. 107-117; Scheirer, W., de Rezende Rocha, A., Sapkota, A., Boult, T., Toward open set recognition (2013) IEEE Trans. Pattern Anal. Mach. Intell., 35 (7), pp. 1757-1772; Riva, M., Ponti, M., de Campos, T., One-class to multi-class model update using the class-incremental optimum-path forest classifier (2016) ECAI, pp. 216-224; Torralba, A., Efros, A., Unbiased look at dataset bias (2011) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2011, pp. 1521-1528; Hand, D.J., Classifier technology and the illusion of progress (2006) Stat. Sci., 21 (1), pp. 1-14; Duin, R., Pekalska, E., Open issues in pattern recognition (2005) Computer Recognition Systems, Advances in Soft Computing, 30, pp. 27-42. , Springer Berlin Heidelberg; Jain, A.K., Data clustering: 50 years beyond k-means (2010) Pattern Recognit. Lett., 31 (8), pp. 651-666; Vapnik, V., (2013) The Nature of Statistical Learning Theory, , Springer Science & Business Media; Lin, Y., Lv, F., Zhu, S., Yang, M., Cour, T., Yu, K., Cao, L., Huang, T., Large-scale image classification: fast feature extraction and SVM training (2011) CVPR 2011, pp. 1689-1696; Erhan, D., Bengio, Y., Courville, A., Manzagol, P.-A., Vincent, P., Bengio, S., Why does unsupervised pre-training help deep learning? (2010) J. Mach. Learn. Res., 11, pp. 625-660; da Silva, N.F.F., Coletta, L.F.S., Hruschka, E.R., Jr., E.R.H., Using unsupervised information to improve semi-supervised tweet sentiment classification (2016) Inf. Sci., 355-356, pp. 348-365; Acharya, A., Hruschka, E.R., Ghosh, J., Acharyya, S., An optimization framework for combining ensembles of classifiers and clusterers with applications to nontransductive semisupervised learning and transfer learning (2014) ACM Trans. Knowl. Discov. Data, 9 (1), pp. 11-1:35; Acharya, A., Hruschka, E.R., Ghosh, J., Acharyya, S., C3E: a framework for combining ensembles of classifiers and clusterers (2011) Multiple Classifier Systems, pp. 269-278. , 6713; Settles, B., Active learning (2012) Synth. Lect. Artif. Intell. Mach. Learn., 6 (1), pp. 1-114; Lampert, C., Nickisch, H., Harmeling, S., Attribute-based classification for zero-shot visual object categorization (2014) IEEE Trans. Pattern Anal. Mach. Intell., 36 (3), pp. 453-465; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324; Schohn, G., Cohn, D., Less is more: active learning with support vector machines (2000) ICML, pp. 839-846. , Citeseer; Zhou, Y., Goldman, S., Democratic co-learning (2004) Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence, 2004. ICTAI 2004, pp. 594-602. , IEEE; Zhang, Q., Sun, S., Multiple-view multiple-learner active learning (2010) Pattern Recognit., 43 (9), pp. 3113-3119; Zhou, J., Sun, S., Gaussian process versus margin sampling active learning (2015) Neurocomputing, 167, pp. 122-131; Huang, S.-J., Jin, R., Zhou, Z.-H., Active learning by querying informative and representative examples (2010) Proceedings of the Advances in neural information processing systems, pp. 892-900; Yang, Y., Ma, Z., Nie, F., Chang, X., Hauptmann, A.G., Multi-class active learning by uncertainty sampling with diversity maximization (2015) Int. J. Comput. Vis., 113 (2), pp. 113-127; Ponti, M., Relevance image sampling from collection using importance selection on randomized optimum-path trees (2017) Proceedings of the 2017 Brazilian Conference on Intelligent Systems (BRACIS), pp. 198-203. , IEEE; Lee, Y.J., Grauman, K., Object-graphs for context-aware visual category discovery (2012) IEEE Trans. Pattern Anal. Mach. Intell., 34 (2), pp. 346-358; Bart, E., Ullman, S., Cross-generalization: learning novel classes from a single example by feature replacement (2005) Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2005. CVPR 2005, 1, pp. 672-679vol. 1; Socher, R., Ganjoo, M., Manning, C.D., Ng, A., Zero-shot learning through cross-modal transfer (2013) Advances in Neural Information Processing Systems 26, pp. 935-943. , C.J.C. Burges L. Bottou M. Welling Z. Ghahramani K.Q. Weinberger Curran Associates, Inc; Rohrbach, M., Stark, M., Schiele, B., Evaluating knowledge transfer and zero-shot learning in a large-scale setting (2011) Proceedings of the 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1641-1648; Markou, M., Singh, S., Novelty detection: a review–part 1: statistical approaches (2003) Signal Process., 83 (12), pp. 2481-2497; Markou, M., Singh, S., Novelty detection: a review–part 2: neural network based approaches (2003) Signal Process., 83 (12), pp. 2499-2521; Masud, M., Chen, Q., Khan, L., Aggarwal, C., Gao, J., Han, J., Srivastava, A., Oza, N., Classification and adaptive novel class detection of feature-evolving data streams (2013) IEEE Trans. Knowl. Data Eng., 25 (7), pp. 1484-1497; Kuncheva, L.I., Classifier ensembles for detecting concept change in streaming data: Overview and perspectives (2008) Proceedings of the 2nd Workshop SUEMA, 2008, pp. 5-10; Luo, C., Wang, J., Feng, G., Xu, S., Wang, S., Do deep convolutional neural networks really need to be deep when applied for remote scene classification? (2017) J. Appl. Remote Sens., 11 (4), p. 042613; Ponti, M.A., Ribeiro, L.S., Nazare, T.S., Bui, T., Collomosse, J., Everything you wanted to know about deep learning for computer vision but were afraid to ask (2017) SIBGRAPI–Conference on Graphics, Patterns and Images Tutorials (SIBGRAPI-T 2017), pp. 17-41; Strehl, A., Ghosh, J., Cluster ensembles - a knowledge reuse framework for combining multiple partitions (2002) J. Mach. Learn. Res., 3, pp. 583-617; Coletta, L.F.S., Hruschka, E.R., Acharya, A., Ghosh, J., A differential evolution algorithm to optimise the combination of classifier and cluster ensembles (2015) Int. J. Bio-Inspired Comput., 7 (2), pp. 111-124; Van der Wel, F.J., Van der Gaag, L.C., Gorte, B.G., Visual exploration of uncertainty in remote-sensing classification (1998) Comput. Geosci., 24 (4), pp. 335-343; Witten, I.H., Frank, E., Data mining: practical machine learning tools and techniques (2005), 2nd; Hsu, C.-W., Chang, C.-C., Lin, C.-J., A practical guide to support vector classification (2003) Taipei, Technical Report, pp. 1-16; Campello, R.J., Hruschka, E.R., Alves, V.S., On the efficiency of evolutionary fuzzy clustering (2009) J. Heuristics, 15, pp. 43-75; Ponti, M., Nazaré, T.S., Thumé, G.S., Image quantization as a dimensionality reduction procedure in color and texture feature extraction (2016) Neurocomputing, 173, pp. 385-396; Nene, S.A., Nayar, S.K., Murase, H., Columbia Object Image Library (COIL-20) (1996) Technical Report; Wang, J., Li, J., Wiederhold, G., Simplicity: semantics-sensitive integrated matching for picture libraries (2001) IEEE Trans. Pattern Anal. Mach. Intell., 23 (9), pp. 947-963; Rocha, A., Hauagge, D.C., Wainer, J., Goldenstein, S., Automatic fruit and vegetable classification from images (2010) Comput. Electron. Agric., 70 (1), pp. 96-104; Penatti, O., Valle, E., Torres, R., Comparative study of global color and texture descriptors for web image retrieval (2012) J. Vis. Commun. Image Represent., 23 (2), pp. 359-380; Ponti, M., Picon, C., Color description of low resolution images using fast bitwise quantization and border-interior classification (2015) Proceedings of the 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), , IEEE Brisbane, Australia; Stehling, R.O., Nascimento, M.A., Falcao, A.X., A compact and efficient image retrieval approach based on border/interior pixel classification (2002) Proceedings of the CIKM’02 - 11th ACM Int. Conf. Information Knowledge Management, pp. 102-109; Haralick, R., Shanmugan, K., Dinstein, I., Textural features for image classification (1973) IEEE Trans. Syst. Man Cybern., SMC-3 (6), pp. 610-621},
correspondence_address1={Coletta, L.F.S.; School of Sciences and Engineering, Brazil; email: luiz.coletta@unesp.br},
publisher={Elsevier B.V.},
issn={09252312},
coden={NRCGE},
language={English},
abbrev_source_title={Neurocomputing},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Wang2019411,
author={Wang, C. and Bian, S. and Tang, L. and Fujita, H. and Lu, Y. and Zhang, D. and Zhang, Z. and Wu, Y.},
title={ProductNet: A collection of high-quality datasets for product representation learning},
journal={The Web Conference 2019 - Companion of the World Wide Web Conference, WWW 2019},
year={2019},
pages={411-414},
doi={10.1145/3308560.3316607},
note={cited By 0; Conference of 2019 World Wide Web Conference, WWW 2019 ; Conference Date: 13 May 2019 Through 17 May 2019;  Conference Code:147967},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066895373&doi=10.1145%2f3308560.3316607&partnerID=40&md5=e7d2bec4696be218a3f3efdb11a127f7},
affiliation={Amazon.com, United States},
abstract={ProductNet is a collection of high-quality product datasets for better product understanding. Motivated by ImageNet, ProductNet aims at supporting product representation learning by curating product datasets of high quality with properly chosen taxonomy. In this paper, the two goals of building high-quality product datasets and learning product representation support each other in an iterative fashion: the product embedding is obtained via a multi-modal deep neural network (master model) designed to leverage product image and catalog information; and in return, the embedding is utilized via active learning (local model) to vastly accelerate the annotation process. For the labeled data, the proposed master model yields high categorization accuracy (94.7% top-1 accuracy for 1240 classes), which can be used as search indices, partition keys, and input features for machine learning models. The product embedding, as well as the fined-tuned master model for a specific business task, can also be used for various transfer learning tasks. � 2019 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY-NC-ND 4.0 License.},
author_keywords={Active Learning;  Dataset Construction;  Deep Learning;  Multi-Modal Learning;  Representation Learning},
keywords={Artificial intelligence;  Deep learning;  Embeddings;  World Wide Web, Active Learning;  High-quality products;  Learning products;  Machine learning models;  Multi-modal learning;  Product representation;  Representation Learning;  Transfer learning, Deep neural networks},
references={Devlin, J., Chang, M.-W., Lee, K., Toutanova, K., (2018) Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding, , 2018; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) IEEE Conference on Computer Vision and Pattern Recognition, pp. 580-587; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; (2015) Google Product Taxonomy, , https://www.google.com/basepages/producttype/taxonomy.en-US.txt; Johnson, R., Zhang, T., Deep pyramid convolutional neural networks for text categorization (2017) Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 1, pp. 562-570; Joulin, A., Grave, E., Bojanowski, P., Mikolov, T., (2016) Bag of Tricks for Efficient Text Classification, , 2016; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Proceedings of Advances in Neural Information Processing Systems, pp. 1097-1105; Le, Q., Mikolov, T., Distributed representations of sentences and documents (2014) International Conference on Machine Learning, pp. 1188-1196; Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollar, P., Lawrence Zitnick, C., Microsoft coco: Common objects in context (2014) European Conference on Computer Vision, pp. 740-755. , Springer; McAuley, J., Leskovec, J., Hidden factors and hidden topics: Understanding rating dimensions with review text (2013) Proceedings of the 7th ACM Conference on Recommender Systems, pp. 165-172; Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S., Dean, J., Distributed representations of words and phrases and their compositionality (2013) Advances in Neural Information Processing Systems, pp. 3111-3119; Sak, H., Senior, A., Beaufays, F., Long short-term memory recurrent neural network architectures for large scale acoustic modeling (2014) Fifteenth Conference of the International Speech Communication Association; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition, , 2014; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) AAAI, 4 (12); Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., Polosukhin, I., (2017) Attention Is All You Need, , 2017},
sponsors={Amazon; Bloomberg; Criteo AI Lab; et al.; Google; Microsoft},
publisher={Association for Computing Machinery, Inc},
isbn={9781450366755},
language={English},
abbrev_source_title={Web Conf. - Companion World Wide Web Conf., WWW},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Zhou2019290,
author={Zhou, Z. and Shin, J. and Feng, R. and Hurst, R.T. and Kendall, C.B. and Liang, J.},
title={Integrating Active Learning and Transfer Learning for Carotid Intima-Media Thickness Video Interpretation},
journal={Journal of Digital Imaging},
year={2019},
volume={32},
number={2},
pages={290-299},
doi={10.1007/s10278-018-0143-2},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056356641&doi=10.1007%2fs10278-018-0143-2&partnerID=40&md5=6d1e5811513170a3d84f712ff213eb22},
affiliation={Arizona State University, 13212 E Shea Blvd, Scottsdale, AZ  85259, United States; Mayo Clinic, 13400 E Shea Blvd, Scottsdale, AZ  85259, United States},
abstract={Cardiovascular disease (CVD) is the number one killer in the USA, yet it is largely preventable (World Health Organization 2011). To prevent CVD, carotid intima-media thickness (CIMT) imaging, a noninvasive ultrasonography method, has proven to be clinically valuable in identifying at-risk persons before adverse events. Researchers are developing systems to automate CIMT video interpretation based on deep learning, but such efforts are impeded by the lack of large annotated CIMT video datasets. CIMT video annotation is not only tedious, laborious, and time consuming, but also demanding of costly, specialty-oriented knowledge and skills, which are not easily accessible. To dramatically reduce the cost of CIMT video annotation, this paper makes three main contributions. Our first contribution is a new concept, called Annotation Unit (AU), which simplifies the entire CIMT video annotation process down to six simple mouse clicks. Our second contribution is a new algorithm, called AFT (active fine-tuning), which naturally integrates active learning and transfer learning (fine-tuning) into a single framework. AFT starts directly with a pre-trained convolutional neural network (CNN), focuses on selecting the most informative and representative AU s from the unannotated pool for annotation, and then fine-tunes the CNN by incorporating newly annotated AU s in each iteration to enhance the CNN’s performance gradually. Our third contribution is a systematic evaluation, which shows that, in comparison with the state-of-the-art method (Tajbakhsh et al., IEEE Trans Med Imaging 35(5):1299–1312, 2016), our method can cut the annotation cost by >81% relative to their training from scratch and >50% relative to their random selection. This performance is attributed to the several advantages derived from the advanced active, continuous learning capability of our AFT method. © 2018, Society for Imaging Informatics in Medicine.},
author_keywords={Active learning;  Cardiovascular disease;  Transfer learning},
keywords={Cardiology;  Diseases;  Iterative methods;  Mammals;  Neural networks, Active Learning;  Cardio-vascular disease;  Carotid intima-media thickness;  Convolutional Neural Networks (CNN);  State-of-the-art methods;  Systematic evaluation;  Transfer learning;  World Health Organization, Deep learning, arterial wall thickness;  carotid artery;  classification;  diagnostic imaging;  echography;  human;  machine learning;  procedures;  videorecording, Carotid Arteries;  Carotid Intima-Media Thickness;  Humans;  Machine Learning;  Ultrasonography;  Video Recording},
funding_details={National Institutes of HealthNational Institutes of Health, NIH},
funding_details={National Heart, Lung, and Blood InstituteNational Heart, Lung, and Blood Institute, NHLBI, R01HL128785},
funding_details={Mayo ClinicMayo Clinic},
funding_details={Adams State UniversityAdams State University, ASU},
funding_text 1={This research has been supported partially by NIH under Award Number R01HL128785 and partially by ASU and Mayo Clinic through the Discovery Translation Program. The content is solely the responsibility of the authors and does not necessarily represent the official views of NIH.},
funding_text 2={Acknowledgements This research has been supported partially by NIH under Award Number R01HL128785 and partially by ASU and Mayo Clinic through the Discovery Translation Program. The content is solely the responsibility of the authors and does not necessarily represent the official views of NIH.},
references={(2011) Global Atlas on Cardiovascular Disease Prevention and Control, , http://www.who.int/cardiovascular_diseases/publications, September 19; Al Rahhal, M., Bazi, Y., AlHichri, H., Alajlan, N., Melgani, F., Yager, R., Deep learning approach for active classification of electrocardiogram signals (2016) Inf Sci, 345, pp. 340-354; Carneiro, G., Nascimento, J., Bradley, A., Unregistered multiview mammogram analysis with pre-trained deep learning models (2015) Medical Image Computing and Computer-Assisted Intervention – MICCAI 2015, Lecture Notes in Computer Science, 9351, pp. 652-660. , https://doi.org/10.1007/978-3-319-24574-4_78, (Navab N, Hornegger J, Wells WM, Frangi AF, Eds.), Springer International Publishing; Chen, H., Ni, D., Qin, J., Li, S., Yang, X., Wang, T., Heng, P.A., Standard plane localization in fetal ultrasound via domain transferred deep neural networks (2015) IEEE J Biomed Health Inform, 19 (5), pp. 1627-1636; Delsanto, S., Molinari, F., Giustetto, P., Liboni, W., Badalamenti, S., Suri, J.S., Characterization of a completely user-independent algorithm for carotid artery segmentation in 2-d ultrasound images (2007) IEEE Trans Instrum Meas, 56 (4), pp. 1265-1274; (2011) Global Atlas on Cardiovascular Disease Prevention and Control, , http://www.who.int/cardiovascular_diseases/publications, September 19; Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L., (2009) Imagenet: A Large-Scale Hierarchical Image Database CVPR09; Gao, M., Bagci, U., Lu, L., Wu, A., Buty, M., Shin, H.C., Roth, H., Summers, R.M., Holistic classification of ct attenuation patterns for interstitial lung diseases via deep convolutional neural networks (2015) The 1St Workshop on Deep Learning in Medical Image Analysis, International Conference on Medical Image Computing and Computer Assisted Intervention, at MICCAI-DLMIA’15; Gepner, A.D., Young, R., Delaney, J.A., Tattersall, M.C., Blaha, M.J., Post, W.S., Gottesman, R.F., Burke, G.L., A comparison of coronary artery calcium presence, carotid plaque presence, and carotid intima-media thickness for cardiovascular disease prediction in the multi-ethnic study of atherosclerosis (mesa) (2015) Circulation Cardiovascular Imaging, 8 (1); Greenspan, H., van Ginneken, B., Summers, R.M., Guest editorial deep learning in medical imaging: Overview and future promise of an exciting new technique (2016) IEEE Trans Med Imaging, 35 (5), pp. 1153-1159; Guyon, I., Cawley, G., Dror, G., Lemaire, V., Statnikov, A., (2011) JMLR Workshop and Conference Proceedings (Volume 16): Active Learning Challenge Microtome Publishing; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) . In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Hoo-Chang, S., Roth, H.R., Gao, M., Lu, L., Xu, Z., Nogues, I., Yao, J., Summers, R.M., Deep convolutional neural networks for computer-aided detection: Cnn architectures, dataset characteristics and transfer learning (2016) IEEE Trans Med Imaging, 35 (5), p. 1285; Hurst, R.T., Burke, R.F., Wissner, E., Roberts, A., Kendall, C.B., Lester, S.J., Somers, V., Khandheria, B., Incidence of subclinical atherosclerosis as a marker of cardiovascular risk in retired professional football players (2010) Am J Cardiol, 105 (8), pp. 1107-1111; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., (2014) Caffe: Convolutional architecture for fast feature embedding, , http://arXiv.org/abs/1408.5093; Kass, M., Witkin, A., Terzopoulos, D., Snakes: Active contour models (1988) Int J Comput Vis, 1 (4), pp. 321-331; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Li, J., Active learning for hyperspectral image classification with a stacked autoencoders based neural network (2016) 2016 IEEE International Conference on Image Processing (ICIP), pp. 1062-1065. , https://doi.org/10.1109/ICIP.2016.7532520; Liang, J., McInerney, T., Terzopoulos, D., United snakes (2006) Med Image Anal, 10 (2), pp. 215-233; Liang, Q., Wendelhag, I., Wikstrand, J., Gustavsson, T., A multiscale dynamic programming procedure for boundary detection in ultrasonic artery images (2000) IEEE Trans Med Imaging, 19 (2), pp. 127-142; Loizou, C.P., Pattichis, C.S., Pantziaris, M., Nicolaides, A., An integrated system for the segmentation of atherosclerotic carotid plaque (2007) IEEE Trans Inf Technol Biomed, 11 (6), pp. 661-667; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431-3440; Lorenz, M.W., Markus, H.S., Bots, M.L., Rosvall, M., Sitzer, M., Prediction of clinical cardiovascular events with carotid intima-media thickness (2007) Circulation, 115 (4), pp. 459-467; Margeta, J., Criminisi, A., Cabrera Lozoya, R., Lee, D.C., Ayache, N., Fine-tuned convolutional neural nets for cardiac mri acquisition plane recognition (2017) Comput Methods Biomech Biomed Eng: Imaging Visual, 5 (5), pp. 339-349; Menchón-Lara, R.M., Bastida-Jumilla, M.C., González-López, A., Sancho-Gómez, J.L., Automatic evaluation of carotid intima-media thickness in ultrasounds using machine learning (2013) Natural and Artificial Computation in Engineering and Medical Applications, pp. 241-249. , Springer; Menchón-Lara, R.M., Sancho-Gómez, J.L., Fully automatic segmentation of ultrasound common carotid artery images based on machine learning (2015) Neurocomputing, 151, pp. 161-167; Schlegl, T., Ofner, J., Langs, G., Unsupervised pre-training across image domains improves lung tissue classification (2014) Medical Computer Vision: Algorithms for Big Data, pp. 82-93. , Springer; Shin, H.C., Lu, L., Kim, L., Seff, A., Yao, J., Summers, R.M., Interleaved text/image deep mining on a very large-scale radiology database (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1090-1099; Shin, J., Tajbakhsh, N., Todd Hurst, R., Kendall, C.B., Liang, J., Automating carotid intima-media thickness video interpretation with convolutional neural networks (2016) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) ICLR; Stark, F., Hazırbas, C., Triebel, R., Cremers, D., Captcha recognition with active deep learning (2015) Workshop New Challenges in Neural Computation 2015, p. 94. , Citeseer; Stein, J.H., Korcarz, C.E., Hurst, R.T., Lonn, E., Kendall, C.B., Mohler, E.R., Najjar, S.S., Post, W.S., Use of carotid ultrasound to identify subclinical vascular disease and evaluate cardiovascular disease risk: a consensus statement from the american society of echocardiography carotid intima-media thickness task force endorsed by the society for vascular medicine (2008) J Am Soc Echocardiogr, 21 (2), pp. 93-111; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) The IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Tajbakhsh, N., Shin, J.Y., Gurudu, S.R., Hurst, R.T., Kendall, C.B., Gotway, M.B., Liang, J., Convolutional neural networks for medical image analysis: Full training or fine tuning? (2016) IEEE Trans Med Imaging, 35 (5), pp. 1299-1312; Tajbakhsh, N., Shin, J.Y., Hurst, R.T., Kendall, C.B., Liang, J., Automatic interpretation of carotid intima–media thickness videos using convolutional neural networks (2017) Deep learning for medical image analysis, pp. 105-131. , In:., Elsevier; Wang, D., Shang, Y., A new active labeling method for deep learning (2014) International Joint Conference on Neural Networks (IJCNN), pp. 112-119. , https://doi.org/10.1109/IJCNN.2014.6889457; Yang, L., Zhang, Y., Chen, J., Zhang, S., Chen, D.Z., Suggestive annotation: A deep active learning framework for biomedical image segmentation (2017) International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 399-407. , Springer; Zhou, Z., Shin, J., Zhang, L., Gurudu, S., Gotway, M., Liang, J., Fine-tuning convolutional neural networks for biomedical image analysis: Actively and incrementally (2017) IEEE Conference on Computer Vision and Pattern Recognition, Hawaii, pp. 7340-7349},
correspondence_address1={Liang, J.; Arizona State University, 13212 E Shea Blvd, United States; email: jianming.liang@asu.edu},
publisher={Springer New York LLC},
issn={08971889},
coden={JDIME},
pubmed_id={30402668},
language={English},
abbrev_source_title={J. Digit. Imaging},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Saboori2019397,
author={Saboori, A. and Ghassemian, H.},
title={Active Learning for Domain Adaptation in Classification of Remote Sensing Data by Minimizing Expected Error with Diversity Maximization},
journal={9th International Symposium on Telecommunication: With Emphasis on Information and Communication Technology, IST 2018},
year={2019},
pages={397-402},
doi={10.1109/ISTEL.2018.8660974},
art_number={8660974},
note={cited By 0; Conference of 9th International Symposium on Telecommunication, IST 2018 ; Conference Date: 17 December 2018 Through 19 December 2018;  Conference Code:145883},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063898415&doi=10.1109%2fISTEL.2018.8660974&partnerID=40&md5=cbe3882c3147b9643bb8bacf5862a72f},
affiliation={Faculty of Electrical and Computer Engineering, Islamic Azad University, Tehran, Iran},
abstract={This paper investigates a method addressing remote sensing image classification based on the domain adaptation (DA) and active learning (AL). The key idea of our method is to retrain the classifier by using the available labeled samples from source domain, and adding minimum number of the most informative samples with active queries in the target domain. The active learning approaches provide pool of candidate samples based on different query functions with the assessment of uncertainty and diversity. The uncertainty criterion evaluates the algorithm' confidence in order to correctly classify the considered samples, while the diversity criterion decreasing the redundancy between the selected samples by choosing a set of unlabeled samples with more diversity. So, based on this model, we exploit both two criteria in order to choose the most informative samples are selected iteratively at the active learning procedure. In this work, we have proposed a novel uncertainty criteria based minimum expected error (MEE), and also use angular based diversity (ABD) as diversity criteria. The experimental outcomes prove the superiority of the proposed approach to counterpart methods. © 2018 IEEE.},
author_keywords={Active Learning;  Classification;  Diversity;  Domain Adaptation;  Remote Sensing;  Uncertainty},
keywords={Artificial intelligence;  Classification (of information);  Iterative methods, Active Learning;  Diversity;  Domain adaptation;  Query functions;  Remote sensing data;  Remote sensing image classification;  Uncertainty;  Unlabeled samples, Remote sensing},
references={Tuia, D., Persello, C., Bruzzone, L., Domain adaptation for the classification of remote sensing data: An Overview of Recent Advances (2016) IEEE Geoscience and Remote Sensing Magazine, 4 (2), pp. 41-57. , June; Patel, V.M., Gopalan, R., Li, R., Chellappa, R., Visual domain adaptation: A survey of recent advances (2015) IEEE Signal Processing Magazine, 32 (3), pp. 53-69. , May; Patra, S., Bhardwaj, K., Bruzzone, L., A spectral-spatial multicriteria active learning technique for hyperspectral image classification (2017) IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 10 (12), pp. 5213-5227. , Dec; Imani, M., Ghassemian, H., Weighted joint collaborative representation based on median-mean line and angular separation (2017) IEEE Transactions on Geoscience and Remote Sensing, 55 (10), pp. 5612-5624. , Oct; Di, W., Crawford, M.M., Active learning via multi-view and local proximity co-regularization for hyperspectral image Classification (2011) IEEE Journal of Selected Topics in Signal Processing, 5 (3), pp. 618-628. , June; Kianisarkaleh, A., Ghassemian, H., Nonparametric feature extraction for classification of hyperspectral images with limited training samples (2016) ISPRS Journal of Photogrammetry and Remote Sensing, 119, pp. 64-78; Demir, B., Persello, C., Bruzzone, L., Batch-mode active-learning methods for the interactive classification of remote sensing images (2011) IEEE Transactions on Geoscience and Remote Sensing, 49 (3), pp. 1014-1031. , March; Crawford, M.M., Tuia, D., Yang, H.L., Active learning: Any value for classification of remotely sensed data? (2013) Proceedings of the IEEE, 101 (3), pp. 593-608. , March; Liu, C., He, L., Li, Z., Li, J., Feature-driven active learning for hyperspectral image classification (2018) IEEE Transactions on Geoscience and Remote Sensing, 56 (1), pp. 341-354; Zehtabian, A., Ghassemian, H., Automatic object-based hyperspectral image classification using complex diffusions and a new Distance Metric (2016) IEEE Transactions on Geoscience and Remote Sensing, 54 (7), pp. 4106-4114. , July; Tuia, D., Ratle, F., Pacifici, F., Kanevski, M.F., Emery, W.J., Active learning methods for remote sensing image classification (2009) IEEE Transactions on Geoscience and Remote Sensing, 47 (7), pp. 2218-2232. , July; Kowkabi, F., Ghassemian, H., Keshavarz, A., Enhancing hyperspectral endmember extraction using clustering and over-segmentation based Preprocessing (2016) IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 9 (6), pp. 2400-2413. , June; Golipour, M., Ghassemian, H., Mirzapour, F., Integrating hierarchical segmentation maps with mrf prior for classification of hyperspectral images in a Bayesian Framework (2016) IEEE Transactions on Geoscience and Remote Sensing, 54 (2), pp. 805-816. , FEBRUARY; Othman, E., Bazi, Y., Alajlan, N., AlHichri, H., Melgani, F., Three-layer convex network for domain adaptation in multitemporal vhr images (2016) IEEE Geoscience and Remote Sensing Letters, 13 (3), pp. 354-358. , March; Tuia, D., Munoz-Mari, J., Gomez-Chova, L., Malo, J., Graph matching for adaptation in remote sensing (2013) IEEE Transactions on Geoscience and Remote Sensing, 51 (1), pp. 329-341. , Jan; Sun, H., Liu, S., Zhou, S., Zou, H., Unsupervised cross-view semantic transfer for remote sensing image classification (2016) IEEE Geoscience and Remote Sensing Letters, 13 (1), pp. 13-17. , Jan; Yang, H.L., Crawford, M.M., Spectral and spatial proximity-based manifold alignment for multitemporal hyperspectral image Classification (2016) IEEE Transactions on Geoscience and Remote Sensing, 54 (1), pp. 51-64. , Jan; Ghahremani, M., Ghassemian, H., A compressed-sensing-based pan sharpening method for spectral distortion reduction IEEE Transactions on Geoscience and Remote Sensing; Tuia, D., Volpi, M., Copa, L., Kanevski, M., Munoz-Mari, J., A survey of active learning algorithms for supervised remote sensing image classification (2011) IEEE Journal of Selected Topics in Signal Processing, 5 (3), pp. 606-617. , June; Amor, I.B.S.B., Chehata, N., Bailly, J., Farah, I.R., Lagacherie, P., Parcel-based active learning for large extent cultivated area mapping (2018) IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 11 (1), pp. 79-88. , Jan},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538682746},
language={English},
abbrev_source_title={Int. Symp. Telecommun.: With Emphas. Inf. Commun. Technol., IST},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Younesian2019234,
author={Younesian, T. and Masoudnia, S. and Hosseini, R. and Araabi, B.N.},
title={Active Transfer Learning for Persian Offline Signature Verification},
journal={4th International Conference on Pattern Recognition and Image Analysis, IPRIA 2019},
year={2019},
pages={234-239},
doi={10.1109/PRIA.2019.8786013},
art_number={8786013},
note={cited By 2; Conference of 4th International Conference on Pattern Recognition and Image Analysis, IPRIA 2019 ; Conference Date: 6 March 2019 Through 7 March 2019;  Conference Code:150581},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066065929&doi=10.1109%2fPRIA.2019.8786013&partnerID=40&md5=440147c2e84c066c68f9798e09f7611f},
affiliation={Department of Electrical and Computer Engineering, University of Tehran, Teharn, Iran},
abstract={Offline Signature Verification (OSV) remains a challenging pattern recognition task, especially in the presence of skilled forgeries that are not available during the training. This challenge is aggravated when there are small labeled training data available but with large intra-personal variations. In this study, we address this issue by employing an active learning approach, which selects the most informative instances to label and therefore reduces the human labeling effort significantly. Our proposed OSV includes three steps: feature learning, active learning, and final verification. We benefit from transfer learning using a pre-trained CNN for feature learning. We also propose SVM-based active learning for each user to separate his genuine signatures from the random forgeries. We finally used the SVMs to verify the authenticity of the questioned signature. We examined our proposed active transfer learning method on UTSig: A Persian offline signature dataset. We achieved near 13% improvement compared to the random selection of instances. Our results also showed 1% improvement over the state-of-the-art method in which a fully supervised setting with five more labeled instances per user was used. © 2019 IEEE.},
author_keywords={Active Learning;  Signature Verification;  SVM;  Transfer Learning;  Uncertainty},
keywords={Image analysis;  Machine learning;  Support vector machines, Active Learning;  Intra-personal variations;  Off-line signature verification;  Signature verification;  State-of-the-art methods;  Transfer learning;  Transfer learning methods;  Uncertainty, Pattern recognition},
references={Hafemann, L.G., Sabourin, R., Oliveira, L.S., Learning features for offline handwritten signature verification using deep convolutional neural networks (2017) Pattern Recognition, 70, pp. 163-176; Masoudnia, S., Mersa, O., Araabi, B.N., Vahabie, A.-H., Sadeghi, M.A., Nili Ahmadabadi, M., Multi-representational learning for offline signature verification using multi-loss snapshot ensemble of CNNs (2019) Expert Systems with Applications; Mersa, O., Etaati, F., Masoudnia, S., Araabi, B.N., Learning representations from Persian handwriting for offline signature verification, a deep transfer learning approach (2019) The 4th International Conference on Pattern Recognition and Image Analysis, , Tehran, Iran; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Hafemann, L.G., Sabourin, R., Oliveira, L.S., Offline handwritten signature verification - Literature review (2017) Image Processing Theory, Tools and Applications (IPTA), 2017 Seventh International Conference on, pp. 1-8; Soleimani, A., Fouladi, K., Araabi, B.N., UTSig: A Persian offline signature dataset (2016) IET Biometrics, 6 (1), pp. 1-8; Sharif, M., Khan, M.A., Faisal, M., Yasmin, M., Fernandes, S.L., A framework for offline signature verification system: Best features selection approach (2018) Pattern Recognition Letters; Bouamra, W., Djeddi, C., Nini, B., Diaz, M., Siddiqi, I., Towards the design of an offline signature verifier based on a small number of genuine samples for training (2018) Expert Systems with Applications, 107, pp. 182-195; Soleimani, A., Araabi, B.N., Fouladi, K., Deep multitask metric learning for offline signature verification (2016) Pattern Recognition Letters, 80, pp. 84-90; Masoudnia, S., Ebrahimpour, R., Mixture of experts: A literature survey (2012) Artificial Intelligence Review, 42 (2), pp. 275-293; Berkay Yilmaz, M., Ozturk, K., Hybrid user-independent and user-dependent offline signature verification with a two-channel CNN (2018) The Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, , presented at; Li, M., Sethi, I.K., Confidence-based active learning (2006) IEEE Transactions on Pattern Analysis and Machine Intelligence, 28 (8), pp. 1251-1261; Schohn, G., Cohn, D., Less is more: Active learning with support vector machines (2000) ICML, pp. 839-846. , Citeseer; Tong, S., Koller, D., Support vector machine active learning with applications to text classification (2001) Journal of Machine Learning Research, 2, pp. 45-66. , no. Nov; Seung, H.S., Opper, M., Sompolinsky, H., Query by committee (1992) Proceedings of the Fifth Annual Workshop on Computational Learning Theory, pp. 287-294; Gavves, E., Mensink, T., Tommasi, T., Snoek, C.G., Tuytelaars, T., Active transfer learning with zero-shot priors: Reusing past datasets for future tasks (2015) Proceedings of the IEEE International Conference on Computer Vision, pp. 2731-2739; Holub, A., Perona, P., Burl, M.C., Entropy-based active learning for object recognition (2008) Computer Vision and Pattern Recognition Workshops, 2008. CVPRW'08. IEEE Computer Society Conference on, pp. 1-8; Leng, Y., Qi, G.H., Xu, X.Y., Wang, X.P., Li, D.W., A new SVM active learning algorithm based on KNN (2014) Advanced Materials Research, 926, pp. 2906-2909. , Trans Tech Publ; Platt, J., Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods (1999) Advances in Large Margin Classifiers, 10 (3), pp. 61-74; Soleimani, A., Fouladi, K., Araabi, B.N., UTSig: A Persian offline signature dataset (2017) IET Biometrics, 6 (1), pp. 1-8},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781728116211},
language={English},
abbrev_source_title={Int. Conf. Pattern Recognit. Image Anal., IPRIA},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Deng20191741,
author={Deng, C. and Xue, Y. and Liu, X. and Li, C. and Tao, D.},
title={Active Transfer Learning Network: A Unified Deep Joint Spectral-Spatial Feature Learning Model for Hyperspectral Image Classification},
journal={IEEE Transactions on Geoscience and Remote Sensing},
year={2019},
volume={57},
number={3},
pages={1741-1754},
doi={10.1109/TGRS.2018.2868851},
art_number={8520902},
note={cited By 50},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056189603&doi=10.1109%2fTGRS.2018.2868851&partnerID=40&md5=6e39f7c1c9e7c164f406d66701b0f742},
affiliation={School of Electronic Engineering, Xidian University, Xi'an, 710071, China; State Key Laboratory of Software Development Environment, Beihang University, Beijing, 100191, China; UBTECH Sydney Artificial Intelligence Centre, University of Sydney, Darlington, NSW  2008, Australia; School of Information Technologies, Faculty of Engineering and Information Technologies, University of Sydney, Darlington, NSW  2008, Australia},
abstract={Deep learning has recently attracted significant attention in the field of hyperspectral images (HSIs) classification. However, the construction of an efficient deep neural network mostly relies on a large number of labeled samples being available. To address this problem, this paper proposes a unified deep network, combined with active transfer learning (TL) that can be well-trained for HSIs classification using only minimally labeled training data. More specifically, deep joint spectral-spatial feature is first extracted through hierarchical stacked sparse autoencoder (SSAE) networks. Active TL is then exploited to transfer the pretrained SSAE network and the limited training samples from the source domain to the target domain, where the SSAE network is subsequently fine-tuned using the limited labeled samples selected from both source and target domains by the corresponding active learning (AL) strategies. The advantages of our proposed method are threefold: 1) the network can be effectively trained using only limited labeled samples with the help of novel AL strategies; 2) the network is flexible and scalable enough to function across various transfer situations, including cross data set and intraimage; and 3) the learned deep joint spectral-spatial feature representation is more generic and robust than many joint spectral-spatial feature representations. Extensive comparative evaluations demonstrate that our proposed method significantly outperforms many state-of-the-art approaches, including both traditional and deep network-based methods, on three popular data sets. © 2019 IEEE.},
author_keywords={Active learning (AL);  deep learning;  hyperspectral image (HSI) classification;  multiple-feature representation;  stacked sparse autoencoder (SSAE);  transfer learning (TL)},
keywords={Artificial intelligence;  Data communication systems;  Deep learning;  Deep neural networks;  Feature extraction;  Hyperspectral imaging;  Image classification;  Independent component analysis;  Personnel training;  Spectroscopy, Active Learning;  Auto encoders;  Loss measurement;  Multiple features;  Training data;  Transfer learning, Classification (of information)},
funding_details={2017ZDCXL-GY-05-04-02},
funding_details={Australian Research CouncilAustralian Research Council, ARC, DP-180103424, FL-170100117, IH180100002},
funding_details={National Natural Science Foundation of ChinaNational Natural Science Foundation of China, NSFC, 61572388, 61872021},
funding_text 1={Manuscript received September 23, 2017; revised January 26, 2018 and May 4, 2018; accepted August 31, 2018. Date of publication November 2, 2018; date of current version February 25, 2019. This work was supported in part by the National Natural Science Foundation of China under Grant 61572388 and Grant 61872021, in part by the Key R&D Program-The Key Industry Innovation Chain of Shaanxi under Grant 2017ZDCXL-GY-05-04-02, and in part by the Australian Research Council under Project FL-170100117, Project DP-180103424, and Project IH180100002.},
references={Lacar, F.M., Lewis, M.M., Grierson, I.T., Use of hyperspectral imagery for mapping grape varieties in the barossa valley, South Australia (2001) Proc. IEEE Int. Geosci. Remote Sens. Symp. (IGARSS), 6, pp. 2875-2877. , Sydney, NSW, Australia, Jul; Van Der-Meer, F., Analysis of spectral absorption features in hyperspectral imagery (2004) Int. J. Appl. Earth Observ. Geoinf., 5 (1), pp. 55-68. , Feb; Malthus, T.J., Mumby, P.J., Remote sensing of the coastal zone: An overview and priorities for future research (2003) Int. J. Remote Sens., 24, pp. 2805-2815. , Nov; Bioucas-Dias, J.M., Plaza, A., Camps-Valls, G., Scheunders, P., Nasrabadi, N.M., Chanussot, J., Hyperspectral remote sensing data analysis and future challenges (2013) IEEE Geosci. Remote Sens. Mag., 1 (2), pp. 6-36. , Jun; Camps-Valls, G., Bruzzone, L., Kernel-based methods for hyperspectral image classification (2005) IEEE Trans. Geosci. Remote Sens., 43 (6), pp. 1351-1362. , Jun; Foody, G.M., Mathur, A., A relative evaluation of multiclass image classification by support vector machines (2004) IEEE Trans. Geosci. Remote Sens., 42 (6), pp. 1335-1343. , Jun; Li, J., Bioucas-Dias, J.M., Plaza, A., Semisupervised hyperspectral image classification using soft sparse multinomial logistic regression (2012) IEEE Geosci. Remote Sens. Lett., 10 (2), pp. 318-322. , Mar; Bruce, L.M., Koger, C.H., Li, J., Dimensionality reduction of hyperspectral data using discrete wavelet transform feature extraction (2002) IEEE Trans. Geosci. Remote Sens., 40 (10), pp. 2331-2338. , Oct; Bilgin, G., Erturk, S., Yildirim, T., Unsupervised classification of hyperspectral-image data using fuzzy approaches that spatially exploit membership relations (2008) IEEE Geosci. Remote Sens. Lett., 5 (4), pp. 673-677. , Oct; Prasad, S., Bruce, L.M., Limitations of principal components analysis for hyperspectral target recognition (2008) IEEE Geosci. Remote Sens. Lett., 5 (4), pp. 625-629. , Oct; Wang, R., Nie, F., Yang, X., Gao, F., Yao, M., Robust 2DPCA with non-greedy ℓ1-norm maximization for image analysis (2015) IEEE Trans. Cybern., 45 (5), pp. 1108-1112. , May; Yu, Q., Wang, R., Yang, X., Li, B.N., Yao, M., Diagonal principal component analysis with non-greedy ℓ1-norm maximization for face recognition (2016) Neurocomputing, 171, pp. 57-62. , Jan; Bruzzone, L., Chi, M., Marconcini, M., A novel transductive SVM for semisupervised classification of remote-sensing images (2006) IEEE Trans. Geosci. Remote Sens., 44 (11), pp. 3363-3373. , Nov; Li, J., Bioucas-Dias, J.M., Plaza, A., Semi-supervised hyperspectral image classification using a new (soft) sparse multinomial logistic regression model (2011) Proc. 3rd Workshop Hyperspectral Image Signal Process. Evol. Remote Sens. (WHISPERS), pp. 1-4. , Jun; Fauvel, M., Benediktsson, J.A., Chanussot, J., Sveinsson, J.R., Spectral and spatial classification of hyperspectral data using SVMs and morphological profiles (2008) IEEE Trans. Geosci. Remote Sens., 46 (11), pp. 3804-3814. , Nov; Li, J., Bioucas-Dias, J.M., Plaza, A., Spectral-spatial classification of hyperspectral data using loopy belief propagation and active learning (2013) IEEE Trans. Geosci. Remote Sens., 51 (2), pp. 844-856. , Feb; Zhong, Y., Wang, X., Zhao, L., Feng, R., Zhang, L., Xu, Y., Blind spectral unmixing based on sparse component analysis for hyperspectral remote sensing imagery (2016) ISPRS J. Photogram. Remote Sens., 119 (3), pp. 49-63. , Sep; Ghamisi, P., Mura, M.D., Benediktsson, J.A., A survey on spectral-spatial classification techniques based on attribute profiles (2015) IEEE Trans. Geosci. Remote Sens., 53 (5), pp. 2335-2353. , May; Wang, X., Zhong, Y., Zhang, L., Xu, Y., Spatial group sparsity regularized nonnegative matrix factorization for hyperspectral unmixing (2017) IEEE Trans. Geosci. Remote Sens., 55 (11), pp. 6287-6304. , Nov; Tao, D., Tao, D., Li, X., Gao, X., Large sparse cone non-negative matrix factorization for image annotation (2017) ACM Trans. Intell. Syst. Technol., 8 (3), pp. 1-21. , Apr; Zhao, J., Spectral-spatial classification of hyperspectral imagery with cooperative game (2018) ISPRS J. Photogram. Remote Sens., 135, pp. 31-42. , Jan; Ratle, F., Camps-Valls, G., Weston, J., Semisupervised neural networks for efficient hyperspectral image classification (2010) IEEE Trans. Geosci. Remote Sens., 48 (5), pp. 2271-2282. , May; Li, T., Zhang, J., Zhang, Y., Classification of hyperspectral image based on deep belief networks (2014) Proc. IEEE Int. Conf. Image Process. (ICIP), pp. 5132-5136. , Paris, France, Oct; Zhong, Y., Ma, A., Ong, Y.S., Zhu, Z., Zhang, L., Computational intelligence in optical remote sensing image processing (2018) Appl. Soft Comput., 64, pp. 75-93. , Mar; Hinton, G.E., Salakhutdinov, R.R., Reducing the dimensionality of data with neural networks (2006) Science, 313 (5786), pp. 504-507; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Proc. Adv. Neural Inf. Process. Syst., pp. 1097-1105; Dizaji, K.G., Herandi, A., Huang, H., Deep clustering via joint convolutional autoencoder embedding and relative entropy minimization (2017) Proc. IEEE Int. Conf. Comput. Vis., pp. 5747-5756. , Oct; Cheng, G., Yang, C., Yao, X., Guo, L., Han, J., When deep learning meets metric learning: Remote sensing image scene classification via learning discriminative CNNs (2018) IEEE Trans. Geosci. Remote Sens., 56 (5), pp. 2811-2821. , May; Chen, Y., Lin, Z., Zhao, X., Wang, G., Gu, Y., Deep learning-based classification of hyperspectral data (2014) IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., 7 (6), pp. 2094-2107. , Jun; Shin, H.-C., Orton, M.R., Collins, D.J., Doran, S.J., Leach, M.O., Stacked autoencoders for unsupervised feature learning and multiple organ detection in a pilot study using 4D patient data (2013) IEEE Trans. Pattern Anal. Mach. Intell., 35 (8), pp. 1930-1943. , Aug; Tao, C., Pan, H., Li, Y., Zou, Z., Unsupervised spectral-spatial feature learning with stacked sparse autoencoder for hyperspectral imagery classification (2015) IEEE Geosci. Remote Sens. Lett., 12 (12), pp. 2438-2442. , Dec; Chen, Y., Zhao, X., Jia, X., Spectral-spatial classification of hyperspectral data based on deep belief network (2015) IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., 8 (6), pp. 2381-2392. , Jun; Zhong, P., Gong, Z., Li, S., Schnlieb, C.B., Learning to diversify deep belief networks for hyperspectral image classification (2017) IEEE Trans. Geosci. Remote Sens., 55 (6), pp. 3516-3530. , Jun; Zhao, W., Du, S., Spectral-spatial feature extraction for hyperspectral image classification: A dimension reduction and deep learning approach (2016) IEEE Trans. Geosci. Remote Sens., 54 (8), pp. 4544-4554. , Aug; Demir, B., Persello, C., Bruzzone, L., Batch-mode active-learning methods for the interactive classification of remote sensing images (2011) IEEE Trans. Geosci. Remote Sens., 49 (3), pp. 1014-1031. , Mar; Persello, C., Bruzzone, L., Active learning for domain adaptation in the supervised classification of remote sensing images (2012) IEEE Trans. Geosci. Remote Sens., 50 (11), pp. 4468-4483. , Nov; Persello, C., Interactive domain adaptation for the classification of remote sensing images using active learning (2013) IEEE Geosci. Remote Sens. Lett., 10 (4), pp. 736-740. , Jul; Li, J., Active learning for hyperspectral image classification with a stacked autoencoders based neural network (2016) Proc. IEEE Int. Conf. Image Process. (ICIP), pp. 1062-1065. , Phoenix, AZ, USA, Sep; Schein, A.I., Ungar, L.H., Active learning for logistic regression: An evaluation (2007) Mach. Learn., 68 (3), pp. 235-265; Deng, C., Liu, X., Li, C., Tao, D., Active multi-kernel domain adaptation for hyperspectral image classification (2018) Pattern Recognit., 77, pp. 306-315. , May; Liu, P., Zhang, H., Eom, K.B., Active deep learning for classification of hyperspectral images (2017) IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., 10 (2), pp. 712-724. , Feb; Marmanis, D., Datcu, M., Esch, T., Stilla, U., Deep learning earth observation classification using imagenet pretrained networks (2016) IEEE Geosci. Remote Sens. Lett., 13 (1), pp. 105-109. , Jan; Hu, F., Xia, G.S., Hu, J., Zhang, L., Transferring deep convolutional neural networks for the scene classification of high-resolution remote sensing imagery (2015) Remote Sens., 7 (11), pp. 14680-14707; Yang, J., Zhao, Y.Q., Chan, J.C.W., Learning and transferring deep joint spectral-spatial features for hyperspectral classification (2017) IEEE Trans. Geosci. Remote Sens., 55 (8), pp. 4729-4742. , Aug; Zhou, W., Shao, Z., Cheng, Q., Deep feature representations for high-resolution remote sensing scene classification (2016) Proc. 4th Int. Workshop Earth Observ. Remote Sens. Appl. (EORSA), pp. 338-342. , Guangzhou, China, Jul; Cao, L.-L., Huang, W.-B., Sun, F.-C., Building feature space of extreme learning machine with sparse denoising stacked-autoencoder (2015) Neurocomputing, 174, pp. 60-71. , Jan; Han, X., Zhong, Y., Zhang, L., Spatial-spectral unsupervised convolutional sparse auto-encoder classifier for hyperspectral imagery (2017) Photogramm. Eng. Remote Sens., 83 (3), pp. 195-206; Chen, Y., Jiang, H., Li, C., Jia, X., Ghamisi, P., Deep feature extraction and classification of hyperspectral images based on convolutional neural networks (2016) IEEE Trans. Geosci. Remote Sens., 54 (10), pp. 6232-6251. , Oct; Ghamisi, P., Benediktsson, J.A., Cavallaro, G., Plaza, A., Automatic framework for spectral-spatial classification based on supervised feature extraction and morphological attribute profiles (2014) IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., 7 (6), pp. 2147-2160. , Jun; Xu, J., Liu, X., Huo, Z., Deng, C., Nie, F., Huang, H., Multi-class support vector machine via maximizing multi-class margins (2017) Proc. 26th Int. Joint Conf. Artif. Intell., pp. 3154-3160; Thompson, W.D., Walter, S.D., Areappraisal of the kappa coefficient (1988) J. Clin. Epidemiol., 41 (10), pp. 949-958. , Oct; Bottu, L., Stochastic gradient descent tricks (2012) Neural Networks: Tricks of the Trade, pp. 421-436. , Berlin, Germany: Springer; Melgani, F., Bruzzone, L., Classification of hyperspectral remote sensing images with support vector machines (2004) IEEE Trans. Geosci. Remote Sens., 42 (8), pp. 1778-1790. , Aug; Chang, C.-C., Lin, C.-J., LIBSVM: A library for support vector machines (2011) ACM Trans. Intell. Syst. Technol., 2 (3), pp. 1-27},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={01962892},
coden={IGRSD},
language={English},
abbrev_source_title={IEEE Trans Geosci Remote Sens},
document_type={Article},
source={Scopus},
}

@ARTICLE{Singla2019,
author={Singla, N. and Dubey, K. and Srivastava, V.},
title={Automated assessment of breast cancer margin in optical coherence tomography images via pretrained convolutional neural network},
journal={Journal of Biophotonics},
year={2019},
volume={12},
number={3},
doi={10.1002/jbio.201800255},
art_number={e201800255},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056434733&doi=10.1002%2fjbio.201800255&partnerID=40&md5=8948c226f6bddf2c6497fef1457d2dba},
affiliation={Department of Electrical and Instrumentation Engineering, Thapar Institute of Engineering and Technology, Patiala, Punjab, India; Department of Electrical and Computer Engineering, University of California Los Angeles, Los Angeles, CA, United States},
abstract={The benchmark method for the evaluation of breast cancers involves microscopic testing of a hematoxylin and eosin (H&E)-stained tissue biopsy. Resurgery is required in 20% to 30% of cases because of incomplete excision of malignant tissues. Therefore, a more accurate method is required to detect the cancer margin to avoid the risk of recurrence. In the recent years, convolutional neural networks (CNNs) has achieved excellent performance in the field of medical images diagnosis. It automatically extracts the features from the images and classifies them. In the proposed study, we apply a pretrained Inception-v3 CNN with reverse active learning for the classification of healthy and malignancy breast tissue using optical coherence tomography (OCT) images. This proposed method attained the sensitivity, specificity and accuracy is 90.2%, 91.7% and 90%, respectively, with testing datasets collected from 48 patients (22 normal fibro-adipose tissue and 26 Invasive ductal carcinomas cancerous tissues). The trained network utilizes for the breast cancer margin assessment to predict the tumor with negative margins. Additionally, the network output is correlated with the corresponding histology image. Our results lay the foundation for the future that the proposed method can be used to perform automatic intraoperative identification of breast cancer margins in real-time and to guide core needle biopsies. © 2018 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim},
author_keywords={breast cancer tissue;  deep convolutional neural network;  optical coherence tomography;  transfer learning},
keywords={Biopsy;  Convolution;  Deep neural networks;  Diseases;  Histology;  Neural networks;  Optical tomography;  Tissue;  Tissue engineering, Automated assessment;  Breast Cancer;  Cancerous tissues;  Convolutional neural network;  Core-needle biopsies;  Deep convolutional neural networks;  Malignant tissues;  Transfer learning, Medical imaging, adult;  aged;  automation;  breast tumor;  case control study;  diagnostic imaging;  female;  human;  image processing;  intraoperative period;  middle aged;  optical coherence tomography;  pathology;  procedures, Adult;  Aged;  Automation;  Breast Neoplasms;  Case-Control Studies;  Female;  Humans;  Image Processing, Computer-Assisted;  Intraoperative Period;  Middle Aged;  Neural Networks, Computer;  Tomography, Optical Coherence},
funding_details={Indo-US Science and Technology ForumIndo-US Science and Technology Forum, IUSSTF},
funding_details={Science and Engineering Research BoardScience and Engineering Research Board, SERB},
funding_details={Department of Science and Technology, Government of KeralaDepartment of Science and Technology, Government of Kerala, EMR/2016/000677},
funding_text 1={information Department of Science and Technology, Grant/Award Number: EMR/2016/000677The authors are thankful to Department of Science and Technology for providing funding in the project no. EMR/2016/000677. The corresponding author is also thankful to IUSSTF and SERB for their fellowship.},
funding_text 2={The authors are thankful to Department of Science and Technology for providing funding in the project no. EMR/2016/000677. The corresponding author is also thankful to IUSSTF and SERB for their fellowship.},
references={Torre, L., Rebecca Siegel, A.J., (2012) Global Cancer Facts & Figures, p. 1. , 3rd, ed.,, American Cancer Society, Atlanta, Georgia, p; (2018), http://www.who.int/en/, Accessed date 22 March 2018; Samala, R.K., Chan, H.-P., Hadjiiski, L., Helvie, M.A., Wei, J., Cha, K., (2016) Med. Phys., 43 (12), p. 6654; Buist, D.S.M., Porter, P.L., Lehman, C., Taplin, S.H., White, E., (2004) J. Natl. Cancer Inst., 96 (19), p. 1432; Taneja, P., Maglic, D., Kai, F., Zhu, S., Kendig, R.D., Fry, E.A., Inoue, K., (2010) Clin. Med. Insights Oncol., 4, p. 15; Vakoc, B.J., Fukumura, D., Jain, R.K., Bouma, B.E., (2012) Nat. Rev. Cancer, 12 (5), p. 363; He, L., Long, L.R., Antani, S., Thoma, G.R., (2012) Comput. Methods Prog. Biomed., 107 (3), p. 538; Gurcan, M.N., Member, S., Boucheron, L.E., Can, A., (2009) IEEE Rev. Biomed. Eng., 2, p. 147; Nahid, A.A., Kong, Y., (2018) Information, 9 (19), p. 1; Araujo, T., Aresta, G., Castro, E., Rouco, J., Aguiar, P., Eloy, C., Polonia, A., Campilho, A., (2017) PLoS One, 12 (6); Savastru, D., Chang, E.W., Miclos, S., Pitman, M.B., Patel, A., Iftimia, N., (2014) J. Biomed. Opt., 19 (5), p. 56001; Kowal, M., Filipczuk, P., Obuchowicz, A., Korbicz, J., Monczak, R., (2013) Comput. Biol. Med., 43 (10), p. 1563; Singla, N., Srivastava, V., Mehta, D.S., (2018) Laser Phys. Lett., 15. , 025601; Dubey, K., Srivastava, V., Dalal, K., (2018) Comput. Med. Imaging Graph., 64, p. 22; Galloway, D.A., Laimins, L.A., Division, B., Hutchinson, F., (2017) Lasers Surg. Med., 49 (3), p. 258; Wan, S., Lee, H.C., Huang, X., Xu, T., Xu, T., Zeng, X., Zhang, Z., Zhou, C., (2017) Med. Image Anal., 38, p. 104; Zhou, C., Cohen, D.W., Wang, Y., Lee, H.-C., Mondelblatt, A.E., Tsai, T.-H., Aguirre, A.D., Connolly, J.L., (2010) Cancer Res., 70 (24). , canres-2968; Sullivan, A.C., Hunt, J.P., Oldenburg, A.L., (2011) J. Biomed. Opt., 16 (6), p. 66010; Boppart, S.A., Luo, W., Marks, D.L., Singletary, K.W., (2004) Breast Cancer Res. Treat., 84 (2), p. 85; Ambekar, R., Lau, T.-Y., Walsh, M., Bhargava, R., Toussaint, K.C.J., (2012) Biomed. Opt. Express, 3 (9), p. 2021; Abdel-ilah, L., Šahinbegovi, H., Using machine learning tool in classification of breast cancer (2017) CMBEBIH, p. 3. , Springer, Singapore, p; Majeed, H., Nguyen, T.H., Kandel, M.E., Kajdacsy-Balla, A., Popescu, G., (2018) Sci. Rep., 8 (1), p. 1; Cvetković, J., (2017) Cancer Investig., 35 (8), p. 569; Chen, C.L., Mahjoubfar, A., Tai, L.-C., Blaby, I.K., Huang, A., Niazi, K.R., Jalali, B., (2016) Sci. Rep., 6 (1), p. 21471; Li, H., Mendel, K.R., Lee, J.H., Lan, L., Giger, M.L., (2018) Deep learning in breast cancer risk assessment: evaluation of fine-tuned convolutional neural networks on a clinical dataset of FFDMs, , Proc. SPIE, San Francisco, 10575, Medical Imaging 2018 Computer-Aided Diagnosis; Golatkar, A., Anand, D., Sethi, A., Classification of Breast Cancer Histology using Deep Learning (2018) International Conference Image Analysis and Recognition, p. 837. , Springer, Cham, p; Salehi, H.S., Karimian, N., Mahdian, M., Alnajjar, H., Tadinada, A., (2018) Lasers Dent. XXIV, 10473, p. 3; Albarqouni, S., Baur, C., Achilles, F., Belagiannis, V., Demirci, S., Navab, N., (2016) IEEE Trans. Med. Imaging, 35 (5), p. 1313; Abdolmanafi, F.C.A., Duong, L., Dahdah, N., (2017) Biomed. Opt. Express, 8 (2), p. 481; Yap, M.H., Pons, G., Marti, J., Ganau, S., Sentis, M., Zwiggelaar, R., Davison, A.K., Marti, R., (2017) IEEE J. Biomed. Heal. Informatics, 22 (4), p. 1218; Triki, A.R., Blaschko, M.B., Jung, Y.M., Song, S., Han, H.J., Kim, S.I., Joo, C., (2018) Comput. Med. Imaging Graph., 69, p. 21. , https://doi.org/10.1016/j.compmedimag.2018.06.002; Tran, P.V., (2016) A Fully Convolutional Neural Network for Cardiac Segmentation in Short-Axis MRI, p. 1. , arXiv preprint p; Ben-Cohen, A., Mark, D., Kovler, I., Zur, D., Barak, A., Iglicki, M., Soferman, R., Retinal Layers Segmentation Using Fully Convolutional Network in OCT Images, (2017), p. 1. , RSIP Visionp; Xu, M., Papageorgiou, D.P., Abidi, S.Z., Dao, M., Zhao, H., Karniadakis, G.E., (2017) PLoS Comput. Biol., 13 (10), p. 1; Zheng, Y., Yang, C., Merkulov, A., (2018) Breast cancer screening using convolutional neural network and follow-up digital mammography, , Proc. SPIE, San Francisco, 10669, Computational Imaging III, 1066905; Karri, S.P.K., Chakraborty, D., Chatterjee, J., (2017) Biomed. Opt. Express, 8 (2), p. 579; Li, H., Giger, M.L., Huynh, B.Q., Antropova, N.O., (2017) J. Med. Imaging, 4 (4), p. 1; Taghavikhalilbad, A., Adabi, S., Clayton, A., Soltanizadeh, H., Mehregan, D., Avanaki, M.R.N., (2017) Appl. Opt., 56, p. 3116; Duchi, J., Hazan, E., Singer, Y., (2011) J. Mach. Learn. Res., 12, p. 2121; Xie, X., Li, Y., Shen, L., (2018) arXiv, 1804, p. 06670; Wang, G., Li, W., Zuluaga, M.A., Pratt, R., Patel, P.A., Aertsen, M., Doel, T., Vercauteren, T., (2018) IEEE Trans. Med. Imaging, 37 (7), p. 1562},
correspondence_address1={Srivastava, V.; Department of Electrical and Instrumentation Engineering, India; email: vishalsrivastava17@gmail.com},
publisher={Wiley-VCH Verlag},
issn={1864063X},
pubmed_id={30318761},
language={English},
abbrev_source_title={J. Biophotonics},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Requeima2019,
author={Requeima, J. and Gordon, J. and Bronskill, J. and Nowozin, S. and Turner, R.E.},
title={Fast and flexible multi-task classification using conditional neural adaptive processes},
journal={Advances in Neural Information Processing Systems},
year={2019},
volume={32},
note={cited By 4; Conference of 33rd Annual Conference on Neural Information Processing Systems, NeurIPS 2019 ; Conference Date: 8 December 2019 Through 14 December 2019;  Conference Code:161263},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090173962&partnerID=40&md5=c283c874ae351013f5ea495ac54b29b6},
affiliation={University of Cambridge, United Kingdom; Invenia Labs; Google Research Berlin; Microsoft Research},
abstract={The goal of this paper is to design image classification systems that, after an initial multi-task training phase, can automatically adapt to new tasks encountered at test time. We introduce a conditional neural process based approach to the multi-task classification setting for this purpose, and establish connections to the meta-learning and few-shot learning literature. The resulting approach, called CNAPS, comprises a classifier whose parameters are modulated by an adaptation network that takes the current task's dataset as input. We demonstrate that CNAPS achieves state-of-the-art results on the challenging META-DATASET benchmark indicating high-quality transfer-learning. We show that the approach is robust, avoiding both over-fitting in low-shot regimes and under-fitting in high-shot regimes. Timing experiments reveal that CNAPS is computationally efficient at test-time as it does not involve gradient based adaptation. Finally, we show that trained models are immediately deployable to continual learning and active learning where they can outperform existing approaches that do not leverage transfer learning. © 2019 Neural information processing systems foundation. All rights reserved.},
keywords={Benchmarking;  Classification (of information), Active Learning;  Adaptive process;  Computationally efficient;  Continual learning;  Gradient-based adaptation;  Image classification systems;  Neural process;  State of the art, Transfer learning},
funding_details={GoogleGoogle},
funding_details={Engineering and Physical Sciences Research CouncilEngineering and Physical Sciences Research Council, EPSRC, EP/L000776/1, EP/M0269571},
funding_text 1={The authors would like to thank Ambrish Rawat for helpful discussions and David Duvenaud, Wessel Bruinsma, Will Tebbutt Adrià Garriga Alonso, Eric Nalisnick, and Lyndon White for the insightful comments and feedback. Richard E. Turner is supported by Google, Amazon, Improbable and EPSRC grants EP/M0269571 and EP/L000776/1.},
references={Schmidhuber, Jürgen, (1987) Evolutionary principles in self-referential learning, , PhD thesis, Technische Universität München; Thrun, Sebastian, Pratt, Lorien, (2012) Learning to learn, , Springer Science & Business Media; Lake, Brenden M, Salakhutdinov, Ruslan, Tenenbaum, Joshua B, Human-level concept learning through probabilistic program induction (2015) Science, 350 (6266), pp. 1332-1338; Snell, Jake, Swersky, Kevin, Zemel, Richard, Prototypical networks for few-shot learning (2017) Advances in Neural Information Processing Systems, pp. 4080-4090; Gordon, Jonathan, Bronskill, John, Bauer, Matthias, Nowozin, Sebastian, Turner, Richard, Meta-learning probabilistic inference for prediction (2019) International Conference on Learning Representations, , https://openreview.net/forum?id=HkxStoC5F7; Triantafillou, Eleni, Zhu, Tyler, Dumoulin, Vincent, Lamblin, Pascal, Xu, Kelvin, Goroshin, Ross, Gelada, Carles, Larochelle, Hugo, (2019) Meta-dataset: A dataset of datasets for learning to learn from few examples, , arXiv preprint arXiv:1903.03096; Finn, Chelsea, Abbeel, Pieter, Levine, Sergey, Model-agnostic meta-learning for fast adaptation of deep networks (2017) International Conference on Machine Learning, pp. 1126-1135; Nichol, Alex, Schulman, John, (2018) Reptile: a scalable metalearning algorithm, , arXiv preprint arXiv:1803.02999; Yosinski, Jason, Clune, Jeff, Bengio, Yoshua, Lipson, Hod, How transferable are features in deep neural networks? (2014) Advances in neural information processing systems, pp. 3320-3328; Qiao, Siyuan, Liu, Chenxi, Shen, Wei, Yuille, Alan, (2017) Few-shot image recognition by predicting parameters from activations, , arXiv preprint arXiv:1706.03466; Geisser, Seymour, (1983) On the prediction of observables: a selective update, , Technical report, University of Minnesota; Geisser, Seymour, (2017) Predictive inference, , Routledge; Garnelo, Marta, Rosenbaum, Dan, Maddison, Chris J, Ramalho, Tiago, Saxton, David, Shanahan, Murray, Teh, Yee Whye, Eslami, SM, (2018) Conditional neural processes, , arXiv preprint arXiv:1807.01613; He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, Sun, Jian, Deep residual learning for image recognition (2016) Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778; Perez, Ethan, Strub, Florian, De Vries, Harm, Dumoulin, Vincent, Courville, Aaron, FiLM: Visual reasoning with a general conditioning layer (2018) Thirty-Second AAAI Conference on Artificial Intelligence; Rebuffi, Sylvestre-Alvise, Bilen, Hakan, Vedaldi, Andrea, Learning multiple visual domains with residual adapters (2017) Advances in Neural Information Processing Systems, pp. 506-516; Rebuffi, Sylvestre-Alvise, Bilen, Hakan, Vedaldi, Andrea, Efficient parametrization of multi-domain deep neural networks (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 8119-8127; Zaheer, Manzil, Kottur, Satwik, Ravanbakhsh, Siamak, Poczos, Barnabas, Salakhutdinov, Ruslan R, Smola, Alexander J, Deep sets (2017) Advances in Neural Information Processing Systems, pp. 3394-3404; Qi, Charles R, Su, Hao, Mo, Kaichun, Guibas, Leonidas J, Pointnet: Deep learning on point sets for 3d classification and segmentation (2017) Proc. Computer Vision and Pattern Recognition (CVPR), IEEE, 1 (2), p. 4; Vartak, Manasi, Thiagarajan, Arvind, Miranda, Conrado, Bratman, Jeshua, Larochelle, Hugo, A meta-learning perspective on cold-start recommendations for items (2017) Advances in Neural Information Processing Systems, 30, pp. 6904-6914. , http://papers.nips.cc/paper/7266-a-meta-learning-perspective-on-cold-start-recommendations-for-items.pdf, I. Guyon, U. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, pages Curran Associates, Inc; Russakovsky, Olga, Deng, Jia, Su, Hao, Krause, Jonathan, Satheesh, Sanjeev, Ma, Sean, Huang, Zhiheng, Bernstein, Michael, Imagenet large scale visual recognition challenge (2015) International journal of computer vision, 115 (3), pp. 211-252; Ravi, Sachin, Larochelle, Hugo, Optimization as a model for few-shot learning (2017) Proceedings of the International Conference on Learning Representations (ICLR); Rusu, Andrei A, Rao, Dushyant, Sygnowski, Jakub, Vinyals, Oriol, Pascanu, Razvan, Osindero, Simon, Hadsell, Raia, (2018) Meta-learning with latent embedding optimization, , arXiv preprint arXiv:1807.05960; Vinyals, Oriol, Blundell, Charles, Lillicrap, Tim, Wierstra, Daan, Matching networks for one shot learning (2016) Advances in Neural Information Processing Systems, pp. 3630-3638; Zintgraf, Luisa M, Shiarlis, Kyriacos, Kurin, Vitaly, Hofmann, Katja, Whiteson, Shimon, (2018) CAML: Fast context adaptation via meta-learning, , arXiv preprint arXiv:1810.03642; Bauer, Matthias, Rojas-Carulla, Mateo, Swiatkowski, Jakub Bartlomiej, Schölkopf, Bernhard, Turner, Richard E, (2017) Discriminative k-shot learning using probabilistic models, , arXiv preprint arXiv:1706.00326; Oreshkin, Boris N, Lacoste, Alexandre, Rodriguez, Pau, (2018) TADAM: Task dependent adaptive metric for improved few-shot learning, , arXiv preprint arXiv:1805.10123; Ioffe, Sergey, Szegedy, Christian, Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) International Conference on Machine Learning, pp. 448-456; LeCun, Yann, Cortes, Corinna, Burges, CJ, (2010) MNIST handwritten digit database. AT&T Labs, 2. , http://yann.lecun.com/exdb/mnist, [Online]. Available: 18; Krizhevsky, Alex, Hinton, Geoffrey, (2009) Learning multiple layers of features from tiny images, , Technical report, Citeseer; Lake, Brenden, Salakhutdinov, Ruslan, Gross, Jason, Tenenbaum, Joshua, One shot learning of simple visual concepts (2011) Proceedings of the Annual Meeting of the Cognitive Science Society, 33; Maji, Subhransu, Rahtu, Esa, Kannala, Juho, Blaschko, Matthew, Vedaldi, Andrea, (2013) Fine-grained visual classification of aircraft, , arXiv preprint arXiv:1306.5151; Wah, Catherine, Branson, Steve, Welinder, Peter, Perona, Pietro, Belongie, Serge, (2011) The caltech-ucsd birds-200-2011 dataset; Cimpoi, Mircea, Maji, Subhransu, Kokkinos, Iasonas, Mohamed, Sammy, Vedaldi, Andrea, Describing textures in the wild (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3606-3613; Ha, David, Eck, Douglas, (2017) A neural representation of sketch drawings, , arXiv preprint arXiv:1704.03477; Schroeder, Brigit, Cui, Yin, (2018) Fgvcx fungi classification challenge at fgvc5, , https://www.kaggle.com/c/fungi-challenge-fgvc-2018; Nilsback, Maria-Elena, Zisserman, Andrew, Automated flower classification over a large number of classes (2008) 2008 Sixth Indian Conference on Computer Vision, Graphics & Image Processing, pp. 722-729. , IEEE; Houben, Sebastian, Stallkamp, Johannes, Salmen, Jan, Schlipsing, Marc, Igel, Christian, Detection of traffic signs in real-world images: The german traffic sign detection benchmark (2013) The 2013 international joint conference on neural networks (IJCNN), pp. 1-8. , IEEE; Lin, Tsung-Yi, Maire, Michael, Belongie, Serge, Hays, James, Perona, Pietro, Ramanan, Deva, Dollár, Piotr, Zitnick, C Lawrence, Microsoft coco: Common objects in context (2014) European conference on computer vision, pp. 740-755. , Springer; Ring, Mark B, Child: A first step towards continual learning (1997) Machine Learning, 28 (1), pp. 77-104; Zenke, Friedemann, Poole, Ben, Ganguli, Surya, Continual learning through synaptic intelligence (2017) Proceedings of the 34th International Conference on Machine Learning, 70, pp. 3987-3995. , pages JMLR. org; Chaudhry, Arslan, Dokania, Puneet K, Ajanthan, Thalaiyasingam, Torr, Philip HS, Riemannian walk for incremental learning: Understanding forgetting and intransigence (2018) Proceedings of the European Conference on Computer Vision (ECCV), pp. 532-547; Kirkpatrick, James, Pascanu, Razvan, Rabinowitz, Neil, Veness, Joel, Desjardins, Guillaume, Rusu, Andrei A, Milan, Kieran, Grabska-Barwinska, Agnieszka, Overcoming catastrophic forgetting in neural networks (2017) Proceedings of the national academy of sciences, 114 (13), pp. 3521-3526; Nguyen, Cuong V, Li, Yingzhen, Bui, Thang D, Turner, Richard E, (2017) Variational continual learning, , arXiv preprint arXiv:1710.10628; Swaroop, Siddharth, Nguyen, Cuong V, Bui, Thang D, Turner, Richard E, (2019) Improving and understanding variational continual learning, , arXiv preprint arXiv:1905.02099; Cohn, David A, Ghahramani, Zoubin, Jordan, Michael I, Active learning with statistical models (1996) Journal of artificial intelligence research, 4, pp. 129-145; Settles, Burr, Active learning (2012) Synthesis Lectures on Artificial Intelligence and Machine Learning, 6 (1), pp. 1-114; Garnelo, Marta, Schwarz, Jonathan, Rosenbaum, Dan, Viola, Fabio, Rezende, Danilo J, Eslami, SM, Teh, Yee Whye, (2018) Neural processes, , arXiv preprint arXiv:1807.01622; Kim, Hyunjik, Mnih, Andriy, Schwarz, Jonathan, Garnelo, Marta, Eslami, Ali, Rosenbaum, Dan, Vinyals, Oriol, Teh, Yee Whye, Attentive neural processes (2019) International Conference on Learning Representations, , https://openreview.net/forum?id=SkE6PjC9KX},
sponsors={Citadel; Doc.AI; et al.; Lambda; Lyft; Microsoft Research},
publisher={Neural information processing systems foundation},
issn={10495258},
language={English},
abbrev_source_title={Adv. neural inf. proces. syst.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Sonigo2018,
author={Sonigo, C. and Jankowski, S. and Yoo, O. and Trassard, O. and Bousquet, N. and Grynberg, M. and Beau, I. and Binart, N.},
title={High-throughput ovarian follicle counting by an innovative deep learning approach},
journal={Scientific Reports},
year={2018},
volume={8},
number={1},
doi={10.1038/s41598-018-31883-8},
art_number={13499},
note={cited By 14},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053192858&doi=10.1038%2fs41598-018-31883-8&partnerID=40&md5=0f982d30b3919c3af82303806a9f12bf},
affiliation={Inserm U1185, Univ Parus Sud, Université Paris Sud, Le Kremlin Bicetre, 94276, France; Quantmetry, 128 rue du Faubourg Saint Honoré, Paris, 75008, France; INSERM, Institut Biomédical de Bicêtre, 80 rue du Général Leclerc, Le Kremlin Bicêtre, 94276, France; Sorbonne Université, Laboratoire de Probabilité, Statistique et Modélisation, 4 place Jussieu, Paris, 75005, France; Institut de Mathématiques de Toulouse, Université Paul Sabatier, 118 route de Narbonne, Toulouse, 31400, France; Service de Médecine de la Reproduction et Préservation de la Fertilité, Hôpital Antoine Béclère, Hôpital Antoine Béclère, Clamart, 92140, France; Univ Paris Sud, Université Paris-Saclay, Le Kremlin Bicetre, 94276, France},
abstract={The evaluation of the number of mouse ovarian primordial follicles (PMF) can provide important information about ovarian function, regulation of folliculogenesis or the impact of chemotherapy on fertility. This counting, usually performed by specialized operators, is a tedious, time-consuming but indispensable procedure.The development and increasing use of deep machine learning algorithms promise to speed up and improve this process. Here, we present a new methodology of automatically detecting and counting PMF, using convolutional neural networks driven by labelled datasets and a sliding window algorithm to select test data. Trained from a database of 9 millions of images extracted from mouse ovaries, and tested over two ovaries (3 millions of images to classify and 2 000 follicles to detect), the algorithm processes the digitized histological slides of a completed ovary in less than one minute, dividing the usual processing time by a factor of about 30. It also outperforms the measurements made by a pathologist through optical detection. Its ability to correct label errors enables conducting an active learning process with the operator, improving the overall counting iteratively. These results could be suitable to adapt the methodology to the human ovarian follicles by transfer learning. © 2018, The Author(s).},
keywords={animal experiment;  article;  error;  female;  histopathology;  mouse;  nonhuman;  pathologist;  primordial follicle;  transfer of learning;  animal;  animal model;  high throughput screening;  ovary follicle;  procedures, Animals;  Deep Learning;  Female;  High-Throughput Screening Assays;  Mice;  Models, Animal;  Ovarian Follicle},
references={Wallace, W.H.B., Kelsey, T.W., Human ovarian reserve from conception to the menopause (2010) PloS One, 5. , PID: 20111701; Reddy, P., Zheng, W., Liu, K., Mechanisms maintaining the dormancy and survival of mammalian primordial follicles (2010) Trends Endocrinol. Metab. TEM, 21, pp. 96-103. , PID: 19913438; Monniaux, D., The ovarian reserve of primordial follicles and the dynamic reserve of antral growing follicles: what is the link? (2014) Biol. Reprod., 90, p. 85. , PID: 24599291; Tilly, J.L., Ovarian follicle counts–not as simple as 1, 2, 3 (2003) Reprod. Biol. Endocrinol. RBE, 1, p. 11; Myers, M., Britt, K.L., Wreford, N.G.M., Ebling, F.J.P., Kerr, J.B., Methods for quantifying follicular numbers within the mouse ovary (2004) Reprod. Camb. Engl., 127, pp. 569-580; Casari, C., Accelerated uptake of VWF/platelet complexes in macrophages contributes to VWD type 2B-associated thrombocytopenia (2013) Blood, 122, pp. 2893-2902. , PID: 23945153; Sharma, H., Zerbe, N., Klempert, I., Hellwich, O., Hufnagl, P., Deep convolutional neural networks for automatic classification of gastric carcinoma using whole slide images in digital histopathology (2017) Comput. Med. Imaging Graph. Off. J. Comput. Med. Imaging Soc., , https://doi.org/10.1016/j.compmedimag.2017.06.001; Vandenberghe, M.E., Relevance of deep learning to facilitate the diagnosis of HER2 status in breast cancer (2017) Sci. Rep., 7. , PID: 28378829; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521, pp. 436-444. , PID: 26017442; Araújo, T., Classification of breast cancer histology images using Convolutional Neural Networks (2017) PloS One, 12. , PID: 28570557; Cireşan, D.C., Giusti, A., Gambardella, L.M., Schmidhuber, J., Mitosis detection in breast cancer histology images with deep neural networks (2013) Med. Image Comput. Comput.-Assist. Interv. MICCAI Int. Conf. Med. Image Comput. Comput.-Assist. Interv., 16, pp. 411-418; Su, H., Robust Cell Detection and Segmentation in Histopathological Images Using Sparse Reconstruction and Stacked Denoising Autoencoders (2015) Med. Image Comput. Comput.-Assist. Interv. MICCAI Int. Conf. Med. Image Comput. Comput.-Assist. Interv., 9351, pp. 383-390; Sirinukunwattana, K., Locality Sensitive Deep Learning for Detection and Classification of Nuclei in Routine Colon Cancer Histology Images (2016) IEEE Trans. Med. Imaging, 35, pp. 1196-1206. , PID: 26863654; Litjens, G., Deep learning as a tool for increased accuracy and efficiency of histopathological diagnosis (2016) Sci. Rep., 6. , PID: 27212078; Bejnordi, B.E., Diagnostic Assessment of Deep Learning Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer (2017) JAMA, 318, pp. 2199-2210; Pedersen, T., Peters, H., Proposal for a classification of oocytes and follicles in the mouse ovary (1968) J. Reprod. Fertil., 17, pp. 555-557. , PID: 5715685; Welch, T.A., A Technique for High-Performance Data Compression (1984) Computer, 17, pp. 8-19; Goodfellow, I., Bengio, Y., Courville, A., (2016), Deep Learning (Adaptive Computation and Machine Learning series), part II, chapter 6, The MIT press; Hochreiter, S., Bengio, Y., Frasconi, P., Schmidhuber, J., (2001), A field guide to dynamical recurrent networds, Wiley-IEEE Press, chapter: Gradient Flow in Recurrent Nets: the Difficulty of Learning Long-Term Dependencies; Simonyan, K., Zisserman, A., (2014), Very Deep Convolutional Networks for Large-Scale Image Recognition, ArXiv14091556 Cs; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet Classification with Deep Convolutional Neural Networks (2012) Advances in Neural Information Processing Systems 25, pp. 1097-1105. , ds Pereira, F., Burges, C. J. C., Bottou, L. & Weinberger, K. Q, Curran Associates, Inc; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation (2014) Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition, pp. 580-587. , 10.1109/CVPR.2014.81, IEEE Computer Society; Ren, S., He, K., Girshick, R., Sun, J., (2015), Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks; Zeiler, M.D., (2012) ADADELTA: An Adaptive Learning Rate Method, , Cs; Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: A Simple Way to Prevent Neural Networks from Overfitting (2014) J. Mach. Learn. Res., 15, pp. 1929-1958; Chollet, F., (2015) Keras, Github, , https://github.com/fchollet/keras; Abadi, M., (2016) TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems; Bradski, G., (2018), http://www.drdobbs.com/open-source/the-opencv-library/184404319, The OpenCV Library. Dr. Dobb’s, Accessed: 16th February; Evans, E., (2013) Domain-Driven Design: Tackling Complexity in the Heart of Software; Suzuki, S., be, K., Topological structural analysis of digitized binary images by border following (1985) Comput. Vis. Graph. Image Process., 30, pp. 32-46; Perez, L., Wang, J., (2017) The Effectiveness of Data Augmentation in Image Classification using Deep Learning, , 171204621 Cs; Felzenszwalb, P.F., Girshick, R.B., McAllester, D., Ramanan, D., Object Detection with Discriminatively Trained Part-Based Models (2010) IEEE Trans. Pattern Anal. Mach. Intell., 32, pp. 1627-1645. , PID: 20634557; Dalal, N., Triggs, B., Histograms of oriented gradients for human detection (2005) 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05), 1, pp. 886-893; Wang, H., Mitosis detection in breast cancer pathology images by combining handcrafted and convolutional neural network features (2014) J. Med. Imaging Bellingham Wash, 1 (3); Bucci, T.J., Bolon, B., Warbritton, A.R., Chen, J.J., Heindel, J.J., Influence of sampling on the reproducibility of ovarian follicle counts in mouse toxicity studies (1997) Reprod. Toxicol. Elmsford N, 11, pp. 689-696; Miller, P.B., Charleston, J.S., Battaglia, D.E., Klein, N.A., Soules, M.R., An accurate, simple method for unbiased determination of primordial follicle number in the primate ovary (1997) Biol. Reprod., 56, pp. 909-915. , PID: 9096872; Charleston, J.S., Estimating human ovarian non-growing follicle number: the application of modern stereology techniques to an old problem (2007) Hum. Reprod. Oxf. Engl., 22, pp. 2103-2110; Guzy, L., Demeestere, I., Assessment of ovarian reserve and fertility preservation strategies in children treated for cancer (2016) Minerva Ginecol; Donnez, J., Dolmans, M.-M., Fertility Preservation in Women (2017) N. Engl. J. Med., 377, pp. 1657-1665. , PID: 29069558},
correspondence_address1={Sonigo, C.; Inserm U1185, France; email: charlotte.sonigo@gmail.com},
publisher={Nature Publishing Group},
issn={20452322},
pubmed_id={30202115},
language={English},
abbrev_source_title={Sci. Rep.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Lin20184048,
author={Lin, J. and Zhao, L. and Li, S. and Ward, R. and Wang, Z.J.},
title={Active-Learning-Incorporated Deep Transfer Learning for Hyperspectral Image Classification},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
year={2018},
volume={11},
number={11},
pages={4048-4062},
doi={10.1109/JSTARS.2018.2874225},
art_number={8531707},
note={cited By 18},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056361326&doi=10.1109%2fJSTARS.2018.2874225&partnerID=40&md5=3c84ad384e76d43fe1e864f8cc12ef6c},
affiliation={Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC  V6T 1Z2, Canada; School of Information Science and Technology, Northwest University, Xi'an, 710069, China; School of Software Technology, Dalian University of Technology, Dalian, 116023, China; School of Automation, Xi'an University of Post and Telecommunications, Xi'an, 710121, China},
abstract={A hyperspectral image (HSI) includes a vast quantity of samples, a large number of bands, and randomly occurring redundancy. Classifying such complex data is challenging, and its classification performance can be affected significantly by the amount of labeled training samples, as well as the quality, position, and others factors of these samples. Collecting such labeled training samples is labor and time consuming, motivating the idea of taking advantage of labeled samples from other pre-existing related images. Therefore, transfer learning, which can mitigate the semantic gap between existing and new HSIs, has drawn increasing research attention. However, existing transfer learning methods for HSIs (which mainly concentrate on how to overcome the divergence among images) may fail to carefully consider the contents to be transferred and thus limit their performances. In this paper, we present two novel ideas: 1) we, for the first time, introduce an active learning process to initialize the salient samples on the HSI data, which would be transferred later; and 2) we propose constructing and connecting higher level features for the source and target HSI data to further overcome the cross-domain disparity. Different from existing methods, the proposed framework requires no a priori knowledge on the target domain, and it works for both homogeneous and heterogeneous HSI data. Experimental results on three real-world HSIs support the effectiveness of the proposed method for HSI classification. © 2018 IEEE.},
author_keywords={Hyperspectral image (HSI);  salient samples;  supervised classification;  transfer learning},
keywords={Artificial intelligence;  Classification (of information);  Correlation methods;  Hyperspectral imaging;  Image classification;  Neural networks;  Personnel training;  Sampling;  Semantics;  Spectroscopy, Active Learning;  Active-learning process;  Classification performance;  Priori knowledge;  Supervised classification;  Training sample;  Transfer learning;  Transfer learning methods, Deep learning, data set;  image analysis;  image classification;  machine learning;  spectral analysis;  supervised classification},
funding_details={Qatar FoundationQatar Foundation, QF, 7-684-1-127},
funding_details={Qatar National Research FundQatar National Research Fund, QNRF},
funding_text 1={Manuscript received April 24, 2018; revised July 5, 2018 and September 20, 2018; accepted September 22, 2018. Date of publication November 12, 2018; date of current version November 27, 2018. This work was supported by the Qatar National Research Fund (a member of the Qatar Foundation) through the National Priorities Research Program under Grant 7-684-1-127. (Corresponding author: Shuying Li.) J. Lin and Z. J. Wang are with the Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC V6T 1Z2, Canada, and also with the School of Information Science and Technology, Northwest University, Xi’an 710069, China (e-mail:, jianzhelin@ece.ubc.ca; zjanew@ece.ubc.ca).},
references={Foody, G., Mathur, A., Toward intelligent training of supervised image classifications:Directing training data acquisition forSVMclassification (2004) Remote Sens. Environ., 93 (1), pp. 107-117; Samat, A., Li, J., Liu, S., Du, P., Miao, Z., Luo, J., Improved hyperspectral image classification by active learning using pre-designed mixed pixels (2016) Pattern Recognit., 51, pp. 43-58; Shao, M., Castillo, C., Zhenghong, G., Fu, Y., Low-rank transfer subspace learning (2012) Proc. IEEE Int. Conf. Data Mining, pp. 1104-1109; Rodriguez, A., Laio, A., Clustering by fast search and find of density peaks (2014) Science, 344 (6191), pp. 1492-1496; Zhou, X., Prasad, S., Active and semisupervised learning with morphological component analysis for hyperspectral image classification (2017) IEEE Geosci. Remote Sens. Lett., 14 (8), pp. 1348-1352. , Aug; Liu, P., Zhang, H., Eom, K.B., Active deep learning for classification of hyperspectral images (2017) IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., 10 (2), pp. 712-724. , Feb; Wang, Z., Du, B., Zhang, L., Zhang, L., Jia, X., A novel semisupervised active-learning algorithm for hyperspectral image classification (2017) IEEE Trans. Geosci. Remote Sens., 55 (6), pp. 3071-3083. , Jun; Lin, J., Ward, R., Wang, Z., Deep transfer learning for hyperspectral image classification (2018) Proc. IEEE Int. Workshop Multimedia Signal Process., pp. 1-4; Huang, S., Jin, R., Zhou, Z., Active learning by querying informative and representative examples (2014) IEEE Trans. Pattern Anal. Mach. Intell., 36 (10), pp. 1936-1949. , Oct; Balcan, M., Broder, A., Zhang, T., Margin based active learning (2007) Proc. 20th Annu. Conf. Learn. Theory, pp. 35-50; Tong, S., Koller, D., Support vector machine active learning with applications to text classification (2000) Proc. 17th Int. Conf. Mach. Learn., pp. 999-1006; Lewis, D., Catlett, J., Heterogeneous uncertainty sampling for supervised learning (1994) Proc. 11th Int. Conf. Mach. Learn., pp. 148-156; Dagan, I., Engelson, S., Committee-based sampling for training probabilistic classifiers (1995) Proc. 12th Int. Conf. Mach. Learn., pp. 150-157; Freund, Y., Seung, H., Shamir, E., Tishby, N., Selective sampling using the query by committee algorithm (1997) Mach. Learn., 28 (2-3), pp. 133-168; Xu, Z., Yu, K., Tresp, V., Xu, X., Wang, J., Query by committee (1992) Proc. Int. Workshop Comput. Learn. Theory, pp. 287-294; Roy, N., Mccallum, A., Toward optimal active learning through sampling estimation of error reduction (2001) Proc. 18th Int. Conf.Mach. Learn., pp. 441-448; Guo, Y., Schuurman, D., Toward optimal active learning through sampling estimation of error reduction (2007) Proc. Neural Inf. Process. Syst. Conf., pp. 593-600; Wang, Q., Zhang, F., Li, X., Optimal clustering framework for hyperspectral band selection (2018) IEEE Trans. Geosci. Remote Sens., 56 (10), pp. 5910-5922. , Oct; Dasgupta, S., HsuLewis, D., Hierarchical sampling for active learning (2008) Proc. IEEE Int. Conf. Mach. Learn., pp. 208-215; Chattopadhyay, R., Wang, Z., Fan, W., Davidson, I., Panchanathan, S., Ye, J., Batch mode active sampling based on marginal probability distribution matching (2012) Proc. ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 741-749; Yu, K., Ji, B., Tresp, V., Active learning via transductive experimental design (2006) Proc. IEEE Int. Conf. Mach. Learn., pp. 1081-1088; Donmez, P., Carbonell, J., Bennett, P., Active learning via transductive experimental design (2007) Proc. IEEE Int. Conf. Mach. Learn., pp. 116-127; Matasci, G., Tuia, D., Kanevski, M., SVM-based boosting of active learning strategies for efficient domain adaptation (2012) IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., 5 (5), pp. 1335-1343. , Oct; Persello, C., Interactive domain adaptation for the classification of remote sensing images using active learning (2013) IEEE Geosci. Remote Sens. Lett., 10 (4), pp. 736-740. , Jul; Zhao, L., Pan, S., Xiang, W., Zhong, E., Lu, Z., Yang, Q., Active transfer learning for cross-system recommendation (2013) Proc. Assoc. Adv. Artif. Intell., pp. 1205-1211; Gavves, E., Mensink, T., Tommasi, T., Snoek, C.G., Tuytelaars, T., (2015) Active Transfer Learning with Zero-shot Priors: Reusing Past Datasets for Future Tasks; Persello, C., Bruzzone, L., Active learning for domain adaptation in the supervised classification of remote sensing images (2012) IEEE Trans. Geosci. Remote Sens., 50 (11), pp. 4468-4483. , Nov; Persello, C., Bruzzone, L., A novel active learning strategy for domain adaptation in the classification of remote sensing images (2011) Proc. IEEE Int. Conf. Geosci. Remote Sens. Symp., pp. 3720-3723; Pan, S.J., Yang, Q., A survey on transfer learning (2010) IEEE Trans. Knowl. Data Eng., 22 (10), pp. 1345-1359. , Oct; Li, J., Zhang, H., Huang, Y., Zhang, L., Visual domain adaptation: A survey of recent advances (2015) IEEE Signal Process. Mag., 33 (3), pp. 53-69. , May; Wang, Q., Yuan, Z., Li, X., GETNET: A general end-to-end twodimensional CNN framework for hyperspectral image change detection (2018) IEEE Trans. Geosci. Remote Sens., , to be published; Glorot, X., Bordes, A., Bengio, Y., Domain adaptation for large-scale sentiment classification: A deep learning approach (2011) Proc. Int. Conf. Mach. Learn., pp. 513-521; Chen, M., Xu, Z., Weinberger, K., Sha, F., Marginalized denoising autoencoders for domain adaptation (2011) Proc. Int. Conf. Mach. Learn., pp. 1-8; Ding, Z., Nasrabadi, N., Fu, Y., Task-driven deep transfer learning for image classification (2016) Proc. IEEE Int. Conf. Acoust., Speech, Signal Process., pp. 2414-2418; Zhuang, F., Cheng, X., Luo, P., Pan, S., He, Q., Supervised representation learning: Transfer learning with deep autoencoders (2015) Proc. Int. Joint Conf. Artif. Intell., pp. 4119-4125; Hardoon, D., Szedmak, S., Shawe-Taylor, J., Canonical correlation analysis: An overviewwith application to learning methods (2004) Neural Comput., 16 (12), pp. 2639-2664; Lin, J., Wang, Q., Ward, R., Wang, Z., (2018) DT-LET: Deep Transfer Learning by Exploring Where to Transfer; Andrew, G., Arora, R., Bilmes, J., Livescu, K., Deep canonical correlation analysis (2013) Proc. Int. Conf. Mach. Learn., pp. 1247-1255; Li, X., Zhang, L., Du, B., Zhang, L., Shi, Q., Iterative reweighting heterogeneous transfer learning framework for supervised remote sensing image classification (2017) IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., 10 (5), pp. 2022-2035. , May; Zhou, J., Pan, J., Tsang, I., Yan, Y., Active transfer learning for cross-system recommendation (2014) Proc. Assoc. Adv. Artif. Intell., pp. 2213-2220; Tang, J., Shu, X., Li, Z., Qi, G., Wang, J., Generalized deep transfer networks for knowledge propagation in heterogeneous domains (2016) ACM Trans. Multimedia Comput., Commun., Appl., 12 (4); Li, X., Liu, B., Ng, S., Negative training data can be harmful to text classification (2010) Proc. Conf. Empirical Methods Natural Lang. Process., pp. 218-228; Seah, C., Ong, Tsang, I., Combating negative transfer from predictive distribution differences (2013) IEEE Trans. Cybern., 43 (4), pp. 1153-1165. , Aug; Yeh, Y., Huang, C., Wang, Y., Heterogeneous domain adaptation and classification by exploiting the correlation subspace (2014) IEEE Trans. Image Process., 23 (5), pp. 2009-2018. , May; Lin, J., He, C., Wang, Z., Li, S., Structure preserving transfer learning for unsupervised hyperspectral image classification (2017) IEEE Geosci. Remote Sens. Lett., 14 (10), pp. 1656-1660. , Oct},
correspondence_address1={Li, S.; School of Automation, China; email: angle_lisy@163.com},
publisher={Institute of Electrical and Electronics Engineers},
issn={19391404},
language={English},
abbrev_source_title={IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Jiang20181,
author={Jiang, H. and Wang, R. and Li, Y. and Liu, H. and Shan, S. and Chen, X.},
title={Attribute annotation on large-scale image database by active knowledge transfer},
journal={Image and Vision Computing},
year={2018},
volume={78},
pages={1-13},
doi={10.1016/j.imavis.2018.06.012},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051024794&doi=10.1016%2fj.imavis.2018.06.012&partnerID=40&md5=65829cf2827d3ab9b27ad04d4d74cca3},
affiliation={Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences, Shanghai, 200050, China; Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences, Chinese Academy of Sciences, Institute of Computing Technology, Beijing, 100190, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, 201210, China; University of Chinese Academy of Sciences, Beijing, 100049, China},
abstract={Attributes are widely used in different vision tasks. However, existing attribute resources are quite limited and most of them are not in large scale. Current attribute annotation process is generally done by human, which is expensive and time-consuming. In this paper, we propose a novel framework to perform effective attribute annotations. Based on the common knowledge that attributes can be shared among different classes, we leverage the benefits of transfer learning and active learning together to transfer knowledge from some existing small attribute databases to large-scale target databases. In order to learn more robust attribute models, attribute relationships are incorporated to assist the learning process. Using the proposed framework, we conduct extensive experiments on two large-scale image databases, i.e. ImageNet and SUN Attribute, where high quality automatic attribute annotations are obtained. © 2018 Elsevier B.V.},
author_keywords={Active learning;  Annotation;  Attribute;  Relationship;  Transfer learning},
keywords={Artificial intelligence;  Database systems;  Knowledge management, Active Learning;  Annotation;  Attribute;  Relationship;  Transfer learning, Image annotation},
funding_details={University of Washington College of Arts and SciencesUniversity of Washington College of Arts and Sciences, CAS, 2015085, QYZDJ-SSW-JSC009},
funding_details={National Natural Science Foundation of ChinaNational Natural Science Foundation of China, NSFC, 61390511, 61772500},
funding_details={National Basic Research Program of China (973 Program)National Basic Research Program of China (973 Program), 2015CB351802},
funding_text 1={This work is partially supported by 973 Program under contract No. 2015CB351802, Natural Science Foundation of China under contract Nos. 61390511 and 61772500, Frontier Science Key Research Project CAS No. QYZDJ-SSW-JSC009, and Youth Innovation Promotion Association CAS No. 2015085.},
funding_text 2={This work is partially supported by 973 Program under contract No. 2015CB351802 , Natural Science Foundation of China under contract Nos. 61390511 and 61772500 , Frontier Science Key Research Project CAS No. QYZDJ-SSW-JSC009 , and Youth Innovation Promotion Association CAS No. 2015085 .},
references={Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Li, F.F., ImageNet: a large-scale hierarchical image database (2009) Computer Vision and Pattern Recognition, pp. 248-255; Lampert, C.H., Nickisch, H., Harmeling, S., Learning to detect unseen object classes by between-class attribute transfer (2009) Computer Vision and Pattern Recognition, pp. 951-958; Farhadi, A., Endres, I., Hoiem, D., Forsyth, D., Describing objects by their attributes (2009) Computer Vision and Pattern Recognition, pp. 1778-1785; Huang, C., Change Loy, C., Tang, X., Unsupervised learning of discriminative attributes and visual representations (2016) Computer Vision and Pattern Recognition, pp. 5175-5184; Siddiquie, B., Feris, R.S., Davis, L.S., Image ranking and retrieval based on multi-attribute queries (2011) Computer Vision and Pattern Recognition, pp. 801-808; Kovashka, A., Parikh, D., Grauman, K., Whittlesearch: image search with relative attribute feedback (2012) Computer Vision and Pattern Recognition, pp. 2973-2980; Kovashka, A., Grauman, K., Attribute pivots for guiding relevance feedback in image search (2013) International Conference on Computer Vision, pp. 297-304; Patterson, G., Hays, J., Sun attribute database: discovering, annotating, and recognizing scene attributes (2012) Computer Vision and Pattern Recognition, pp. 2751-2758; Liu, J., Kuipers, B., Savarese, S., Recognizing human actions by attributes (2011) Computer Vision and Pattern Recognition, pp. 3337-3344; Diba, A., Pazandeh, A.M., Pirsiavash, H., Gool, L.V., DeepCAMP: deep convolutional action & attribute mid-level patterns (2016) Computer Vision and Pattern Recognition, pp. 3557-3565; Fu, Y., Hospedales, T.M., Xiang, T., Fu, Z., Gong, S., Transductive multi-view embedding for zero-shot recognition and annotation (2014) European Conference on Computer Vision, pp. 584-599; Douze, M., Ramisa, A., Schmid, C., Combining attributes and fisher vectors for efficient image retrieval (2011) Computer Vision and Pattern Recognition, pp. 745-752; Kulkarni, G., Premraj, V., Ordonez, V., Dhar, S., Li, S., Choi, Y., Berg, A.C., Berg, T.L., Babytalk: understanding and generating simple image descriptions (2013) IEEE Trans. Pattern Anal. Mach. Intell., 35 (12), p. 2891; Ordonez, V., Kulkarni, G., Berg, T.L., Im2Text: describing images using 1 million captioned photographs (2011), pp. 1143-1151; Wang, Y., Mori, G., A discriminative latent model of object classes and attributes (2010) European Conference on Computer Vision, pp. 155-168; Mahajan, D., Sellamanickam, S., Nair, V., A joint learning framework for attribute models and object descriptions (2011) International Conference on Computer Vision, pp. 1227-1234; Fu, Y., Hospedales, T.M., Xiang, T., Gong, S., Attribute learning for understanding unstructured social activity (2012) European Conference on Computer Vision, pp. 530-543; Chen, L., Zhang, Q., Li, B., Predicting multiple attributes via relative multi-task learning (2014) Computer Vision and Pattern Recognition, pp. 1027-1034; Liu, M., Zhang, D., Chen, S., Attribute relation learning for zero-shot classification (2014) Neurocomputing, 139, pp. 34-46; Jayaraman, D., Sha, F., Grauman, K., Decorrelating semantic visual attributes by resisting the urge to share (2014) Computer Vision and Pattern Recognition, pp. 1629-1636; Kusakunniran, W., Attribute-based learning for gait recognition using spatio-temporal interest points (2014) Image Vis. Comput., 32 (12), pp. 1117-1126; Huang, S., Elhoseiny, M., Elgammal, A., Yang, D., Learning hypergraph-regularized attribute predictors (2015) Computer Vision and Pattern Recognition, pp. 409-417; Samangouei, P., Patel, V.M., Chellappa, R., Facial attributes for active authentication on mobile devices (2017) Image Vis. Comput., 58, pp. 181-192; Al-Halah, Z., Stiefelhagen, R., Automatic discovery, association estimation and learning of semantic attributes for a thousand categories (2017) Computer Vision and Pattern Recognition, pp. 5112-5121; Luo, P., Wang, X., Tang, X., A deep sum-product architecture for robust facial attributes analysis (2013) International Conference on Computer Vision, pp. 2864-2871; Zhang, N., Paluri, M., Ranzato, M., Darrell, T., Bourdev, L., PANDA: pose aligned networks for deep attribute modeling (2014) Computer Vision and Pattern Recognition, pp. 1637-1644; Chen, Q., Huang, J., Feris, R., Brown, L.M., Dong, J., Yan, S., Deep domain adaptation for describing people based on fine-grained clothing attributes (2015) Computer Vision and Pattern Recognition, pp. 5315-5324; Escorcia, V., Niebles, J.C., Ghanem, B., On the relationship between visual attributes and convolutional networks (2015) Computer Vision and Pattern Recognition, pp. 1256-1264; Zhu, J., Liao, S., Lei, Z., Li, S.Z., Multi-label convolutional neural network based pedestrian attribute classification (2017) Image Vis. Comput., 58, pp. 224-229; Russakovsky, O., Fei-Fei, L., Attribute learning in large-scale datasets (2010) European Conference on Trends and Topics in Computer Vision, pp. 1-14; Patterson, G., Hays, J., COCO attributes: attributes for people, animals, and objects (2016) European Conference on Computer Vision, pp. 85-100; Pan, S.J., Yang, Q., A survey on transfer learning (2010) IEEE Trans. Knowl. Data Eng., 22 (10), pp. 1345-1359; Aytar, Y., Zisserman, A., Tabula rasa: model transfer for object category detection (2011) International Conference on Computer Vision, pp. 2252-2259; Gavves, E., Mensink, T., Tommasi, T., Snoek, C.G.M., Tuytelaars, T., Active transfer learning with zero-shot priors: reusing past datasets for future tasks (2015) International Conference on Computer Vision, pp. 2731-2739; Saenko, K., Kulis, B., Fritz, M., Darrell, T., Adapting visual category models to new domains (2010) European Conference on Computer Vision, pp. 213-226; Gopalan, R., Li, R., Chellappa, R., Domain adaptation for object recognition: an unsupervised approach (2011) International Conference on Computer Vision, pp. 999-1006; Gong, B., Shi, Y., Sha, F., Grauman, K., Geodesic flow kernel for unsupervised domain adaptation (2012) Computer Vision and Pattern Recognition, pp. 2066-2073; Kovashka, A., Grauman, K., Attribute adaptation for personalized image search (2013) International Conference on Computer Vision, pp. 3432-3439; Han, Y., Yang, Y., Ma, Z., Shen, H., Sebe, N., Zhou, X., Image attribute adaptation (2014) Multimedia, 16 (4), pp. 1115-1126; Gan, C., Yang, T., Gong, B., Learning attributes equals multi-source domain generalization (2016) Computer Vision and Pattern Recognition, pp. 87-97; Settles, B., (2009) Active Learning Literature Survey, 39 2), pp. 127-131. , University of Wisconsin-Madison; Kapoor, A., Grauman, K., Urtasun, R., Darrell, T., Gaussian processes for object categorization (2010) IJCV, 88 (2), pp. 169-188; Tong, S., Koller, D., Support vector machine active learning with applications to text classification (2002) J. Mach. Learn. Res., 2 (1), pp. 45-66; Freund, Y., Seung, H.S., Shamir, E., Tishby, N., Selective sampling using the query by committee algorithm (1997) Mach. Learn., 28 (2), pp. 133-168; Mackay, D.J.C., Information-based objective functions for active data selection (1989) Neural Comput., 4 (4), pp. 590-604; Biswas, A., Parikh, D., Simultaneous active learning of classifiers & attributes via relative feedback (2013) Computer Vision and Pattern Recognition, pp. 644-651; Liang, L., Grauman, K., Beyond comparing image pairs: setwise active learning for relative attributes (2014) Computer Vision and Pattern Recognition, pp. 208-215; Mensink, T., Verbeek, J., Csurka, G., Learning structured prediction models for interactive image labeling (2011) Computer Vision and Pattern Recognition, pp. 833-840; Zhang, Y., Yeung, D.-Y., Multi-task boosting by exploiting task relationships (2012) European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 697-710; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., ImageNet large scale visual recognition challenge (2015) Int. J. Comput. Vis., 115 (3), pp. 211-252; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R.B., Guadarrama, S., Darrell, T., Caffe: convolutional architecture for fast feature embedding (2014) Multimedia, pp. 675-678; Xiao, J., Hays, J., Ehinger, K.A., Oliva, A., Torralba, A., Sun database: large-scale scene recognition from abbey to zoo (2010) Computer Vision and Pattern Recognition, pp. 3485-3492},
correspondence_address1={Wang, R.; Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences, China; email: wangruiping@ict.ac.cn},
publisher={Elsevier Ltd},
issn={02628856},
coden={IVCOD},
language={English},
abbrev_source_title={Image Vision Comput},
document_type={Article},
source={Scopus},
}

@ARTICLE{Deng2018306,
author={Deng, C. and Liu, X. and Li, C. and Tao, D.},
title={Active multi-kernel domain adaptation for hyperspectral image classification},
journal={Pattern Recognition},
year={2018},
volume={77},
pages={306-315},
doi={10.1016/j.patcog.2017.10.007},
note={cited By 61},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032215970&doi=10.1016%2fj.patcog.2017.10.007&partnerID=40&md5=6a54630b10b5ae97c643201f3159dd2a},
affiliation={School of Electronic Engineering, Xidian University, Xi'an, Shaanxi  710071, China; State Key Lab of Software Development Environment, Beihang University, Beijing, 100191, China; UBTECH Sydney AI Centre, School of IT, FEIT, The University of Sydney, Australia},
abstract={Recent years have witnessed the quick progress of the hyperspectral images (HSI) classification. Most of existing studies either heavily rely on the expensive label information using the supervised learning or can hardly exploit the discriminative information borrowed from related domains. To address this issues, in this paper we show a novel framework addressing HSI classification based on the domain adaptation (DA) with active learning (AL). The main idea of our method is to retrain the multi-kernel classifier by utilizing the available labeled samples from source domain, and adding minimum number of the most informative samples with active queries in the target domain. The proposed method adaptively combines multiple kernels, forming a DA classifier that minimizes the bias between the source and target domains. Further equipped with the nested actively updating process, it sequentially expands the training set and gradually converges to a satisfying level of classification performance. We study this active adaptation framework with the Margin Sampling (MS) strategy in the HSI classification task. Our experimental results on two popular HSI datasets demonstrate its effectiveness. © 2017 Elsevier Ltd},
author_keywords={Active learning;  Domain adaptation;  Hyperspectral image classification;  Multi-kernel;  Remote sensing},
keywords={Artificial intelligence;  Classification (of information);  Hyperspectral imaging;  Independent component analysis;  Remote sensing;  Spectroscopy, Active Learning;  Adaptation framework;  Classification performance;  Classification tasks;  Domain adaptation;  Label information;  Multi-kernel;  Multiple kernels, Image classification},
funding_details={2017ZDCXL-GY-05-02, 2017ZDCXL-GY-05-04-02},
funding_details={National Natural Science Foundation of ChinaNational Natural Science Foundation of China, NSFC, 61402026, 61572388},
funding_details={Beijing Municipal Science and Technology CommissionBeijing Municipal Science and Technology Commission, Z171100000117022},
funding_details={State Key Laboratory of Software Development EnvironmentState Key Laboratory of Software Development Environment, SKLSDE, SKLSDE-2016ZX-04},
funding_text 1={This work was supported by the National Natural Science Foundation of China ( 61402026 and 61572388 ), the Key R&D Program – The Key Industry Innovation Chain of Shaanxi (Grant nos. 2017ZDCXL-GY-05-04-02 and 2017ZDCXL-GY-05-02), Beijing Municipal Science and Technology Commission (Z171100000117022) and the Foundation of State Key Lab of Software Development Environment (SKLSDE-2016ZX-04).},
references={Alajlan, N., Pasolli, E., Melgani, F., Franzoso, A., Large-scale image classification using active learning (2014) IEEE Geosci. Remote Sensing Lett., 11 (1), pp. 259-263; Li, N., Zhao, H., Huang, P., Jia, G., Bai, X., A novel logistic multi-class supervised classification model based on multi-fractal spectrum parameters for hyperspectral data (2015) Int. J. Comput. Math., 92 (4), pp. 836-849; Li, Z., Li, C., Deng, C., Li, J., Hyperspectral image super-resolution using sparse spectral unmixing and low-rank constraints (2016) Proceedings of IEEE International Geoscience and Remote Sensing Symposium, IGARSS, pp. 7224-7227; Tong, L., Zhou, J., Qian, Y., Bai, X., Gao, Y., Nonnegative-matrix-factorization-based hyperspectral unmixing with partially known endmembers (2016) IEEE Trans. Geosci. Remote Sens., 54 (11), pp. 6531-6544; Tang, Y., Fan, E., Yan, C., Bai, X., Zhou, J., Discriminative weighted band selection via one-class SVM for hyperspectral imagery (2016) Proceedings of IEEE International Geoscience and Remote Sensing Symposium, IGARSS, pp. 2765-2768; Hyperspectral image reconstruction by deep convolutional neural network for classification (2017) Pattern Recognit., 63, pp. 371-383; Plaza, J., Plaza, A., Perez, R., Martinez, P., On the use of small training sets for neural network-based characterization of mixed pixels in remotely sensed hyperspectral images (2009) Pattern Recognit., 42 (11), pp. 3032-3045; Tarabalka, Y., Chanussot, J., Benediktsson, J., Segmentation and classification of hyperspectral images using watershed transformation (2010) Pattern Recognit., 43 (7), pp. 2367-2379; Li, W., Prasad, S., Fowler, J.E., Hyperspectral image classification using Gaussian mixture models and Markov random fields (2014) IEEE Geosci. Remote Sens. Lett., 11 (1), pp. 153-157; Samat, A., Li, J., Liu, S., Du, P., Miao, Z., Luo, J., Improved hyperspectral image classification by active learning using pre-designed mixed pixels (2016) Pattern Recognit., 51, pp. 43-58; Ye, M., Qian, Y., Zhou, J., Tang, Y., Dictionary learning based feature level domain adaptation for cross-scene hyperspectral image classification (2016) IEEE Trans. Geosci. Remote Sens., pp. 1544-1562; Yan, C., Bai, X., Ren, P., Bai, L., Tang, W., Zhou, J., Band weighting via maximizing interclass distance for hyperspectral image classification (2016) IEEE Geosci. Remote Sens. Lett., 13 (7), pp. 922-925; Zhang, E., Zhang, X., Jiao, L., Li, L., Hou, B., Spectral¿cspatial hyperspectral image ensemble classification via joint sparse representation (2016) Pattern Recognit., 59, pp. 42-54; Probabilistic class structure regularized sparse representation graph for semi-supervised hyperspectral image classification (2017) Pattern Recognit., 63, pp. 102-114; A novel spectral-spatial co-training algorithm for the transductive classification of hyperspectral imagery data (2017) Pattern Recognit., 63, pp. 229-245; Ifarraguerri, A., Chang, C.-I., Unsupervised hyperspectral image analysis with projection pursuit (2000) IEEE Trans. Geosci. Remote Sens., 38 (6), pp. 2529-2538; Rajan, S., Ghosh, J., Crawford, M.M., An active learning approach to hyperspectral data classification (2008) IEEE Trans. Geosci. Remote Sens., 46 (4), pp. 1231-1242; Chen, C., Li, S., Qin, H., Hao, A., Structure-sensitive saliency detection via multilevel rank analysis in intrinsic feature space (2015) IEEE Trans. Image Process., 24 (8), pp. 2303-2316; Bruzzone, L., Marconcini, M., Domain adaptation problems: a DASVM classification technique and a circular validation strategy (2010) IEEE Trans. Pattern Anal. Mach. Intell., 32 (5), pp. 770-787; Sun, Z., Wang, C., Wang, H., Li, J., Learn multiple-kernel SVMs for domain adaptation in hyperspectral data (2013) IEEE Geosci. Remote Sens. Lett., 10 (5), pp. 1224-1228; Bruzzone, L., Fernández-Prieto, D., Unsupervised retraining of a maximum likelihood classifier for the analysis of multitemporal remote sensing images (2001) IEEE Trans. Geosci. Remote Sens., 39 (2), pp. 456-460; Persello, C., Bruzzone, L., A novel active learning strategy for domain adaptation in the classification of remote sensing images (2011) Proceedings of 2011 IEEE International Geoscience and Remote Sensing Symposium, pp. 3720-3723; Tuia, D., Pasolli, E., Emery, W., Dataset shift adaptation with active queries (2011) Urban Remote Sensing Event, pp. 121-124; Persello, C., Bruzzone, L., Active learning for domain adaptation in the supervised classification of remote sensing images (2012) IEEE Trans. Geosci. Remote Sens., 50 (11), pp. 4468-4483; Dai, W., Yang, Q., Xue, G.-R., Yu, Y., Boosting for transfer learning (2007) Proceedings of the 24th International Conference on Machine Learning, ICML’07, pp. 193-200. , ACM New York, NY, USA; Tuia, D., Pasolli, E., Emery, W., Using active learning to adapt remote sensing image classifiers (2011) Remote Sens. Environ., 115 (9), pp. 2232-2242; Schohn, G., Cohn, D., Less is more: active learning with support vector machines (2000) Proceedings of International Conference on Machine Learning, ICML, pp. 839-846; Mitra, P., Shankar, B.U., Pal, S.K., Segmentation of multispectral remote sensing images using active support vector machines (2004) Pattern Recognit. Lett., 25 (9), pp. 1067-1074; Demir, B., Persello, C., Bruzzone, L., Batch-mode active-learning methods for the interactive classification of remote sensing images (2011) IEEE Trans. Geosci. Remote Sens., 49 (3), pp. 1014-1031; Camps-Valls, G., Tuia, D., Bruzzone, L., Benediktsson, J.A., Advances in hyperspectral image classification: earth monitoring with statistical learning methods (2014) IEEE Signal Process. Mag., 31 (1), pp. 45-54; Crawford, M.M., Tuia, D., Yang, H.L., Active learning: any value for classification of remotely sensed data? (2013) Proc. IEEE, 101 (3), pp. 593-608; Melgani, F., Bruzzone, L., Classification of hyperspectral remote sensing images with support vector machines (2004) IEEE Trans. Geosci. Remote Sens., 42 (8), pp. 1778-1790; Xu, J., Liu, X., Huo, Z., Deng, C., Nie, F., Huang, H., Multi-class support vector machine via maximizing multi-class margins (2017) Proceedings of International Joint Conference on Artificial Intelligence, IJCAI, pp. 3154-3160; Liu, X., He, J., Lang, B., Multiple feature kernel hashing for large-scale visual search (2014) Pattern Recognit, 47 (2), pp. 748-757; Bandyopadhyay, S., Bandyopadhyay, S., Analysis of Biological Data: A Soft Computing Approach – Vol. 3 (2007), World Scientific Publishing Co., Inc. River Edge, NJ, USA; Camps-Valls, G., Bruzzone, L., Kernel-based methods for hyperspectral image classification (2005) IEEE Trans. Geosci. Remote Sens., 43 (6), pp. 1351-1362; Camps-Valls, G., Gomez-Chova, L., Munoz-Mari, J., Vila-Frances, J., Calpe-Maravilla, J., Composite kernels for hyperspectral image classification (2006) IEEE Geosci. Remote Sens. Lett., 3 (1), pp. 93-97; Camps-Valls, G., Marsheva, T.V.B., Zhou, D., Semi-supervised graph-based hyperspectral image classification (2007) IEEE Trans. Geosci. Remote Sens., 45 (10), pp. 3044-3054; Liu, T., Gu, Y., Jia, X., Benediktsson, J.A., Chanussot, J., Class-specific sparse multiple kernel learning for spectral spatial hyperspectral image classification (2016) IEEE Trans. Geosci. Remote Sens., 54 (12), pp. 7351-7365; Tuia, D., Persello, C., Bruzzone, L., Domain adaptation for the classification of remote sensing data: an overview of recent advances (2016) IEEE Geosci. Remote Sens. Mag., 4 (2), pp. 41-57; Tong, S., Koller, D., Support vector machine active learning with applications to text classification (2002) J. Mach. Learn. Res., 2, pp. 45-66; Jain, P., Vijayanarasimhan, S., Grauman, K., Hashing hyperplane queries to near points with applications to large-scale active learning (2010) Proceedings of Advances in Neural Information Processing Systems, pp. 928-936; Huang, L., Liu, Y., Liu, X., Wang, X., Lang, B., Graph-based active semi-supervised learning: A new perspective for relieving multi-class annotation labor (2014) Proceedings of IEEE International Conference on Multimedia & Expo, ICME, pp. 1-6; Liu, X., Fan, X., Deng, C., Li, Z., Su, H., Tao, D., Multilinear hyperplane hashing (2016) Proceedings of IEEE Computer Vision and Pattern Recognition, CVPR, pp. 1-9; Matasci, G., Tuia, D., Kanevski, M., SVM-based boosting of active learning strategies for efficient domain adaptation (2012) IEEE J. Sel. Top. Appl. Earth Obser. Remote Sens., 5 (5), pp. 1335-1343; Tuia, D., Ratle, F., Pacifici, F., Kanevski, M.F., Emery, W.J., Active learning methods for remote sensing image classification (2009) IEEE Trans. Geosci. Remote Sens., 47 (7), pp. 2218-2232; Vishwanathan, S.V.N., Sun, Z., Theera-Ampornpunt, N., Varma, M., Multiple kernel learning and the SMO algorithm (2010) Proceedings of the 23rd International Conference on Neural Information Processing Systems, pp. 2361-2369; Rakotomamonjy, A., Bach, F., Canu, S., Grandvalet, Y., Simplemkl (2008) J. Mach. Learn. Res., 9, pp. 2491-2521; Duan, L., Xu, D., Tsang, I.W., Luo, J., Visual event recognition in videos by learning from web data (2012) IEEE Trans. Pattern Anal. Mach. Intell., 34 (9), pp. 1667-1680; Borgwardt, K.M., Gretton, A., Rasch, M.J., Kriegel, H., Schölkopf, B., Smola, A.J., Integrating structured biological data by kernel maximum mean discrepancy (2006) Proceedings 14th International Conference on Intelligent Systems for Molecular Biology, pp. 49-57; Tuia, D., Volpi, M., Copa, L., Kanevski, M.F., Muñoz-Marí, J., A survey of active learning algorithms for supervised remote sensing image classification (2011) J. Sel. Top. Signal Process., 5 (3), pp. 606-617; Viera, A., Garrett, J., Understanding interobserver agreement: the Kappa statistic (2005) Fam. Med., 37 (5), pp. 360-363},
correspondence_address1={Liu, X.; State Key Lab of Software Development Environment, China; email: xlliu@nlsde.buaa.edu.com},
publisher={Elsevier Ltd},
issn={00313203},
coden={PTNRA},
language={English},
abbrev_source_title={Pattern Recogn.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Lunga2018962,
author={Lunga, D. and Yang, H.L. and Reith, A. and Weaver, J. and Yuan, J. and Bhaduri, B.},
title={Domain-Adapted Convolutional Networks for Satellite Image Classification: A Large-Scale Interactive Learning Workflow},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
year={2018},
volume={11},
number={3},
pages={962-977},
doi={10.1109/JSTARS.2018.2795753},
note={cited By 18},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041519479&doi=10.1109%2fJSTARS.2018.2795753&partnerID=40&md5=7efe62ac7b125230f52a6b41de788be7},
affiliation={Computing and Computational Sciences, Oak Ridge National Laboratory, Oak Ridge, TN  37830, United States},
abstract={Satellite imagery often exhibits large spatial extent areas that encompass object classes with considerable variability. This often limits large-scale model generalization with machine learning algorithms. Notably, acquisition conditions, including dates, sensor position, lighting condition, and sensor types, often translate into class distribution shifts introducing complex nonlinear factors and hamper the potential impact of machine learning classifiers. This paper investigates the challenge of exploiting satellite images using convolutional neural networks (CNN) for settlement classification where the class distribution shifts are significant. We present a large-scale human settlement mapping workflow based-off multiple modules to adapt a pretrained CNN to address the negative impact of distribution shift on classification performance. To extend a locally trained classifier onto large spatial extents areas we introduce several submodules: First, a human-in-the-loop element for relabeling of misclassified target domain samples to generate representative examples for model adaptation; second, an efficient hashing module to minimize redundancy and noisy samples from the mass-selected examples; and third, a novel relevance ranking module to minimize the dominance of source example on the target domain. The workflow presents a novel and practical approach to achieve large-scale domain adaptation with binary classifiers that are based-off CNN features. Experimental evaluations are conducted on areas of interest that encompass various image characteristics, including multisensors, multitemporal, and multiangular conditions. Domain adaptation is assessed on source-target pairs through the transfer loss and transfer ratio metrics to illustrate the utility of the workflow. © 2008-2012 IEEE.},
author_keywords={Adaptation model;  image classification;  remote sensing;  semi-supervised learning;  supervised learning},
keywords={Artificial intelligence;  Convolution;  Learning algorithms;  Learning systems;  Neural networks;  Remote sensing;  Satellite imagery;  Satellites;  Supervised learning, Adaptation models;  Class distribution shifts;  Classification performance;  Convolutional networks;  Convolutional neural network;  Experimental evaluation;  Satellite image classification;  Semi- supervised learning, Image classification, algorithm;  image classification;  modeling;  remote sensing;  satellite imagery;  sensor;  supervised learning},
funding_details={U.S. Department of EnergyU.S. Department of Energy, USDOE},
funding_details={UT-BattelleUT-Battelle, DE-AC05-00OR22725},
funding_text 1={Manuscript received August 16, 2017; revised November 2, 2017 and December 18, 2017; accepted January 11, 2018. Date of publication February 6, 2018; date of current version March 9, 2018. This work was supported in part by UT-Battelle, LLC under Contract No. DE-AC05-00OR22725 with the U.S. Department of Energy. The United States Government retains and the publisher, by accepting the article for publication, acknowledges that the United States Government retains a nonexclusive, paid-up, irrevocable, world-wide license to publish or reproduce the published form of this manuscript, or allow others to do so, for United States Government purposes. (Corresponding author: Dalton Lunga.) The authors are with the Computing and Computational Sciences Directorate, Oak Ridge National Laboratory, Oak Ridge, TN 37830 USA (e-mail: lungadd@ornl.gov; yangh@ornl.gov; reithae@ornl.gov; weaverje@ornl.gov; yuanj@ornl.gov; bhaduribl@ornl.gov).},
references={Rujoiu-Mare, M.-R., Mihai, B.-A., Mapping land cover using remote sensing data andGIS techniques:Acase study of Prahova Subcarpathians (2016) Procedia Environ. Sci., 32, pp. 244-255; Patlolla, D.R., Bright, E.A., Weaver, J.E., Cheriyadat, A.M., Accelerating satellite image based large-scale settlement detection with GPU (2012) Proc. 1st ACM SIGSPATIAL Int. Workshop Anal. Big Geospatial Data, pp. 43-51. , New York, NY, USA; Vatsavai, R.R., Bhaduri, B., Graesser, J., Complex settlement pattern extraction with multi-instance learning (2013) Proc. Joint Urban Remote Sensing Event, 2013, pp. 246-249. , Apr; Crawford, M.M., Tuia, D., Yang, H.L., Active learning: Any value for classification of remotely sensed data? (2013) Proc. IEEE, 101 (3), pp. 593-608. , Mar; Tuia, D., Persello, C., Bruzzone, L., Recent advances in domain adaptation for the classification of remote sensing data (2017) IEEE Geosci. Remote Sensing Mag.; Graesser, J., Cheriyadat, A., Vatsavai, R.R., Chandola, V., Long, J., Bright, E., Image based characterization of formal and informal neighborhoods in an urban landscape (2012) IEEE J. Sel. Topics Appl. Earth Obs. Remote Sens., 5 (4), pp. 1164-1176. , Aug; Daumé, H., III, Marcu, D., Domain adaptation for statistical classifiers (2006) J. Artif. Int. Res., 26 (1), pp. 101-126. , May; Glorot, X., Bordes, A., Bengio, Y., Domain adaptation for large-scale sentiment classification: A deep learning approach (2011) Proc. 28th Int. Conf. Mach. Learn., pp. 513-520; Bruzzone, L., Persello, C., A novel approach to the selection of spatially invariant features for the classification of hyperspectral images with improved generalization capability (2009) IEEE Trans. Geosci. Remote Sens., 47 (9), pp. 3180-3191. , Sep; Tuia, D., Munoz-Mari, J., Gomez-Chova, L., Malo, J., Graph matching for adaptation in remote sensing (2013) IEEE Trans. Geosci. Remote Sens., 51 (1), pp. 329-341. , Jan; Demir, B., Minello, L., Bruzzone, L., Definition of effective training sets for supervised classification of remote sensing images by a novel cost-sensitive active learning method (2014) IEEE Trans. Geosci. Remote Sens., 52 (2), pp. 1272-1284. , Feb; Persello, C., Boularias, A., Dalponte, M., Gobakken, T., Nsset, E., Schlkopf, B., Cost-sensitive active learning with lookahead: Optimizing field surveys for remote sensing data classification (2014) IEEE Trans. Geosci. Remote Sens., 52 (10), pp. 6652-6664. , Oct; Krizhevsky, A., Sutskever, I., Hinton, G., ImageNet classification with deep convolutional neural networks (2012) Proc. Conf. Neural Inf. Process. Syst., pp. 1097-1105; Hu, W., Huang, Y., Wei, L., Zhang, F., Li, H., Deep convolutional neural networks for hyperspectral image classification (2015) J. Sensors, 2015; Maggiori, E., Tarabalka, Y., Charpiat, G., Alliez, P., Convolutional neural networks for large-scale remote sensing image classification (2017) IEEE Trans. Geosci. Remote Sens., 55 (5), pp. 645-657. , Feb; Sande De Van, A.K.E., Gevers, T., Snoek, C.G.M., Empowering visual categorization with the GPU (2011) IEEE Trans. Multimedia, 13 (1), pp. 60-70. , Feb; Oquab, M., Bottou, L., Laptev, I., Sivic, J., Learning and transferring mid-level image representations using convolutional neural networks (2014) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 1717-1724; Paisitkriangkrai, S., Sherrah, J., Janney, P., Van den Hengel, A., Semantic labeling of aerial and satellite imagery (2016) IEEE J. Sel. Topics Appl. Earth Obs. Remote Sens., 9 (7), pp. 2868-2881. , Jul; Basaeed, E., Bhaskar, H., Hill, P., Al-Mualla, M., Bull, D., A supervised hierarchical segmentation of remote-sensing images using a committee of multi-scale convolutional neural networks (2016) Int. J. Remote Sens., 37 (7), pp. 1671-1691; Sherrah, J., Fully convolutional networks for dense semantic labelling of high-resolution aerial imagery (2016) ArXiv:1606.02585; Alajlan, N., Pasolli, E., Melgani, F., Franzoso, A., Large-scale image classification using active learning (2014) IEEE Geosci. Remote Sens. Lett., 11 (1), pp. 259-263. , Jan; Blanchart, P., Ferecatu, M., Cui, S., Datcu, M., Pattern retrieval in large image databases usingmultiscale coarse-to-fine cascaded active learning (2014) IEEE J. Sel. Topics Appl. Earth Obs. Remote Sens., 7 (4), pp. 1127-1141. , Apr; Yang, H.L., Crawford, M.M., Domain adaptation with preservation of manifold geometry for hyperspectral image classification (2016) IEEE J. Sel. Topics Appl. Earth Obs. Remote Sens., 9 (2), pp. 543-555. , Feb; Gmez-Chova, L., Tuia, D., Moser, G., Camps-Valls, G., Multimodal classification of remote sensing images: A review and future directions (2015) Proc. IEEE, 103 (9), pp. 1560-1584. , Sep; Matasci, G., Longbotham, N., Pacifici, F., Kanevski, M., Tuia, D., Understanding angular effects in VHR imagery and their significance for urban land-cover model portability: A study of two multi-angle in-track image sequences (2015) ISPRS J. Photogram. Remote Sens., 107, pp. 99-111; Volpi, M., Camps-Valls, G., Tuia, D., Spectral alignment of multitemporal cross-sensor images with automated kernel canonical correlation analysis (2015) ISPRS J. Photogram. Remote Sens., 107, pp. 50-63; Matasci, G., Tuia, D., Kanevski, M., SVM-based boosting of active learning strategies for efficient domain adaptation (2012) IEEE J. Sel. Topics Appl. Earth Obs. Remote Sens., 5 (5), pp. 1335-1343. , Oct; Bahirat, K., Bovolo, F., Bruzzone, L., Chaudhuri, S., A novel domain adaptation Bayesian classifier for updating land-cover maps with class differences in source and target domains (2012) IEEE Trans. Geosci. Remote Sens., 50 (7), pp. 2810-2826. , Jul; Tuia, D., Volpi, M., Trolliet, M., Camps-Valls, G., Semisupervised manifold alignment of multimodal remote sensing images (2014) IEEE Trans. Geosci. Remote Sens., 52 (12), pp. 7708-7720. , Dec; Sun, H., Liu, S., Zhou, S., Zou, H., Transfer sparse subspace analysis for unsupervised cross-view scene model adaptation (2016) IEEE J. Sel. Topics Appl. Earth Obs. Remote Sens., 9 (7), pp. 2901-2909. , Jul; Persello, C., Bruzzone, L., Kernel-based domain-invariant feature selection in hyperspectral images for transfer learning (2016) IEEE Trans. Geosci. Remote Sens., 54 (5), pp. 2615-2626. , May; Bruzzone, L., Prieto, D.F., Unsupervised retraining of a maximum likelihood classifier for the analysis of multitemporal remote sensing images (2001) IEEE Trans. Geosci. Remote Sens., 39 (2), pp. 456-460. , Feb; Kim, W., Crawford, M.M., Adaptive classification for hyperspectral image data using manifold regularization kernel machines (2010) IEEE Trans. Geosci. Remote Sens., 48 (11), pp. 4110-4121. , Nov; Li, M., Sethi, I.K., Confidence-based active learning (2006) IEEE Trans. Pattern Anal. Mach. Intell., 28 (8), pp. 1251-1261. , Aug; Gal, Y., Islam, R., Ghahramani, Z., Deep Bayesian active learning with image data (2016) Proc. NIPS Bayesian Deep Learn. Workshop; Lunga, D., Prasad, S., Crawford, M.M., Ersoy, O., Manifold-learningbased feature extraction for classification of hyperspectral data (2014) IEEE Signal Process. Mag., 31 (1), pp. 55-66. , Jan; Demir, B., Bruzzone, L., Hashing-based scalable remote sensing image search and retrieval in large archives (2016) IEEE Trans. Geosci. Remote Sens., 54 (2), pp. 892-904. , Feb; Zhong, Z., Fan, B., Ding, K., Li, H., Xiang, S., Pan, C., Efficientmultiple feature fusion with hashing for hyperspectral imagery classification: A comparative study (2016) IEEE Trans. Geosci. Remote Sens., 54 (8), pp. 4461-4478. , Aug; Kulis, B., Grauman, K., Kernelized locality-sensitive hashing for scalable image search (2009) Proc. IEEE Int. Conf. Comput. Vis.; Shawe-Taylor, J., Cristianini, N., (2004) Kernel Methods for Pattern Analysis, , New York, NY, USA: Cambridge Univ. Press; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning, , Cambridge, MA, USA: MIT Press; Choe, H., Lee, S., Park, S., Joon Kim, S., Chung, E.-Y., Yoon, S., (2016) Neardata Processing for Machine Learning, , arXiv:1610. 02273; Hinton, G.E., Osindero, S., Teh, Y.-W., A fast learning algorithm for deep belief nets (2006) Neural Comput., 18 (7), pp. 1527-1554; Salakhutdinov, R., Mnih, A., Hinton, G., Restricted Boltzmann machines for collaborative filtering (2007) Proc. 24th Int. Conf. Mach. Learn., pp. 791-798; Glorot, X., Bengio, Y., Understanding the difficulty of training deep feedforward neural networks (2010) Proc. Int. Conf. Artif. Intell. Statist., 9, pp. 249-256; Hinton, G.E., A practical guide to training restricted Boltzmann machines (2012) Neural Networks: Tricks of the Trade, 7700, pp. 599-619. , 2nd ed. Berlin, Germany: Springer; Nesterov, Y., A method for unconstrained convex minimization problem with the rate of convergence o(1/k2) (1983) Doklady ANSSSR, 269, pp. 543-547; Kingma, D.P., Ba, J., (2014) ADAM: A Method for Stochastic Optimization, , arXiv:1412. 6980; Zeiler, M.D., (2012) ADADELTA: An Adaptive Learning Rate Method, , CoRR abs/1212. 5701; Duchi, J., Hazan, E., Singer, Y., Adaptive subgradient methods for online learning and stochastic optimization (2011) J. Mach. Learn. Res., 12, pp. 2121-2159. , Jul; Sebastian, R., (2016) An Overview of Gradient Descent Optimisation Algorithms, , arXiv:1609. 04747; He, K., Zhang, X., Ren, S., Sun, J., Delving deep into rectifiers: Surpassing human-level performance on imagenet classification (2015) Proc. IEEE Int. Conf. Comput. Vis., pp. 1026-1034; Donahue, J., Long-term recurrent convolutional networks for visual recognition and description (2015) IEEE Trans. Patt. Anal. Mach. Intell., 39, pp. 677-691; Hinton, G., Roweis, S., Stochastic neighbor embedding (2003) Adv. Neural Inf. Process. Syst., 15, pp. 833-840; Yoshua, B., (2012) Practical Recommendations for Gradient-based Training of Deep Architectures, , arXiv:1206. 5533; (2016) NVIDIA CuDNN | NVIDIA Developer, , https://developer.nvidia.com/cudnn, NVIDIA. Accessed on: Jun. 8, 2016; Bergstra, J., Theano: A CPU and GPU math expression compiler (2010) Proc. Python Sci. Comput. Conf., , Jun. [Oral Presentation]},
correspondence_address1={Lunga, D.; Computing and Computational Sciences, United States; email: lungadd@ornl.gov},
publisher={Institute of Electrical and Electronics Engineers},
issn={19391404},
language={English},
abbrev_source_title={IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Paris20181308,
author={Paris, C. and Bruzzone, L.},
title={A Sensor-Driven Hierarchical Method for Domain Adaptation in Classification of Remote Sensing Images},
journal={IEEE Transactions on Geoscience and Remote Sensing},
year={2018},
volume={56},
number={3},
pages={1308-1327},
doi={10.1109/TGRS.2017.2761839},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032727492&doi=10.1109%2fTGRS.2017.2761839&partnerID=40&md5=f4c5a0d79237491ac7da8dd0e98d67cb},
affiliation={Department of Information Engineering and Computer Science, University of Trento, Trento, 38123, Italy},
abstract={This paper presents a sensor-driven hierarchical domain adaptation method that aims at transferring the knowledge from a source domain (RS image where reference data are available) to a different but related target domain (RS image where no labeled reference data are available) for solving a classification problem. Due to the different acquisition conditions, a difference in the source and target distributions of the features representing the same class is generally expected. To solve this problem, the proposed method takes advantage from the availability of multisensor data to hierarchically detect features subspaces where for some classes data manifolds are partially (or completely) aligned. These feature subspaces are associated with invariant physical properties of classes measured by the sensors in the scene, i.e., measures having almost the same behavior in both domains. The detection of these invariant feature subspaces allows us to infer labels of the target samples that result more aligned to the source data for the considered subset of classes. Then, the labeled target samples are analyzed in the full feature space to classify the remaining target samples of the same classes. Finally, for those classes for which none of the sensors can measure invariant features, we perform the adaptation via a standard active learning technique. Experimental results obtained on two real multisensor data sets confirm the effectiveness of the proposed method. © 1980-2012 IEEE.},
author_keywords={Classification;  Data fusion;  Domain adaptation (DA);  Invariant features;  Multisensor data acquisition;  Remote sensing (RS);  Transfer learning},
keywords={Automobile engine manifolds;  Data acquisition;  Data fusion;  Data structures;  Feature extraction;  Image classification;  Personnel training;  Remote sensing;  Space optics;  Standards;  Support vector machines;  Vectors, Adaptation models;  Domain adaptation;  Invariant features;  Multi-sensor data;  Transfer learning, Classification (of information), algorithm;  data acquisition;  data set;  detection method;  experimental study;  image classification;  numerical method;  remote sensing;  satellite data;  satellite imagery;  satellite sensor},
references={Bruzzone, L., Marconcini, M., Domain adaptation problems: A dasvm classification technique and a circular validation strategy (2010) IEEE Trans. Pattern Anal. Mach. Intell., 32 (5), pp. 770-787. , May; Pan, S.J., Yang, Q., A survey on transfer learning (2010) IEEE Trans. Knowl. Data Eng., 22 (10), pp. 1345-1359. , Oct; Schott, J.R., Salvaggio, C., Volchok, W.J., Radiometric scene normalization using pseudoinvariant features (1988) Remote Sens. Environ., 26 (1), pp. 1-14. , Oct; Woodcock, C.E., Macomber, S.A., Pax-Lenney, M., Cohen, W.B., Monitoring large areas for forest change using landsat: Generalization across space, time and landsat sensors (2001) Remote Sens. Environ., 78 (1-2), pp. 194-203. , Oct; Pax-Lenney, M., Woodcock, C.E., Macomber, S.A., Gopal, S., Song, C., Forest mapping with a generalized classifier and landsat tm data (2001) Remote Sens. Environ., 77 (3), pp. 241-250. , Sep; Inamdar, S., Bovolo, F., Bruzzone, L., Chaudhuri, S., Multidimensional probability density function matching for preprocessing of multitemporal remote sensing images (2008) IEEE Trans. Geosci. Remote Sens., 46 (4), pp. 1243-1252. , Apr; Yang, Z., Zhang, W., Wang, W., Xu, Q., Change detection based on iterative invariant area histogram matching (2011) Proc. 19th Int. Conf. Geoinform, pp. 1-6. , Jun; Heo, J., FitzHugh, T.W., A standardized radiometric normalization method for change detection using remotely sensed imagery (2000) Photogram. Eng. Remote Sens., 66 (2), pp. 173-181; Bruzzone, L., Prieto, D.F., Unsupervised retraining of a maximum likelihood classifier for the analysis of multitemporal remote sensing images (2001) IEEE Trans. Geosci. Remote Sens., 39 (2), pp. 456-460. , Feb; Bruzzone, L., Cossu, R., A multiple-cascade-classifier system for a robust and partially unsupervised updating of land-cover maps (2002) IEEE Trans. Geosci. Remote Sens., 40 (9), pp. 1984-1996. , Sep; Demir, B., Bovolo, F., Bruzzone, L., Updating land-cover maps by classification of image time series: A novel change-detection-driven transfer learning approach (2013) IEEE Trans. Geosci. Remote Sens., 51 (1), pp. 300-312. , Jan; Long, M., Wang, J., Ding, G., Sun, J., Yu, P.S., Transfer joint matching for unsupervised domain adaptation (2014) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 1410-1417. , Jun; Zhang, K., Zheng, V., Wang, Q., Kwok, J., Yang, Q., Marsic, I., Covariate shift in hilbert space: A solution via sorrogate kernels (2013) Proc. Int. Conf. Mach. Learn, pp. 388-395; Persello, C., Interactive domain adaptation for the classification of remote sensing images using active learning (2013) IEEE Geosci. Remote Sens. Lett., 10 (4), pp. 736-740. , Jul; Matasci, G., Tuia, D., Kanevski, M., SVM-based boosting of active learning strategies for efficient domain adaptation (2012) IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., 5 (5), pp. 1335-1343. , Oct; Demir, B., Persello, C., Bruzzone, L., Batch-mode active-learning methods for the interactive classification of remote sensing images (2011) IEEE Trans. Geosci. Remote Sens., 49 (3), pp. 1014-1031. , Mar; Chopra, S., Balakrishnan, S., Gopalan, R., Dlid: Deep learning for domain adaptation by interpolating between domains (2013) Proc. ICML Workshop Challenges Represent. Learn, pp. 1-8; Ganin, Y., Domain-Adversarial training of neural networks (2016) J. Mach. Learn. Res., 17 (59), pp. 1-35; Bruzzone, L., Chi, M., Marconcini, M., A novel transductive SVM for semisupervised classification of remote-sensing images (2006) IEEE Trans. Geosci. Remote Sens., 44 (11), pp. 3363-3373. , Nov; Bickel, S., Brückner, M., Scheffer, T., Discriminative learning for differing training and test distributions (2007) Proc. 24th Int. Conf. Mach. Learn, pp. 81-88; Huang, J., Gretton, A., Borgwardt, K.M., Schölkopf, B., Smola, A.J., Correcting sample selection bias by unlabeled data (2006) Proc. Adv. Neural Inf. Process. Syst, pp. 601-608; Jun, G., Ghosh, J., Spatially adaptive classification of land cover with remote sensing data (2011) IEEE Trans. Geosci. Remote Sens., 49 (7), pp. 2662-2673. , Jul; Singla, A., Patra, S., Bruzzone, L., A novel classification technique based on progressive transductive SVM learning (2014) Pattern Recognit. Lett., 42, pp. 101-106. , Jun; Hoffman, J., Rodner, E., Donahue, J., Darrell, T., Saenko, K., (2013) Efficient Learning of Domain-Invariant Image Representations, , https://arxiv.org/abs/1301.3224, [Online]; Jhuo, I.-H., Liu, D., Lee, D., Chang, S.-F., Robust visual domain adaptation with low-rank reconstruction (2012) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR, pp. 2168-2175. , Jun; Kulis, B., Saenko, K., Darrell, T., What you saw is not what you get: Domain adaptation using asymmetric kernel transforms (2011) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR, pp. 1785-1792. , Jun; Saenko, K., Kulis, B., Fritz, M., Darrell, T., Adapting visual category models to new domains (2010) Proc. Eur. Conf. Comput. Vis. (ECCV, pp. 213-226; Camps-Valls, G., Marsheva, T.V.B., Zhou, D., Semi-supervised graph-based hyperspectral image classification (2007) IEEE Trans. Geosci. Remote Sens., 45 (10), pp. 3044-3054. , Oct; Belkin, M., Niyogi, P., Sindhwani, V., Manifold regularization: A geometric framework for learning from labeled and unlabeled examples (2006) J. Mach. Learn. Res., 7, pp. 2399-2434. , Nov; Gómez-Chova, L., Camps-Valls, G., Munoz-Mari, J., Calpe, J., Semisupervised image classification with laplacian support vector machines (2008) IEEE Geosci. Remote Sens. Lett., 5 (3), pp. 336-340. , Jul; Caetano, T.S., Caelli, T., Schuurmans, D., Barone, D.A.C., Graphical models and point pattern matching (2006) IEEE Trans. Pattern Anal. Mach. Intell., 28 (10), pp. 1646-1663. , Oct; Caetano, T.S., McAuley, J.J., Cheng, L., Le, Q.V., Smola, A.J., Learning graph matching (2009) IEEE Trans. Pattern Anal. Mach. Intell., 31 (6), pp. 1048-1058. , Jun; Luo, B., Hancock, E.R., Structural graph matching using the em algorithm and singular value decomposition (2001) IEEE Trans. Pattern Anal. Mach. Intell., 23 (10), pp. 1120-1136. , Oct; Banerjee, B., Bovolo, F., Bhattacharya, A., Bruzzone, L., Chaudhuri, S., Buddhiraju, K.M., A novel graph-matching-based approach for domain adaptation in classification of remote sensing image pair (2015) IEEE Trans. Geosci. Remote Sens., 53 (7), pp. 4045-4062. , Jul; Patel, V.M., Gopalan, R., Li, R., Visual domain adaptation: A survey of recent advances (2015) IEEE Signal Process. Mag., 32 (3), pp. 53-69; Tuia, D., Camps-Valls, G., Kernel manifold alignment for domain adaptation (2016) PLoS ONE, 11 (2), p. e0148655; Fernando, B., Habrard, A., Sebban, M., Tuytelaars, T., Unsupervised visual domain adaptation using subspace alignment (2013) Proc. IEEE Int. Conf. Comput. Vis, pp. 2960-2967. , Dec; Baktashmotlagh, M., Harandi, M.T., Lovell, B.C., Salzmann, M., Unsupervised domain adaptation by domain invariant projection (2013) Proc. IEEE Int. Conf. Comput. Vis, pp. 769-776. , Dec; Si, S., Tao, D., Geng, B., Bregman divergence-based regularization for transfer subspace learning (2010) IEEE Trans. Knowl. Data Eng., 22 (7), pp. 929-942. , Jul; Li, W., Duan, L., Xu, D., Tsang, I.W., Learning with augmented features for supervised and semi-supervised heterogeneous domain adaptation (2013) IEEE Trans. Pattern Anal. Mach. Intell., 36 (6), pp. 1134-1148. , Jun; Gong, B., Shi, Y., Sha, F., Grauman, K., Geodesic flow kernel for unsupervised domain adaptation (2012) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR, pp. 2066-2073. , Jun; Gopalan, R., Li, R., Chellappa, R., Domain adaptation for object recognition: An unsupervised approach (2011) Proc. IEEE Int. Conf. Comput. Vis. (ICCV, pp. 999-1006. , Nov; Gopalan, R., Li, R., Chellappa, R., Unsupervised adaptation across domain shifts by generating intermediate data representations (2014) IEEE Trans. Pattern Anal. Mach. Intell., 36 (11), pp. 2288-2302. , Nov; Daumé, H., III, (2009) Frustratingly Easy Domain Adaptation, , https://arxiv.org/abs/0907.1815, [Online]; Courty, N., Flamary, R., Tuia, D., Rakotomamonjy, A., Optimal transport for domain adaptation (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39 (9), pp. 1853-1865; Bruzzone, L., Persello, C., A novel approach to the selection of spatially invariant features for the classification of hyperspectral images with improved generalization capability (2009) IEEE Trans. Geosci. Remote Sens., 47 (9), pp. 3180-3191. , Sep; Tuia, D., Munoz-Mari, J., Gomez-Chova, L., Malo, J., Graph matching for adaptation in remote sensing (2013) IEEE Trans. Geosci. Remote Sens., 51 (1), pp. 329-341. , Jan; Wang, C., Mahadevan, S., Heterogeneous domain adaptation using manifold alignment (2011) Proc. 22nd Int. Joint Conf. Artif. Intell. (IJCAI, 22, p. 1541; Matasci, G., Volpi, M., Kanevski, M., Bruzzone, L., Tuia, D., Semisupervised transfer component analysis for domain adaptation in remote sensing image classification (2015) IEEE Trans. Geosci. Remote Sens., 53 (7), pp. 3550-3564. , Jul; Ham, J., Lee, D.D., Saul, L.K., Semisupervised alignment of manifolds (2005) Proc. Annu. Conf. Uncertainty Artif. Intell., 10, pp. 120-127; Tuia, D., Volpi, M., Trolliet, M., Camps-Valls, G., Semisupervised manifold alignment of multimodal remote sensing images (2014) IEEE Trans. Geosci. Remote Sens., 52 (12), pp. 7708-7720. , Dec; Ben-David, S., Luu, T., Lu, T., Pál, D., Impossibility theorems for domain adaptation (2010) Proc. AISTATS, pp. 129-136; Ben-David, S., Urner, R., On the hardness of domain adaptation and the utility of unlabeled target samples (2012) Proc. Int. Conf. Algorithmic Learn. Theory, pp. 139-153; Tuia, D., Persello, C., Bruzzone, L., Domain adaptation for the classification of remote sensing data: An overview of recent advances (2016) IEEE Geosci. Remote Sens. Mag., 4 (2), pp. 41-57. , Jun; Arenas-Garciá, J., Petersen, K.B., Camps-Valls, G., Hansen, L.K., Kernel multivariate analysis framework for supervised subspace learning: A tutorial on linear and kernel multivariate methods (2013) IEEE Signal Process. Mag., 30 (4), pp. 16-29. , Jul; Brand, M., Charting a manifold (2002) Proc. Adv. Neural Inf. Process. Syst, pp. 961-968; Teh, Y.W., Roweis, S., Automatic alignment of local representations (2002) Proc. Adv. Neural Inf. Process. Syst, pp. 841-848; Yang, H.L., Crawford, M.M., Spectral and spatial proximity-based manifold alignment for multitemporal hyperspectral image classification (2016) IEEE Trans. Geosci. Remote Sens., 54 (1), pp. 51-64. , Jan; Zhu, L., Ma, L., Class centroid alignment based domain adaptation for classification of remote sensing images (2016) Pattern Recognit. Lett., 83, pp. 124-132. , Nov; Kim, W., Crawford, M.M., Adaptive classification for hyperspectral image data using manifold regularization kernel machines (2010) IEEE Trans. Geosci. Remote Sens., 48 (11), pp. 4110-4121. , Nov; Demir, B., Bovolo, F., Bruzzone, L., Classification of time series of multispectral images with limited training data (2013) IEEE Trans. Image Process., 22 (8), pp. 3219-3233. , Aug; Tuia, D., Pasolli, E., Emery, W.J., Using active learning to adapt remote sensing image classifiers (2011) Remote Sens. Environ., 115 (9), pp. 2232-2242. , Sep; Huang, X., Lu, Q., Zhang, L., A multi-index learning approach for classification of high-resolution remotely sensed images over urban areas (2014) ISPRS J. Photogram. Remote Sens., 90, pp. 36-48. , Apr; Huang, X., Weng, C., Lu, Q., Feng, T., Zhang, L., Automatic labelling and selection of training samples for high-resolution remote sensing image classification over urban areas (2015) Remote Sens., 7 (12), pp. 16024-16044; Bruzzone, L., Marconcini, M., Wegmuller, U., Wiesmann, A., An advanced system for the automatic classification of multitemporal sar images (2004) IEEE Trans. Geosci. Remote Sens., 42 (6), pp. 1321-1334. , Jun; Gualtieri, J.A., Chettri, S.R., Cromp, R.F., Johnson, L.F., Support vector machine classifiers as applied to aviris data (1999) Proc. 8th JPL Airborne Geosci. Workshop, pp. 1-11; Melgani, F., Bruzzone, L., Classification of hyperspectral remote sensing images with support vector machines (2004) IEEE Trans. Geosci. Remote Sens., 42 (8), pp. 1778-1790. , Aug; Chi, M., Bruzzone, L., A semilabeled-sample-driven bagging technique for ill-posed classification problems (2005) IEEE Geosci. Remote Sens. Lett., 2 (1), pp. 69-73. , Jan; Camps-Valls, G., Bruzzone, L., Kernel-based methods for hyperspectral image classification (2005) IEEE Trans. Geosci. Remote Sens., 43 (6), pp. 1351-1362. , Jun; Patra, S., Bruzzone, L., A fast cluster-Assumption based activelearning technique for classification of remote sensing images (2011) IEEE Trans. Geosci. Remote Sens., 49 (5), pp. 1617-1626. , May; Rajan, S., Ghosh, J., Crawford, M.M., An active learning approach to hyperspectral data classification (2008) IEEE Trans. Geosci. Remote Sens., 46 (4), pp. 1231-1242. , Apr; Persello, C., Bruzzone, L., A novel active learning strategy for domain adaptation in the classification of remote sensing images (2011) Proc. IEEE Int. Geosci. Remote Sens. Symp. (IGARSS, pp. 3720-3723. , Jul; Tuia, D., Ratle, F., Pacifici, F., Kanevski, M.F., Emery, W.J., Active learning methods for remote sensing image classification (2009) IEEE Trans. Geosci. Remote Sens., 47 (7), pp. 2218-2232. , Jul; Mitra, P., Shankar, B.U., Pal, S.K., Segmentation of multispectral remote sensing images using active support vector machines (2004) Pattern Recognit. Lett., 25 (9), pp. 1067-1074. , Jul; Debes, C., Hyperspectral and lidar data fusion: Outcome of the 2013 grss data fusion contest (2014) IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., 7 (6), pp. 2405-2418. , Jun; Pan, S.J., Tsang, I.W., Kwok, J.T., Yang, Q., Domain adaptation via transfer component analysis (2011) IEEE Trans. Neural Netw., 22 (2), pp. 199-210. , Feb},
correspondence_address1={Bruzzone, L.; Department of Information Engineering and Computer Science, Italy; email: lorenzo.bruzzone@ing.unitn.it},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={01962892},
coden={IGRSD},
language={English},
abbrev_source_title={IEEE Trans Geosci Remote Sens},
document_type={Article},
source={Scopus},
}

@ARTICLE{Ahmed2018751,
author={Ahmed, M.U. and Kim, Y.H. and Kim, J.W. and Bashar, M.R. and Rhee, P.K.},
title={Two person interaction recognition based on effective hybrid learning},
journal={KSII Transactions on Internet and Information Systems},
year={2018},
volume={13},
number={2},
pages={751-770},
doi={10.3837/tiis.2019.02.015},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063259332&doi=10.3837%2ftiis.2019.02.015&partnerID=40&md5=59191a69012158b9512b42712c5128db},
affiliation={Department of Computer Engineering, Inha University, Incheon, South Korea; Science, Technology and Management Crest, Sydney, Australia},
abstract={Action recognition is an essential task in computer vision due to the variety of prospective applications, such as security surveillance, machine learning, and human–computer interaction. The availability of more video data than ever before and the lofty performance of deep convolutional neural networks also make it essential for action recognition in video. Unfortunately, limited crafted video features and the scarcity of benchmark datasets make it challenging to address the multi-person action recognition task in video data. In this work, we propose a deep convolutional neural network–based Effective Hybrid Learning (EHL) framework for two-person interaction classification in video data. Our approach exploits a pre-trained network model (the VGG16 from the University of Oxford Visual Geometry Group) and extends the Faster R-CNN (region–based convolutional neural network a state-of-the-art detector for image classification). We broaden a semi-supervised learning method combined with an active learning method to improve overall performance. Numerous types of two-person interactions exist in the real world, which makes this a challenging task. In our experiment, we consider a limited number of actions, such as hugging, fighting, linking arms, talking, and kidnapping in two environment such simple and complex. We show that our trained model with an active semi-supervised learning architecture gradually improves the performance. In a simple environment using an Intelligent Technology Laboratory (ITLab) dataset from Inha University, performance increased to 95.6% accuracy, and in a complex environment, performance reached 81% accuracy. Our method reduces data-labeling time, compared to supervised learning methods, for the ITLab dataset. We also conduct extensive experiment on Human Action Recognition benchmarks such as UT-Interaction dataset, HMDB51 dataset and obtain better performance than state-of-the-art approaches. © 2019 KSII.},
author_keywords={Action recognition;  Convolutional neural network;  Deep architecture;  Transfer learning},
keywords={Benchmarking;  Complex networks;  Convolution;  Deep neural networks;  Learning algorithms;  Machine learning;  Network architecture;  Neural networks;  Supervised learning;  Video recording, Action recognition;  Convolutional neural network;  Deep architectures;  Semi- supervised learning;  Semi-supervised learning methods;  State-of-the-art approach;  Supervised learning methods;  Transfer learning, Human computer interaction},
funding_details={Inha UniversityInha University, Inha, INHA-59176},
funding_text 1={This work was supported by INHA UNIVERSITY Research Grant. (INHA-59176)},
references={Dalal, N., Triggs, B., Histograms of Oriented Gradients for Human Detection (2005) Proc. of 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05); Laptev, I., On space-time interest points (2005) International Journal of Computer Vision, , Article (CrossRef Link); Hasan, M., Roy-Chowdhury, A.K., A Continuous Learning Framework for Activity Recognition Using Deep Hybrid Feature Models (2015) Ieee Tmm, 17 (11), pp. 1909-1922. , Article (CrossRef Link); Yao, B., Fei-Fei, L., Modeling mutual context of object and human pose in human-object interaction activities (2010) Proc. of IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, 1, pp. 17-24; Feichtenhofer, C., Pinz, A., Zisserman, A., Convolutional Two-Stream Network Fusion for Video Action Recognition (2016) Cvpr, pp. 1933-1941. , Article (CrossRef Link); Richard, A., A BoW-equivalent Recurrent Neural Network for Action Recognition Bag-of-Words Model as Neural Network (2015) Bmvc2015, , Article (CrossRef Link); He, K., Zhang, X., Ren, S., Sun, J., Deep Residual Learning for Image Recognition (2016) Proc. of 2016 IEEE Conf. Comput. Vis. Pattern Recognit., pp. 770-778; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39 (6), pp. 1137-1149. , Article (CrossRef Link); Vedaldi, A., Lenc, K., (2016) Matconvnet Convolutional Neural Networks for MATLAB, , Article (CrossRef Link); Simonyan, K., Vedaldi, A., Zisserman, A., Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps (2014) Iclr, p. 1; Gkioxari, G., Berkeley, U.C., Girshick, R., Berkeley, U.C., Contextual Action Recognition with R*CNN (2015) Cvpr; Stikic, M., van Laerhoven, K., Schiele, B., Exploring semi-supervised and active learning for activity recognition (2008) Wearable Comput. 2008. ISWC 2008. 12Th IEEE Int. Symp, pp. 81-88; Settles, B., (2012) Active Learning, 6 (1); Wang, H., Kläser, A., Schmid, C., Liu, C.L., Action recognition by dense trajectories (2011) Proc. of IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, pp. 3169-3176; Peng, X., Zou, C., Qiao, Y., Peng, Q., Action Recognition with Stacked Fisher Vectors (2014) Eccv, pp. 581-595. , Article (CrossRef Link); Felzenszwalb, P.F., Girshick, R.B., McAllester, D., Ramanan, D., Object Detection with Discriminatively Trained Part-Based Models Article; Slimani, K.N.E.H., Benezeth, Y., Souami, F., Human interaction recognition based on the co-occurrence of visual words (2014) Proc. of IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. Work., pp. 461-466; Laptev, I., Schmid, C., (2015) Long-Term Temporal Convolutions for Action Recognition to Cite This Version: Long-Term Temporal Convolutions for Action Recognition, 40 (6), pp. 1510-1517; Lecun, Y., Kavukcuoglu, K., Farabet, C., Convolutional networks and applications in vision (2010) ISCAS 2010-2010 IEEE Int. Symp. Circuits Syst. Nano-Bio Circuit Fabr. Syst, pp. 253-256; Gkioxari, G., Hariharan, B., Girshick, R., Malik, J., R-CNNs for Pose Estimation and Action Detection (2014) Arxiv Prepr, pp. 1-8; Szegedy, C., (2014) Going Deeper with Convolutions, pp. 1-9; Yarowsky, D., Unsupervised word sense disambiguation rivaling supervised methods (1995) Proc. of 33Rd Annu. Meet. Assoc. Comput. Linguist, pp. 189-196; Goldberg, A.B., (2009) Multi-Manifold Semi-Supervised Learning, pp. 169-176. , Article (CrossRef Link); Ahsan, U., Sun, C., Essa, I., DiscrimNet: Semi-Supervised Action Recognition from Videos using Generative Adversarial Networks (2018) Computer Vision and Pattern Recognition, , CrossRef Link; Zhang, J., Han, Y., Tang, J., Hu, Q., Jiang, J., Semi-Supervised Image-to-Video Adaptation for Video Action Recognition (2017) IEEE Trans. Cybern., 47 (4), pp. 960-973. , Article (CrossRef Link); Jones, S., Shao, L., A Multigraph Representation for Improved Unsupervised / Semi-supervised Learning of Human Actions (2014) Cvpr, , Article (CrossRef Link); Zhang, T., Liu, S., Xu, C., Lu, H., Boosted multi-class semi-supervised learning for human action recognition (2011) Pattern Recognit, 44 (10-11), pp. 2334-2342. , Article (CrossRef Link); Li, M., Sethi, I.K., Confidence-Based Active Learning (2006) IEEE Transactions on Pattern Analysis and Machine Intelligence, 28 (8), pp. 1251-1261; Sourati, J., Akcakaya, M., Erdogmus, D., Leen, T.K., Dy, J.G., A Probabilistic Active Learning Algorithm Based on Fisher Information Ratio (2018) IEEE Trans. Pattern Anal. Mach. Intell., 40 (8), pp. 2023-2029. , Article (CrossRef Link); Bernard, J., Hutter, M., Zeppelzauer, M., Fellner, D., Sedlmair, M., Comparing Visual-Interactive Labeling with Active Learning: An Experimental Study (2018) IEEE Trans. Vis. Comput. Graph, 24 (1), pp. 298-308. , Article (CrossRef Link); Hao, S., Lu, J., Zhao, P., Zhang, C., Hoi, S.C.H., Miao, C., Second-Order Online Active Learning and Its Applications (2018) IEEE Trans. Knowl. Data Eng., 30 (7), pp. 1338-1351. , Article (CrossRef Link); Pan, S.J., Yang, Q., A Survey on Transfer Learning (2010) IEEE Transactions on Knowledge and Data Engineering, 22 (10), pp. 1345-1359. , Article (CrossRef Link); Fung, G.P.C., Yu, J.X., Lu, H., Yu, P.S., Text classification without negative examples revisit (2006) IEEE Trans. Knowl. Data Eng., 18 (1), pp. 6-20. , Article (CrossRef Link); Wu, P., Dietterich, T.G., Improving SVM accuracy by training on auxiliary data sources (2004) Proc. of Int. Conf. Mach. Learn, pp. 110-118; Jie, Y., Qiang, Y., Lionel, N., Adaptive Temporal Radio Maps for Indoor Location Estimation (2005) Pervasive Comput. Commun. 2005. Percom 2005. Third IEEE Int. Conf, 7 (7), pp. 85-94. , Article (CrossRef Link); (2002) Woods, Digital Image Processing; Lopes, A.T., de Aguiar, E., de Souza, A.F., Oliveira-Santos, T., Facial expression recognition with Convolutional Neural Networks: Coping with few data and the training sample order (2017) Pattern Recognit, 61, pp. 610-628. , Article (CrossRef Link); Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., Rethinking the Inception Architecture for Computer Vision (2016) Proc. of 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Simonyan, K., Zisserman, A., Very Deep Convolutional Networks for Large-Scale Image Recognition (2014) Computer Vision and Pattern Recognition, pp. 1-14; Russakovsky, O., ImageNet Large Scale Visual Recognition Challenge (2015) Int. J. Comput. Vis, 115 (3), pp. 211-252. , Article (CrossRef Link); Ryooaggarwal, J.K., (2010) Interaction Dataset, ICPR Contest on Semantic Description of Human Activities (SDHA); Kuehne, H., Jhuang, H., Garrote, E., Poggio, T., Serre, T., HMDB: A large video database for human motion recognition (2011) Roc. of IEEE Int. Conf. Comput. Vis., pp. 2556-2563; Tieleman, G.H., (2012) Lecture 6.5-Rmsprop: Divide the Gradient by a Running Average Ofits Recent Magnitude, , COURSERA Neural Networks Form. Learn; Kingma, D.P., Ba, J., Adam: A Method for Stochastic Optimization (2014) Proc. of Conference Paper at the 3Rd International Conference for Learning Representations, pp. 1-15; Jia, Y., Caffe: Convolutional Architecture for Fast Feature Embedding (2014) Proc. of the 22Nd ACM International Conference on Multimedia, pp. 675-678; Chetlur, S., Cudnn: Efficient Primitives for Deep Learning, , Article (CrossRef Link); Ryoo, M.S., Aggarwal, J.K., Spatio-temporal relationship match: Video structure comparison for recognition of complex human activities (2009) Proc.Of IEEE Int. Conf. Comput. Vis, pp. 1593-1600. , no. Iccv; Brendel, W., Todorovic, S., Learning spatiotemporal graphs of human activities (2011) Proc. of IEEE Int. Conf. Comput. Vis., pp. 778-785; Prakash Sahoo, S., Ari, S., On an algorithm for Human Action Recognition (2018) Expert Syst. Appl., , Article (CrossRef Link)},
correspondence_address1={Rhee, P.K.; Department of Computer Engineering, South Korea; email: pkrhee@inha.ac.kr},
publisher={Korean Society for Internet Information},
issn={19767277},
language={English},
abbrev_source_title={KSII Trans. Internet Inf. Syst.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Sourati201883,
author={Sourati, J. and Gholipour, A. and Dy, J.G. and Kurugol, S. and Warfield, S.K.},
title={Active deep learning with fisher information for patch-wise semantic segmentation},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={11045 LNCS},
pages={83-91},
doi={10.1007/978-3-030-00889-5_10},
note={cited By 8; Conference of 4th International Workshop on Deep Learning in Medical Image Analysis, DLMIA 2018 and 8th International Workshop on Multimodal Learning for Clinical Decision Support, ML-CDS 2018 Held in Conjunction with MICCAI 2018 ; Conference Date: 20 September 2018 Through 20 September 2018;  Conference Code:218789},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057268887&doi=10.1007%2f978-3-030-00889-5_10&partnerID=40&md5=e1622bafd82c8d35750e4689654950d8},
affiliation={Radiology Department, Boston Children’s Hospital, 300 Longwood Avenue, Boston, MA  02115, United States; Department of Electrical and Computer Engineering, Northeastern University, 360 Huntington Avenue, Boston, MA  02115, United States},
abstract={Deep learning with convolutional neural networks (CNN) has achieved unprecedented success in segmentation, however it requires large training data, which is expensive to obtain. Active Learning (AL) frameworks can facilitate major improvements in CNN performance with intelligent selection of minimal data to be labeled. This paper proposes a novel diversified AL based on Fisher information (FI) for the first time for CNNs, where gradient computations from backpropagation are used for efficient computation of FI on the large CNN parameter space. We evaluated the proposed method in the context of newborn and adolescent brain extraction problem under two scenarios: (1) semi-automatic segmentation of a particular subject from a different age group or with a pathology not available in the original training data, where starting from an inaccurate pre-trained model, we iteratively label small number of voxels queried by AL until the model generates accurate segmentation for that subject, and (2) using AL to build a universal model generalizable to all images in a given data set. In both scenarios, FI-based AL improved performance after labeling a small percentage (less than 0.05%) of voxels. The results showed that FI-based AL significantly outperformed random sampling, and achieved accuracy higher than entropy-based querying in transfer learning, where the model learns to extract brains of newborn subjects given an initial model trained on adolescents. © Springer Nature Switzerland AG 2018.},
keywords={Decision support systems;  Fisher information matrix;  Image analysis;  Image segmentation;  Iterative methods;  Medical imaging;  Neural networks;  Semantics, Convolutional Neural Networks (CNN);  Efficient computation;  Fisher information;  Gradient computation;  Parameter spaces;  Semantic segmentation;  Semi-automatic segmentation;  Transfer learning, Deep learning},
funding_details={R01 EB018988},
funding_details={National Institutes of HealthNational Institutes of Health, NIH, R01 DK100404, R01 EB019483, R01 NS079788, R44 MH086984, U54 HD090255},
funding_details={Crohn's and Colitis Foundation of AmericaCrohn's and Colitis Foundation of America, CCFA},
funding_text 1={S. K. Warfield—This work was supported by NIH grants R01 NS079788, R01 EB019483, R01 DK100404, R44 MH086984, BCH IDDRC U54 HD090255, and by a research grant from the Boston Children’s Hospital Translational Research Program. A.G. is supported by NIH grant R01 EB018988. S.K. is also supported by CCFA’s Career Development Award and AGA-Boston Scientific Technology and Innovation Award.},
references={Litjens, G., A survey on deep learning in medical image analysis (2017) Med. Image Anal., 42, pp. 60-88; Top, A., Hamarneh, G., Abugharbieh, R., Active learning for interactive 3D image segmentation (2011) MICCAI 2011. LNCS, 6893, pp. 603-610. , https://doi.org/10.1007/978-3-642-23626-6_74, Fichtinger, G., Martel, A., Peters, T. (eds.); Pace, D.F., Dalca, A.V., Geva, T., Powell, A.J., Moghari, M.H., Golland, P., Interactive whole-heart segmentation in congenital heart disease (2015) MICCAI 2015. LNCS, 9351, pp. 80-88. , https://doi.org/10.1007/978-3-319-24574-4_10, Navab, N., Hornegger, J., Wells, W.M., Frangi, A.F. (eds.), pp., Springer, Cham; Zhou, S., Chen, Q., Wang, X., Active deep networks for semi-supervised sentiment classification (2010) Proceedings of the 23Rd International Conference on Computational Linguistics: Posters, pp. 1515-1523. , Association for Computational Linguistics, pp; Yang, L., Zhang, Y., Chen, J., Zhang, S., Chen, D.Z., Suggestive annotation: A deep active learning framework for biomedical image segmentation (2017) MICCAI 2017. LNCS, 10435, pp. 399-407. , https://doi.org/10.1007/978-3-319-66179-7_46, Descoteaux, M., Maier-Hein, L., Franz, A., Jannin, P., Collins, D.L., Duchesne, S. (eds.); Wang, K., Zhang, D., Li, Y., Zhang, R., Lin, L., Cost-effective active learning for deep image classification (2016) IEEE Trans. Circuits Syst. Video Technol., 27, p. 2591; Zhang, T., Oles, F., The value of unlabeled data for classification problems (2000) Proceedings of the 17Th International Conference on Machine Learning, pp. 1191-1198. , pp; Chaudhuri, K., Kakade, S.M., Netrapalli, P., Sanghavi, S., Convergence rates of active learning for maximum likelihood estimation (2015) Advances in Neural Information Processing Systems, pp. 1090-1098. , pp; Sourati, J., Akcakaya, M., Leen, T.K., Erdogmus, D., Dy, J.G., Asymptotic analysis of objectives based on fisher information in active learning (2017) J. Mach. Learn. Res., 18 (34), pp. 1-41; Hoi, S.C., Jin, R., Zhu, J., Lyu, M.R., Batch mode active learning and its application to medical image classification (2006) Proceedings of the 23Rd International Conference on Machine Learning, pp. 417-424. , pp., ACM; Sourati, J., Akcakaya, M., Erdogmus, D., Leen, T., Dy, J.G., A probabilistic active learning algorithm based on fisher information ratio (2017) IEEE Trans. Pattern Anal. Mach. Intell., 40, pp. 2023-2029; Vandenberghe, L., Boyd, S., Semidefinite programming (1996) SIAM Rev, 38 (1), pp. 49-95; Wei, K., Iyer, R., Bilmes, J., Submodularity in data subset selection and active learning (2015) Proceedings of the 21St International Conference on Machine Learning, 37. , vol; Makropoulos, A., The developing human connectome project: A minimal processing pipeline for neonatal cortical surface reconstruction (2018) Neuroimage, 173, pp. 88-112},
correspondence_address1={Sourati, J.; Radiology Department, 300 Longwood Avenue, United States; email: jamshid.sourati@childrens.harvard.edu},
editor={Maier-Hein L., Syeda-Mahmood T., Taylor Z., Lu Z., Stoyanov D., Madabhushi A., Tavares J.M.R.S., Nascimento J.C., Moradi M., Martel A., Papa J.P., Conjeti S., Belagiannis V., Greenspan H., Carneiro G., Bradley A.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783030008888},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Yang2018187,
author={Yang, J. and Li, S. and Xu, W.},
title={Active Learning for Visual Image Classification Method Based on Transfer Learning},
journal={IEEE Access},
year={2018},
volume={6},
pages={187-198},
doi={10.1109/ACCESS.2017.2761898},
art_number={8100722},
note={cited By 14},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034271377&doi=10.1109%2fACCESS.2017.2761898&partnerID=40&md5=7ebd53f4f7558552abd549c15568487f},
affiliation={School of Computer Science, Wuhan University, Wuhan, 430072, China; Information and Telecommunication Branch, State Grid Jiangxi Electric Power Company, Nanchang, 330077, China; Institute of Mineral Resources, Chinese Academy of Geological Sciences, Beijing, 100037, China},
abstract={The active learning method involves searching for the most informative unmarked samples by query function, submitting them to the expert function for marking, then using the samples to train the classification model in order to improve the accuracy of the model and use the newly acquired knowledge to inquire into the next round, with the aim of getting the highest accuracy of classification using minimal training samples. This paper details the various principles of active learning and develops a method that combines active learning with transfer learning. Experimental results prove that the active learning method can cut back on samples redundancy and promote the accuracy of classifier convergence quickly in small samples. Combining active learning and transfer learning, while taking advantage of knowledge in related areas, could further improve the generalization ability of classification models. © 2017 IEEE.},
author_keywords={Active learning;  field adaptation;  image classification;  transfer learning},
keywords={Artificial intelligence;  Data mining;  Data structures;  Learning systems;  Personnel training;  Redundancy;  Support vector machines, Accuracy of classifications;  Active Learning;  Active learning methods;  Classification methods;  field adaptation;  Generalization ability;  Transfer learning;  Uncertainty, Image classification},
references={Sun, S., Hardoon, D.R., Active learning with extremely sparse labeled examples (2010) Neurocomputing, 73 (16-18), pp. 2980-2988. , nos; Settles, B., Active learning literature survey (2009) Univ. Wisconsin Madison, 39 (2), pp. 127-131; Copa, L., Tuia, D., Volpi, M., Kanevski, M., Unbiased query-bybagging active learning for VHR image classification (2010) Proc. SPIE, Image Signal Process. Remote Sens. XVI, 7830. , Oct; Du, B., Wang, Z., Zhang, L., Zhang, L., Tao, D., Robust and discriminative labeling for multi-label active learning based on maximum correntropy criterion (2017) IEEE Trans. Image Process, 26 (4), pp. 1694-1707. , Apr; Luo, T., Active learning to recognize multiple types of plankton (2004) Proc. 17th Int. Conf. Pattern Recognit. (ICPR), 3, pp. 478-481; Demir, B., Persello, C., Bruzzone, L., Batch-mode active-learning methods for the interactive classification of remote sensing images (2011) IEEE Trans. Geosci. Remote Sens., 49 (3), pp. 1014-1031. , Mar; Pasolli, E., Melgani, F., Bazi, Y., Support vector machine active learning through significance space construction (2011) IEEE Geosci. Remote Sens. Lett., 8 (3), pp. 431-435. , May; Du, B., Zhang, Y., Zhang, L., Tao, D., Beyond the sparsity-based target detector: A hybrid sparsity and statistics-based detector for hyperspectral images (2016) IEEE Trans. Image Process, 25 (11), pp. 5345-5357. , Nov; Stumpf, A., Lachiche, N., Malet, J.-P., Kerle, N., Puissant, A., Active learning in the spatial domain for remote sensing image classification (2014) IEEE Trans. Geosci. Remote Sens., 52 (5), pp. 2492-2507. , May; Persello, C., Bruzzone, L., Active and semisupervised learning for the classification of remote sensing images (2014) IEEE Trans. Geosci. Remote Sens., 52 (11), pp. 6937-6956. , Nov; Cohn, D., Atlas, L., Ladner, R., Improving generalization with active learning (1994) Mach. Learn., 15 (2), pp. 201-221; Du, B., Zhang, M., Zhang, L., Hu, R., Tao, D., PLTD: Patch-based low-rank tensor decomposition for hyperspectral images (2017) IEEE Trans. Multimedia, 19 (1), pp. 67-79. , Jan; Ruiz, P., Mateos, J., Camps-Valls, G., Molina, R., Katsaggelos, A.K., Bayesian active remote sensing image classification (2014) IEEE Trans. Geosci. Remote Sens., 52 (4), pp. 2186-2196. , Apr; Yang, Y., Ma, Z., Nie, F., Chang, X., Hauptmann, A.G., Multi-class active learning by uncertainty sampling with diversity maximization (2014) Int. J. Comput. Vis., 113 (2), pp. 113-127; Demir, B., Minello, L., Bruzzone, L., Definition of effective training sets for supervised classification of remote sensing images by a novel cost-sensitive active learning method (2014) IEEE Trans. Geosci. Remote Sens., 52 (2), pp. 1272-1284. , Feb; Du, B., Xiong, X., Zhang, L., Zhang, L., Tao, D., Stacked convolutional denoising auto-encoders for feature representation (2017) IEEE Trans. Cybern., 47 (4), pp. 1017-1027. , Apr; Persello, C., Bruzzone, L., Active learning for domain adaptation in the supervised classification of remote sensing images (2012) IEEE Trans. Geosci. Remote Sens., 50 (11), pp. 4468-4483. , Nov; Persello, C., Interactive domain adaptation for the classification of remote sensing images using active learning (2013) IEEE Geosci. Remote Sens. Lett., 10 (4), pp. 736-740. , Jul; Schohn, G., Cohn, D., Less is more: Active learning with support vector machines (2000) Proc. 7th Int. Conf. Mach. Learn., pp. 839-846; Du, B., Exploring representativeness and informativeness for active learning (2017) IEEE Trans. Cybern., 41 (1), pp. 14-26. , Jan; Tuia, D., Ratle, F., Pacifici, F., Kanevski, M.F., Emery, W.J., Active learning methods for remote sensing image classification (2009) IEEE Trans. Geosci. Remote Sens., 47 (7), pp. 2218-2232. , Jul; Borgwardt, K.M., Integrating structured biological data by kernel maximum mean discrepancy (2006) Bioinformatics, 22 (14), pp. e49-e57; Chattopadhyay, R., Joint transfer and batch-mode active learning (2013) Proc. 30th Int. Conf. Mach. Learn. (ICML), pp. 253-261; Du, B., Zhang, L., A discriminative metric learning based anomaly detection method (2014) IEEE Trans. Geosci. Remote Sens., 52 (11), pp. 6844-6857. , Nov; Huang, J., Correcting sample selection bias by unlabeled data (2006) Proc. Adv. Neural Inf. Process. Syst., pp. 601-608; Shimodaira, H., Improving predictive inference under covariate shift by weighting the log-likelihood function (2000) J. Stat. Planning Inference, 90 (2), pp. 227-244; Bickel, S., Brückner, M., Scheffer, T., Discriminative learning under covariate shift (2009) J. Mach. Learn. Res., 10, pp. 2137-2155. , Sep; Du, B., Zhang, L., Target detection based on a dynamic subspace (2014) Pattern Recognit., 47 (1), pp. 344-358; Foody, G.M., Campbell, N.A., Trodd, N.M., Wood, T.F., Derivation and applications of probabilistic measures of class membership from the maximum-likelihood classification (1992) Photogramm. Eng. Remote Sens., 58 (9), pp. 1335-1341; Du, B., Zhang, L., Random-selection-based anomaly detector for hyperspectral imagery (2011) IEEE Trans. Geosci. Remote Sens., 49 (5), pp. 1578-1589. , May; Campbell, C., Cristianini, N., Smola, A., Query learning with large margin classifiers (2000) Proc. ICML, pp. 111-118; Pasolli, E., Melgani, F., Tuia, D., Pacifici, F., Emery, W.J., SVM active learning approach for image classification using spatial information (2014) IEEE Trans. Geosci. Remote Sens., 52 (4), pp. 2217-2233. , Apr; Cui, Z., Chen, X., Wu, J., Sheng, V.S., Shi, Y., Maximum classification optimization-based active learning for image classification (2014) Proc. 7th Int. Congr. IEEE Image Signal Process. (CISP), pp. 759-764. , Oct; Shi, X., Fan, W., Ren, J., Actively transfer domain knowledge (2008) Machine Learning and Knowledge Discovery in Databases, pp. 342-357. , Antwerp, Belgium: Springer; Vlachos, A., A stopping criterion for active learning (2008) Comput. Speech Lang., 22 (3), pp. 295-312; Sriperumbudur, B.K., Hilbert space embeddings and metrics on probability measures (2010) J. Mach. Learn. Res., 11, pp. 1517-1561. , Apr; Paola, J.D., Schowengerdt, R.A., A detailed comparison of backpropagation neural network and maximum-likelihood classifiers for urban land use classification (1995) IEEE Trans. Geosci. Remote Sens., 33 (4), pp. 981-996. , Apr; Friedman, J.H., Regularized discriminant analysis (1989) J. Amer. Stat. Assoc., 84 (405), pp. 165-175; Wang, T., Du, B., Zhang, L., A background self-learning framework for unstructured target detectors (2013) IEEE Geosci. Remote Sens. Lett., 10 (6), pp. 1577-1581. , Nov},
correspondence_address1={Li, S.; School of Computer Science, China; email: lishijunwhu@163.com},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={21693536},
language={English},
abbrev_source_title={IEEE Access},
document_type={Article},
source={Scopus},
}

@ARTICLE{Chen2018228,
author={Chen, Y.-T. and Chang, W.-Y. and Lu, H.-L. and Wu, T. and Sun, M.},
title={Leveraging motion priors in videos for improving human segmentation},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={11211 LNCS},
pages={228-244},
doi={10.1007/978-3-030-01234-2_14},
note={cited By 0; Conference of 15th European Conference on Computer Vision, ECCV 2018 ; Conference Date: 8 September 2018 Through 14 September 2018;  Conference Code:219419},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055088406&doi=10.1007%2f978-3-030-01234-2_14&partnerID=40&md5=4b25cd2ba52ba3798994d9b61bbc177f},
affiliation={National Tsing Hua University, Taiwan; Umbo Computer Vision, Taiwan},
abstract={Despite many advances in deep-learning based semantic segmentation, performance drop due to distribution mismatch is often encountered in the real world. Recently, a few domain adaptation and active learning approaches have been proposed to mitigate the performance drop. However, very little attention has been made toward leveraging information in videos which are naturally captured in most camera systems. In this work, we propose to leverage “motion prior” in videos for improving human segmentation in a weakly-supervised active learning setting. By extracting motion information using optical flow in videos, we can extract candidate foreground motion segments (referred to as motion prior) potentially corresponding to human segments. We propose to learn a memory-network-based policy model to select strong candidate segments (referred to as strong motion prior) through reinforcement learning. The selected segments have high precision and are directly used to finetune the model. In a newly collected surveillance camera dataset and a publicly available UrbanStreet dataset, our proposed method improves the performance of human segmentation across multiple scenes and modalities (i.e., RGB to Infrared (IR)). Last but not least, our method is empirically complementary to existing domain adaptation approaches such that additional performance gain is achieved by combining our weakly-supervised active learning approach with domain adaptation approaches. © Springer Nature Switzerland AG 2018.},
author_keywords={Active learning;  Domain adaptation;  Human segmentation},
keywords={Artificial intelligence;  Cameras;  Computer vision;  Deep learning;  Drops;  Reinforcement learning;  Semantics, Active Learning;  Domain adaptation;  Existing domains;  Foreground motions;  Human segmentation;  Motion information;  Semantic segmentation;  Surveillance cameras, Security systems},
funding_details={MediaTekMediaTek},
funding_details={Ministry of Science and Technology, TaiwanMinistry of Science and Technology, Taiwan, MOST, 107-2634-F-007-007},
funding_text 1={We thank Umbo CV, MediaTek, MOST 107-2634-F-007-007 for their support.},
references={Settles, B., (2010) Active Learning Literature Survey; Sener, O., Savarese, S., (2018) Active Learning for Convolutional Neural Networks: A Core-Set Approach, , ICLR; Dragon, R., Rosenhahn, B., Ostermann, J., Multi-scale clustering of frame-to-frame correspondences for motion segmentation (2012) ECCV 2012. LNCS, pp. 445-458. , https://doi.org/10.1007/978-3-642-33709-332, Fitzgibbon, A., Lazebnik, S., Perona, P., Sato, Y., Schmid, C. (eds.), Springer, Heidelberg; Ochs, P., Malik, J., Brox, T., Segmentation of moving objects by long term video analysis (2014) IEEE Trans. Pattern Anal. Mach. Intell., 36 (6), pp. 1187-1200; Elhamifar, E., Vidal, R., Sparse subspace clustering (2009) CVPR. IEEE; Yang, M.Y., Ackermann, H., Lin, W., Feng, S., Rosenhahn, B., (2017) Motion Segmentation via Global and Local Sparse Subspace Optimization, , arXiv preprint arXiv; Yan, J., Pollefeys, M., A general framework for motion segmentation: Independent, articulated, rigid, non-rigid, degenerate and non-degenerate (2006) ECCV 2006. LNCS, 3954, pp. 94-106. , https://doi.org/10.1007/117440858, Leonardis, A., Bischof, H., Pinz, A. (eds.), Springer, Heidelberg; Tsai, Y.H., Yang, M.H., Black, M.J., Video segmentation via object flow (2016) CVPR; Cheng, J., Tsai, Y.H., Wang, S., Yang, M.H., SegFlow: Joint learning for video object segmentation and optical flow (2017) ICCV; Nirkin, Y., Masi, I., Tuan, A.T., Hassner, T., Medioni, G., On face segmentation, face swapping, and face perception (2018) Automatic Face & Gesture Recognition IEEE International Conference; Zhao, T., Nevatia, R., Stochastic human segmentation from a static camera (2002) Motion and Video Computing, Workshop; Zhao, T., Nevatia, R., Bayesian human segmentation in crowded situations (2003) CVPR; Spina, T.V., (2013) Video Human Segmentation Using Fuzzy Object Models and Its Application to Body Pose Estimation of Toddlers for Behavior Studies, , arXiv preprint arXiv; Song, C., Huang, Y., Wang, Z., Wang, L., 1000 fps human segmentation with deep convolutional neural networks (2015) ACPR. IEEE; Guo, L.J., Cheng, T.T., Xiao, B., Zhang, R., Zhao, J.Y., Video human segmentation based on multiple-cue integration (2015) Signal Process. Image Commun., 30, pp. 166-177; Lu, J., Corso, J.J., Human action segmentation with hierarchical supervoxel consistency (2015) CVPR; Tan, Y., Guo, Y., Gao, C., Background subtraction based level sets for human segmentation in thermal infrared surveillance systems (2013) Infrared Phys. Technol., 61, pp. 230-240; He, F., Guo, Y., Gao, C., (2017) Human Segmentation of Infrared Image for Mobile Robot Search. Multimedia Tools and Applications, pp. 1-14; Yarin Gal, R.I., Ghahramani, Z., Deep Bayesian active learning with image data (2017) ICML; Colwell, S.R., Joshi, A.W., (2009) Multi-Item Scale Development for Measuring Institutional Pressures in the Context of Corporate Environmental Action, , IABS; Brinker, K., (2003) Incorporating Diversity in Active Learning with Support Vector Machines, , ICML; Ducoffe, M., Precioso, F., (2018) Adversarial Active Learning for Deep Networks: A Margin Based Approach; Li, X., Guo, R., Cheng, J., Incorporating incremental and active learning for scene classification (2012) ICMLA; Elhamifar, E., Sapiro, G., Yang, A., Sasrty, S.S., A convex optimization framework for active learning (2013) ICCV; Yang, Y., Loog, M., A variance maximization criterion for active learning (2017) Arxiv Preprint Arxiv:1706, 7642; Kading, C., Freytag, A., Rodner, E., Perino, A., Denzler, J., (2016) Large-Scale Active Learning with Approximations of Expected Model Output Changes, , GCPR; Kuwadekar, A., Neville, J., (2011) Relational Active Learning for Joint Collective Classification Models, , ICML; Paul, S., Bappy, J.H., Roy-Chowdhury, A.K., Non-uniform subset selection for active learning in structured data (2017) CVPR; Fang, M., Li, Y., Cohn, T., Learning how to active learn: A deep reinforcement learning approach (2017) EMNLP; Philip Bachman, A.S., Trischler, A., Learning algorithms for active learning (2017) ICML; Tzeng, E., Hoffman, J., Darrell, T., Saenko, K., Simultaneous deep transfer across domains and tasks (2015) ICCV; Long, M., Cao, Y., Wang, J., Jordan, M., Learning transferable features with deep adaptation networks (2015) ICML; Zellinger, W., Grubinger, T., Lughofer, E., Natschläger, T., Saminger-Platz, S., Central moment discrepancy (CMD) for domain-invariant representation learning (2017) ICLR; Goodfellow, I., (2014) Generative Adversarial Nets. In: NIPS; Liu, M.Y., Tuzel, O., (2016) Coupled Generative Adversarial Networks, , NIPS; Ganin, Y., Lempitsky, V., (2015) Unsupervised Domain Adaptation by Backpropagation, , ICML; Tzeng, E., Hoffman, J., Saenko, K., Darrell, T., (2017) Adversarial Discriminative Domain Adaptation, , arXiv preprint arXiv; Bousmalis, K., Trigeorgis, G., Silberman, N., Krishnan, D., Erhan, D., (2016) Domain Separation Networks, , NIPS; Hoffman, J., Wang, D., Yu, F., Darrell, T., (2016) Fcns in the Wild: Pixel-Level Adversarial and Constraint-Based Adaptation, , arXiv preprint arXiv; Chen, Y.H., Chen, W.Y., Chen, Y.T., Tsai, B.C., Wang, Y.C.F., Sun, M., No more discrimination: Cross city adaptation of road scene segmenters (2017) ICCV; Zhang, Y., David, P., Gong, B., Curriculum domain adaptation for semantic segmentation of urban scenes (2017) ICCV; Sankaranarayanan, S., Balaji, Y., Jain, A., Lim, S.N., Chellappa, R., (2017) Unsupervised Domain Adaptation for Semantic Segmentation with Gans, , arXiv preprint arXiv; Ilg, E., Mayer, N., Saikia, T., Keuper, M., Dosovitskiy, A., Brox, T., (2016) Flownet 2.0: Evolution of Optical Flow Estimation with Deep Networks, , arXiv preprint arXiv; Brox, T., Malik, J., Large displacement optical flow: Descriptor matching in variational motion estimation (2011) TPAMI, 33 (3), pp. 500-513; Weston, J., Chopra, S., Bordes, A., Memory networks (2015) ICLR; Oh, J., Chockalingam, V., Singh, S., Lee, H., Control of memory, active perception, and action in minecraft (2016) ICML; Fragkiadaki, K., Zhang, W., Zhang, G., Shi, J., Two-granularity tracking: Mediating trajectory and detection graphs for tracking under occlusions (2012) ECCV 2012. LNCS, 7576, pp. 552-565. , https://doi.org/10.1007/978-3-642-33715-440, Fitzgibbon, A., Lazebnik, S., Perona, P., Sato, Y., Schmid, C. (eds.), Springer, Heidelberg; Ronneberger, O., Fischer, P., Brox, T., U-Net: Convolutional networks for biomedical image segmentation (2015) MICCAI 2015. LNCS, 9351, pp. 234-241. , https://doi.org/10.1007/978-3-319-24574-428, Navab, N., Hornegger, J., Wells, W.M., Frangi, A.F. (eds.), Springer, Cham; Everingham, M., Eslami, S.A., van Gool, L., Williams, C.K., Winn, J., Zisserman, A., The pascal visual object classes challenge: A retrospective (2015) IJCV, 111 (1), pp. 98-136; Kingma, D., Ba, J., (2015) Adam: A Method for Stochastic Optimization, , ICLR; Lin, T.-Y., Microsoft COCO: Common objects in context (2014) ECCV 2014. LNCS, 8693, pp. 740-755. , https://doi.org/10.1007/978-3-319-10602-148, Fleet, D., Pajdla, T., Schiele, B., Tuytelaars, T. (eds.), Springer, Cham},
correspondence_address1={Chen, Y.-T.; National Tsing Hua UniversityTaiwan; email: yuting2401@gmail.com},
editor={Ferrari V., Sminchisescu C., Hebert M., Weiss Y.},
publisher={Springer Verlag},
issn={03029743},
isbn={9783030012335},
language={English},
abbrev_source_title={Lect. Notes Comput. Sci.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Onita201879,
author={Onita, D. and Birlutiu, A.},
title={Active learning based on Transfer Learning techniques for image classification},
journal={ESANN 2018 - Proceedings, European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning},
year={2018},
pages={79-84},
note={cited By 0; Conference of 26th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2018 ; Conference Date: 25 April 2018 Through 27 April 2018;  Conference Code:149253},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069519510&partnerID=40&md5=f18c9b91e0a3a66d5b21420ca7ccf181},
affiliation={Faculty of Science, University of Alba Iulia, Gabriel Bethlen Nr.5, Alba Iulia, 510009, Romania},
abstract={In many imaging tasks only an expert can annotate the data. Though domain experts are available, their labor is expensive and we would like to avoid querying them whenever possible. Our task is to make use of our resources as efficient as possible for a learning task. There are various ways of working in cases of labelled data shortage. This type of learning problems can be approached with Active and Transfer Learning techniques. Active Learning and Transfer Learning have demonstrated their efficiency and ability to train accurate models with significantly reduced amount of training data in many real-life applications. In this paper we investigate the combination of Active and Transfer Learning for building an efficient algorithm for image classification. The experimental results show that by combining active and transfer learning, we can learn faster with fewer labels on a target domain than by random selection. © ESANN 2018 - Proceedings, European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning.},
keywords={Learning algorithms;  Machine learning;  Neural networks, Active Learning;  Domain experts;  Learning problem;  Learning tasks;  Random selection;  Real-life applications;  Target domain;  Transfer learning, Image classification},
funding_details={PN-III-P2-2.1-BG-2016-0333},
funding_details={Corporation for National and Community ServiceCorporation for National and Community Service, CNCS},
funding_details={Autoritatea Natională pentru Cercetare StiintificăAutoritatea Natională pentru Cercetare Stiintifică},
funding_text 1={∗This work was supported by a grant of the Romanian National Authority for Scientific Research and Innovation, CNCS/CCCDI UEFISCDI, project number PN-III-P2-2.1-BG-2016-0333, within PNCDI III.},
references={Birlutiu, A., Groot, P., Heskes, T., Efficiently learning the preferences of people (2013) Machine Learning Journal, 90 (1), pp. 1-28. , Springer; Diethe, T., Twomey, N., Flach, P., Active transfer learning for activity recognition (2016) ESANN 2016 Proceedings, European Symposium on Artificial Neural Networks; Pedregosa, F., (2011) Scikit-learn: Machine Learning in Python, , ACM Digital Library; McCallum, A., Nigam, K., Employing em and pool-based active learning for text classification (1998) Proceedings of the 15th International Conference on Machine Learning, pp. 350-358; Pan, S.J., Yang, Q., A survey on transfer learning (2010) IEEE Trans. Knowle. Data Eng. 2010, 22, p. 13451359; Spanhol, F., Oliveira, L.S., Petitjean, C., Heutte, L., A dataset for breast cancer histopathological image classification (2016) IEEE Transactions on Biomedical Engineering (TBME), 63 (7), pp. 1455-1462; Settles, B., (2012) Active Learning, , Morgan & Claypool; Wang, X., Huang, T.-K., Schneider, J., Active transfer learning under model shift Proceeding ICML'14 Proceedings of the 31st International Conference on International Conference on Machine Learning, 32, pp. 1305-1313; Wang, X., (2016) Active Transfer Learning, , PhD Thesis. CMU; Zhao, L., Jialin-Pan, S., Wei-Xiang, E., Zhong, E., Lu, Z., Yang, Q., Active transfer learning for cross-system recommendation (2013) Proceedings of the 27th AAAI Conference on Artificial Intelligence},
publisher={i6doc.com publication},
isbn={9782875870476},
language={English},
abbrev_source_title={ESANN - Proc., Euro. Symp. Artif. Neural Networks, Comput. Intell. Mach. Learn.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Zhao2018,
author={Zhao, C. and Han, J. and Jia, Y. and Fan, L. and Gou, F.},
title={Versatile Framework for Medical Image Processing and Analysis with Application to Automatic Bone Age Assessment},
journal={Journal of Electrical and Computer Engineering},
year={2018},
volume={2018},
doi={10.1155/2018/2187247},
art_number={2187247},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060183737&doi=10.1155%2f2018%2f2187247&partnerID=40&md5=e2bdcfebc098e6952bee4ca7824b4fae},
affiliation={School of Computer Science and Technology, Xi'an University of Posts and Telecommunications, Xi'an, Shaanxi, 710121, China; Shaanxi Provincial Key Laboratory of Network Data Analysis and Intelligent Processing, Xi'an University of Posts and Telecommunications, Xi'an, Shaanxi, 710121, China},
abstract={Deep learning technique has made a tremendous impact on medical image processing and analysis. Typically, the procedure of medical image processing and analysis via deep learning technique includes image segmentation, image enhancement, and classification or regression. A challenge for supervised deep learning frequently mentioned is the lack of annotated training data. In this paper, we aim to address the problems of training transferred deep neural networks with limited amount of annotated data. We proposed a versatile framework for medical image processing and analysis via deep active learning technique. The framework includes (1) applying deep active learning approach to segment specific regions of interest (RoIs) from raw medical image by using annotated data as few as possible; (2) generative adversarial Network is employed to enhance contrast, sharpness, and brightness of segmented RoIs; (3) Paced Transfer Learning (PTL) strategy which means fine-tuning layers in deep neural networks from top to bottom step by step to perform medical image classification or regression tasks. In addition, in order to understand the necessity of deep-learning-based medical image processing tasks and provide clues for clinical usage, class active map (CAM) is employed in our framework to visualize the feature maps. To illustrate the effectiveness of the proposed framework, we apply our framework to the bone age assessment (BAA) task using RSNA dataset and achieve the state-of-the-art performance. Experimental results indicate that the proposed framework can be effectively applied to medical image analysis task. © 2018 Chen Zhao et al.},
keywords={Artificial intelligence;  Bone;  Deep neural networks;  Image analysis;  Image classification;  Image enhancement;  Image segmentation;  Learning algorithms;  Medical imaging, Adversarial networks;  Annotated training data;  Bone age assessment;  Image processing and analysis;  Learning techniques;  Regions of interest;  State-of-the-art performance;  Transfer learning, Medical image processing},
funding_text 1={(is work was supported by the Graduate Innovation Foundation in Xi’an University of Posts and Communications under Grant CXJJ2017005.},
references={Cheplygina, V., Bruijne, M.D., Pluim, J.P.W., (2018) Not-sosupervised: A Survey of Semi-supervised, Multi-instance, and Transfer Learning in Medical Image Analysis, , https://arxiv.org/abs/1804.06353; Litjens, G., Kooi, T., Bejnordi, B.E., A survey on deep learning in medical image analysis (2017) Medical Image Analysis, 42 (9), pp. 60-88; Spampinato, C., Palazzo, S., Giordano, D., Deep learning for automated skeletal bone age assessment in X-ray images (2016) Medical Image Analysis, 36, pp. 41-51; Iglovikov, V., Rakhlin, A., Kalinin, A., (2017) Pediatric Bone Age Assessment Using Deep Convolutional Neural Networks, [12] Bone Age Recognition Using Convolution Neural Network, , https://arxiv.org/abs/1712.05053; Lee, H., Tajmir, S., Lee, J., Fully automated deep learning system for bone age assessment (2017) Journal of Digital Imaging, 30 (4), pp. 427-441; Rajpurkar, P., Irvin, J., Zhu, K., (2017) CheXNet: Radiologistlevel Pneumonia Detection on Chest X-rays with Deep Learning, , https://arxiv.org/abs/1711.05225; Kooi, T., Litjens, G., Van, G.B., Large scale deep learning for computer aided detection of mammographic lesions (2017) Medical Image Analysis, 35, pp. 303-312; Grinsven, M.J.J.P.V., Ginneken, B.V., Hoyng, C.B., Fast convolutional neural network training using selective data sampling: Application to hemorrhage detection in color fundus images (2016) IEEE Transactions on Medical Imaging, 35 (5), pp. 1273-1284; Ghafoorian, M., Karssemeijer, N., Heskes, T., Deep multiscale location-aware 3D convolutional neural networks for automated detection of lacunes of presumed vascular origin (2017) Neuroimage: Clinical, 14, pp. 391-399; Tajbakhsh, N., Shin, J.Y., Gurudu, S.R., Convolutional neural networks for medical image analysis: Full training or fine tuning? (2016) IEEE Transactions on Medical Imaging, 35 (5), pp. 1299-1312; (2017) RSNA Pediatric Bone Age Challenge, , http://rsnachallenges.cloudapp.net/competitions/4, RSNA, December; Seung Opper, H.S., Query by committee (1992) Proceedings of Fifth Workshop on Computational Learning Theory, pp. 287-294. , Pittsburgh, PA, USA, July; Dasgupta, S., Coarse sample complexity bounds for active learning (2005) Neural Information Processing Systems, pp. 235-242; Huang, G., Liu, Z., Maaten, L.V.D., (2016) Densely Connected Convolutional Networks, , https://arxiv.org/abs/1411.1784; Zhou, B., Khosla, A., Lapedriza, A., Learning deep features for discriminative localization, computer vision and pattern recognition (2016) Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2921-2929. , Las Vegas, NV, USA, June; Jegou, S., Drozdzal, M., Vazquez, D., The one hundred layers tiramisu: Fully convolutional densenets for semantic segmentation (2017) Proceedings of IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), pp. 1175-1183. , Las Vegas, NV, USA, June; Franklin, D., Forensic age estimation in human skeletal remains: Current concepts and future directions (2010) Legal Medicine, 12 (1), pp. 1-7; Drozdzal, M., Vorontsov, E., Chartrand, G., The importance of skip connections in biomedical image segmentation (2016) Lecture Notes in Computer Science, pp. 179-187. , Springer, Berlin, Germany; Otsu, N., Threshold selection method from gray-level histograms (1979) IEEE Transactions on Systems, Man, and Cybernetics, 9 (1), p. 626s6; Lewis, D., Catlett, J., Heterogeneous uncertainty sampling for supervised learning (1994) Proceedings of the International Conference on Machine Learning (ICML), , New Brunswick, NJ, USA, July; Kong, J., Wang, F., Teodoro, G., Automated cell segmentation with 3D fluorescence microscopy images (2015) Proceedings of IEEE 12th International Symposium on Biomedical Imaging (ISBI), pp. 1212-1215. , Brooklyn, NY, USA, April; Mahapatra, D., Schüffler, P.J., Tielbeek, J.A.W., Active learning based segmentation of Crohn's disease using principles of visual saliency (2014) Proceedings of IEEE, International Symposium on Biomedical Imaging (ISBI), pp. 226-229. , Beijing, China, April; Jain, S.D., Grauman, K., Active image segmentation propagation, computer vision and pattern recognition (2016) Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2864-2873. , Las Vegas, NV, USA, June; Mahapatra, D., Buhmann, J.M., Visual saliency-based active learning for prostate magnetic resonance imaging segmentation (2016) Journal of Medical Imaging, 3 (1); Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., (2014) Generative Adversarial Nets, International Conference on Neural Information Processing Systems, , MIT Press, Cambridge, MA, USA; Mirza, M., Osindero, S., Conditional generative adversarial nets (2014) Computer Science, pp. 2672-2680; Gilsanz, V., Ratib, O., (2005) Hand Bone Age: A Digital Atlas of Skeletal Maturity, , Springer Nature, Basingstoke, UK; Forfar, J.O., Assessment of skeletal maturity and prediction of adult height (2010) American Journal of Human Biology, 14 (6), pp. 788-789; Zhou, J., Li, Z., Zhi, W., Using convolutional neural networks and transfer learning for bone age classification (2017) Proceedings of International Conference on Digital Image Computing: Techniques and Applications, pp. 1-6. , Sydney, Australia, November},
correspondence_address1={Zhao, C.; School of Computer Science and Technology, China; email: 1603210019@stu.xupt.edu.cn},
publisher={Hindawi Limited},
issn={20900147},
language={English},
abbrev_source_title={J. Electr. Comput. Eng.},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Stubbs20171,
author={Stubbs, J.J. and Birch, G.C. and Woo, B.L. and Kouhestani, C.G.},
title={Physical security assessment with convolutional neural network transfer learning},
journal={Proceedings - International Carnahan Conference on Security Technology},
year={2017},
volume={2017-October},
pages={1-6},
doi={10.1109/CCST.2017.8167800},
note={cited By 5; Conference of 2017 International Carnahan Conference on Security Technology, ICCST 2017 ; Conference Date: 23 October 2017 Through 26 October 2017;  Conference Code:133621},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042334891&doi=10.1109%2fCCST.2017.8167800&partnerID=40&md5=e7cd293504a4937fa584d7e5cdc0aadc},
affiliation={Sandia National Laboratories, 1515 Eubank SE, Albuquerque, United States},
abstract={Deep learning techniques have demonstrated the ability to perform a variety of object recognition tasks using visible imager data; however, deep learning has not been implemented as a means to autonomously detect and assess targets of interest in a physical security system. We demonstrate the use of transfer learning on a convolutional neural network (CNN) to significantly reduce training time while keeping detection accuracy of physical security relevant targets high. Unlike many detection algorithms employed by video analytics within physical security systems, this method does not rely on temporal data to construct a background scene; targets of interest can halt motion indefinitely and still be detected by the implemented CNN. A key advantage of using deep learning is the ability for a network to improve over time. Periodic retraining can lead to better detection and higher confidence rates. We investigate training data size versus CNN test accuracy using physical security video data. Due to the large number of visible imagers, significant volume of data collected daily, and currently deployed human in the loop ground truth data, physical security systems present a unique environment that is well suited for analysis via CNNs. This could lead to the creation of algorithmic element that reduces human burden and decreases human analyzed nuisance alarms. © 2017 IEEE.},
author_keywords={Convolutional Neural Network;  Machine Learning;  Nuisance Alarms;  Physical Security;  Transfer Learning},
keywords={Chemical detection;  Convolution;  Deep learning;  Learning systems;  Neural networks;  Object recognition;  Security systems, Convolutional neural network;  Convolutional Neural Networks (CNN);  Detection algorithm;  Learning techniques;  Nuisance alarms;  Physical security;  Physical security systems;  Transfer learning, Network security},
funding_details={DE-NA0003525},
funding_details={Sandia National LaboratoriesSandia National Laboratories},
funding_text 1={ACKNOWLEDGMENT Sandia National Laboratories is a multimission laboratory managed and operated by National Technology and Engineering Solutions of Sandia LLC, a wholly owned subsidiary of Honeywell International Inc. for the U.S. Department of Ener-gys National Nuclear Security Administration under contract DE-NA0003525. SAND2017-7072 C},
references={Ciresan, D.C., Convolutional neural network committees for handwritten character classification (2011) Document Analysis and Recognition (ICDAR), 2011 International Conference On. IEEE; Hastie, T., Tibshirani, R., Friedman, J., Overview of supervised learning (2009) The Elements of Statistical Learning, pp. 9-41. , Springer New York; Kim, P., Convolutional neural network (2017) MATLAB Deep Learning, pp. 121-147. , Apress; Lawrence, S., Face recognition: A convolutional neural-network approach (1997) IEEE Transactions on Neural Networks, 8 (1), pp. 98-113; Pan, S.J., Yang, Q., A survey on transfer learning (2010) IEEE Transactions on Knowledge and Data Engineering, 22 (10), pp. 1345-1359; Pinheiro, P., Collobert, R., Recurrent convolutional neural networks for scene labeling (2014) International Conference on Machine Learning; Shin, H.-C., Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning (2016) IEEE Transactions on Medical Imaging, 35 (5), pp. 1285-1298; Olshausen, B.A., Field, D.J., Emergence of simple-cell receptive field properties by learning a sparse code for natural images (1996) Nature, 381 (6583), p. 607; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems; Deng, J., Imagenet: A large-scale hierarchical image database (2009) Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference On. IEEE; Szegedy, C., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.; See, J.E., Vigilance: A review of the literature and applications to sentry duty (2014) Sandia Report SAND2014-17929},
editor={Ortega-Garcia J., Morales A., Fierrez J., Vera-Rodriguez R., Lazzeretti R.},
sponsors={},
publisher={Institute of Electrical and Electronics Engineers Inc.},
issn={10716572},
isbn={9781538615850},
language={English},
abbrev_source_title={Proc. Int. Carnahan Conf. Secur. Technol.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Zhou20174761,
author={Zhou, Z. and Shin, J. and Zhang, L. and Gurudu, S. and Gotway, M. and Liang, J.},
title={Fine-tuning convolutional neural networks for biomedical image analysis: Actively and incrementally},
journal={Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
year={2017},
volume={2017-January},
pages={4761-4772},
doi={10.1109/CVPR.2017.506},
note={cited By 163; Conference of 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017 ; Conference Date: 21 July 2017 Through 26 July 2017;  Conference Code:132417},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040371714&doi=10.1109%2fCVPR.2017.506&partnerID=40&md5=d9b68268e2d5a21939c721079c213a4a},
affiliation={Arizona State University, United States; Mayo Clinic, United States},
abstract={Intense interest in applying convolutional neural networks (CNNs) in biomedical image analysis is wide spread, but its success is impeded by the lack of large annotated datasets in biomedical imaging. Annotating biomedical images is not only tedious and time consuming, but also demanding of costly, specialty-oriented knowledge and skills, which are not easily accessible. To dramatically reduce annotation cost, this paper presents a novel method called AIFT (active, incremental fine-tuning) to naturally integrate active learning and transfer learning into a single framework. AIFT starts directly with a pre-trained CNN to seek "worthy" samples from the unannotated for annotation, and the (fine-tuned) CNN is further fine-tuned continuously by incorporating newly annotated samples in each iteration to enhance the CNN's performance incrementally. We have evaluated our method in three different biomedical imaging applications, demonstrating that the cost of annotation can be cut by at least half. This performance is attributed to the several advantages derived from the advanced active and incremental capability of our AIFT method. © 2017 IEEE.},
keywords={Computer vision;  Convolution;  Image analysis;  Iterative methods;  Medical imaging;  Neural networks;  Pattern recognition, Active Learning;  Annotated datasets;  Biomedical image analysis;  Biomedical images;  Biomedical imaging;  Biomedical imaging applications;  Convolutional neural network;  Transfer learning, Image annotation},
references={Al Rahhal, M., Bazi, Y., AlHichri, H., Alajlan, N., Melgani, F., Yager, R., Deep learning approach for active classification of electrocardiogram signals (2016) Information Sciences, 345, pp. 340-354; Carneiro, G., Nascimento, J., Bradley, A., Unregistered multiview mammogram analysis with pre-trained deep learning models (2015) Medical Image Computing and Computer-Assisted Intervention - MICCAI 2015, 9351 of Lecture Notes in Computer Science, pp. 652-660. , N. Navab, J. Hornegger, W. M. Wells, and A. F. Frangi, editors, Springer International Publishing; Chakraborty, S., Balasubramanian, V., Sun, Q., Panchanathan, S., Ye, J., Active batch selection via convex relaxations with guaranteed solution bounds (2015) IEEE IEEE Transactions on Pattern Analysis and Machine Intelligence, 37 (10), pp. 1945-1958; Chen, H., Dou, Q., Ni, D., Cheng, J.-Z., Qin, J., Li, S., Heng, P.-A., Automatic fetal ultrasound standard plane detection using knowledge transferred recurrent neural networks (2015) International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 507-514. , Springer; Chen, H., Ni, D., Qin, J., Li, S., Yang, X., Wang, T., Heng, P.A., Standard plane localization in fetal ultrasound via domain transferred deep neural networks (2015) Biomedical and Health Informatics, IEEE Journal of, 19 (5), pp. 1627-1636. , Sept; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., Imagenet: A large-scale hierarchical image database (2009) Computer Vision and Pattern Recognition, 2009. CVPR 2009 IEEE Conference on, pp. 248-255. , IEEE; Gao, M., Bagci, U., Lu, L., Wu, A., Buty, M., Shin, H.-C., Roth, H., Summers, R.M., Holistic classification of ct attenuation patterns for interstitial lung diseases via deep convolutional neural networks (2015) The 1st Workshop on Deep Learning in Medical Image Analysis, International Conference on Medical Image Computing and Computer Assisted Intervention, at MICCAIDLMIA', 15; Greenspan, H., Van Ginneken, B., Summers, R.M., Guest editorial deep learning in medical imaging: Overview and future promise of an exciting new technique (2016) IEEE IEEE Transactions on Medical Imaging, 35 (5), pp. 1153-1159; Guyon, I., Cawley, G., Dror, G., Lemaire, V., Statnikov, A., (2011) JMLR Workshop and Conference Proceedings (16): Active Learning Challenge, , Microtome Publishing; Holub, A., Perona, P., Burl, M.C., Entropy-based active learning for object recognition (2008) Computer Vision and Pattern Recognition Workshops, 2008. CVPRW'08 IEEE Computer Society Conference on, pp. 1-8. , IEEE; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., (2014) Caffe: Convolutional Architecture for Fast Feature Embedding; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Kukar, M., Transductive reliability estimation for medical diagnosis (2003) Artificial Intelligence in Medicine, 29 (1), pp. 81-106; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Li, J., Active learning for hyperspectral image classification with a stacked autoencoders based neural network (2016) 2016 IEEE International Conference on Image Processing (ICIP), pp. 1062-1065. , Sept; Liang, J., Bi, J., Computer aided detection of pulmonary embolism with tobogganing and mutiple instance classification in ct pulmonary angiography (2007) Biennial International Conference on Information Processing in Medical Imaging, pp. 630-641. , Springer; Lu, L., Zheng, Y., Carneiro, G., Yang, L., (2016) Deep Learning and Convolutional Neural Networks for Medical Image Computing: Precision Medicine, High Performance and Large-Scale Datasets, , Springer; Margeta, J., Criminisi, A., Cabrera Lozoya, R., Lee, D.C., Ayache, N., Fine-tuned convolutional neural nets for cardiac mri acquisition plane recognition (2015) Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization, pp. 1-11; Schlegl, T., Ofner, J., Langs, G., Unsupervised pre-training across image domains improves lung tissue classification (2014) Medical Computer Vision: Algorithms for Big Data, pp. 82-93. , Springer; Settles, B., Active learning literature survey University of Wisconsin, Madison, 52 (55-66), p. 11; Shin, H.-C., Lu, L., Kim, L., Seff, A., Yao, J., Summers, R.M., Interleaved text/image deep mining on a very largescale radiology database (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1090-1099; Stark, F., Hazirbas, C., Triebel, R., Cremers, D., Captcha recognition with active deep learning (2015) Workshop New Challenges in Neural Computation, p. 94. , Citeseer, 2015; Tajbakhsh, N., Gotway, M.B., Liang, J., Computer-aided pulmonary embolism detection using a novel vessel-aligned multi-planar image representation and convolutional neural networks (2015) International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 62-69. , Springer; Tajbakhsh, N., Shin, J.Y., Gurudu, S.R., Hurst, R.T., Kendall, C.B., Gotway, M.B., Liang, J., Convolutional neural networks for medical image analysis: Full training or fine tuning? (2016) IEEE IEEE Transactions on Medical Imaging, 35 (5), pp. 1299-1312; Wang, D., Shang, Y., A new active labeling method for deep learning (2014) 2014 International Joint Conference on Neural Networks (IJCNN), pp. 112-119. , July; Wang, H., Zhou, Z., Li, Y., Chen, Z., Lu, P., Wang, W., Liu, W., Yu, L., Comparison of machine learning methods forclassifying mediastinal lymph node metastasis of non-small cell lung cancer from 18 f-fdg pet/ct images (2017) EJNMMI Research, 7 (1), p. 11; Zhou, B., Khosla, A., Lapedriza, A., Torralba, A., Oliva, A., (2016) Places: An Image Database for Deep Scene Understanding; Zhou, K., Greenspan, H., Shen, D., (2016) Deep Learning for Medical Image Analysis, , Academic Press},
sponsors={},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538604571},
language={English},
abbrev_source_title={Proc. - IEEE Conf. Comput. Vis. Pattern Recognit, CVPR},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Boggavarapu2017538,
author={Boggavarapu, L.N.P. and Prabukumar, M.},
title={Survey on classification methods for hyper spectral remote sensing imagery},
journal={Proceedings of the 2017 International Conference on Intelligent Computing and Control Systems, ICICCS 2017},
year={2017},
volume={2018-January},
pages={538-542},
doi={10.1109/ICCONS.2017.8250520},
note={cited By 13; Conference of 2017 International Conference on Intelligent Computing and Control Systems, ICICCS 2017 ; Conference Date: 15 June 2017 Through 16 June 2017;  Conference Code:134184},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044645106&doi=10.1109%2fICCONS.2017.8250520&partnerID=40&md5=89a3c192661ed10aee24a4079a91c7ec},
affiliation={Research Scholar School of Information Technology Engineering (SITE), VIT University, Vellore, India},
abstract={Classification of hyperspectral remote sensing images is key to extract abundant information. The researchers are focusing on the development of algorithms for accurate classifiers from last few decades. With the technological advancement and new modern methods of learning provide confidence for efficient and accurate classification when compared to the direct implementation of conventional learning algorithms. The variations in the conventional algorithm leads to active learning based and transfer learning based approaches and provide promising results. This paper attempt to explore various recent technologies applied to Hyperspectral imagery for classification. © 2017 IEEE.},
author_keywords={Active Learning;  Classification;  Hyperspectral remote sensing;  Transfer Learning},
keywords={Classification (of information);  Control systems;  Image classification;  Intelligent computing;  Remote sensing;  Spectroscopy, Active Learning;  Classification methods;  Conventional algorithms;  Hyper-spectral imageries;  Hyperspectral remote sensing;  Hyperspectral Remote Sensing Image;  Technological advancement;  Transfer learning, Learning algorithms},
references={Prasad, S., Chanussot, J., Fowler, J.E., Bioucas-Dias, J., Creuserre, C.D., Introduction to the issue on advances in hyperspectral data processing and analysis (2015) IEEE Journal of Selected Topics in Signal Processing, 9 (6), pp. 961-963. , Sept; Chutia, D., Bhattacharyya, D.K., Sarma, K.K., Kalita, R., Sudhakar, S., Hyperspectral remote sensing classifications: A perspective survey (2016) Transactions in GIS, 20 (4), pp. 463-490; Olmanson, L.G., Brezonik, P.L., Bauer, M.E., Airborne hyperspectral remote sensing to assess spatial distribution of water quality characteristics in large rivers: The Mississippi River and its tributaries in Minnesota (2013) Remote Sensing of Environment, 130, pp. 254-265; Zarco-Tejada, P.J., Berjón, A., López-Lozano, R., Miller, J.R., Martín, P., Cachorro, V., González, M.R., De Frutos, A., Assessing vineyard condition with hyperspectral indices: Leaf and canopy reflectance simulation in a row-structured discontinuous canopy (2005) Remote Sensing of Environment, 99, pp. 271-287; Pascucci, S., Belviso, C., Cavalli, R.M., Laneve, G., Misurovic, A., Perrino, C., Pignatti, S., Red mud soil contamination near an urban settlement analyzed by airborne hyperspectral remote sensing (2009) IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2009, pp. IV893-IV896. , 12-17 July; Briottet, X., Boucher, Y., Dimmeler, A., Malaplate, A., Cini, A., Diani, M., Bekman, H., Oxford, D., Military applications of hyperspectral imagery (2006) Proc. SPIE 6239 Targets and Backgrounds XII: Characterization and Representation, 62390B, May 04; Sakarya, U., Gürbüz, S.Z., Demirkesen, C., Deveci, H.S., Tankz, S., Oztoprak, A.F., Lmaz, O.Y., Teke, M., Afet yönetiminde görüntü i leme uygulamlar n n k sa bir incelemesi ve RASAT ile örnek uygulamalar (2014) (A Short Survey of Image Processing Applications in Disaster Management and Sample Applications with RASAT, , V. Uzaktan Alg lama ve Co rafi Bilgi Sistemleri Sempozyumu (UZAL-CBS 2014), stanbul, 14-17 Ekim; Plaza, A., Benediktsson, J.A., Boardman, J.W., Brazile, J., Bruzzone, L., Camps-Valls, G., Chanussot, J., Trianni, G., Recent advances in techniques for hyperspectral image processing (2009) Remote Sensing of Environment, 113, pp. 110-122; Ammanouil, R., Nonlinear unmixing of hyperspectral data with vector-valued kernel functions IEEE Transactions on Image Processing, 26 (1). , January 2017; Gan, L., Du, P., Xia, J., Meng, Y., Kernel fused representation-based classifier for hyperspectral imagery IEEE Geoscience and Remote Sensing Letters, PP (99), pp. 1-5; Landgrebe, D.A., Hyperspectral image data analysis as a high dimensional signal processing problems (2002) IEEE Signal Processing Magazine, 19, pp. 17-28; Performance versus energy consumptionof hyperspectral unmixing algorithms on multi-core platforms (2013) EURASIPJournal on Advances in Signal Processing, 68. , Remo; http://ipi.ugent.be/ipi/drupal/http%3A/%252Fipi.ugent.be/ipi/drupal/hyperspectral, ir. Wenzhi Liao; Rajan, S., Ghosh, J., Crawford, M.M., An active learning approach to hyperspectral data classification IEEE Transactions on Geoscience and Remote Sensing, 46 (4), pp. 1231-1242. , April 2008; Torrey, L., Shavlik, J., (2009) Transfer Learning, Handbook of Research on Machine Learning Applications, pp. 1-22; Kemker, R., Kanan, C., Self-taught feature learning for hyperspectral image classification (2017) IEEE Transactions on Geoscience and Remote Sensing, 55 (5), pp. 2693-2705. , May; Zhu, W., Unsupervised classification in hyperspectral imagery with nonlocal total variation and primal-dual hybrid gradient algorithm (2017) IEEE Transactions on Geoscience and Remote Sensing, 55 (5), pp. 2786-2798. , May; Jia, S., Deng, B., Zhu, J., Jia, X., Li, Q., Superpixel-based multitask learning framework for hyperspectral image classification (2017) IEEE Transactions on Geoscience and Remote Sensing, 55 (5), pp. 2575-2588. , May; Dong, Y., Du, B., Zhang, L., Zhang, L., Dimensionality reduction and classification of hyperspectral images using ensemble discriminative local metric learning (2017) IEEE Transactions on Geoscience and Remote Sensing, 55 (5), pp. 2509-2524. , May; Zhai, H., Zhang, H., Zhang, L., Li, P., Plaza, A., A new sparse subspace clustering algorithm for hyperspectral remote sensing imagery (2017) IEEE Geoscience and Remote Sensing Letters, 14 (1), pp. 43-47. , Jan; Zhang, H., Zhai, H., Zhang, L., Li, P., Spectral-spatial sparse subspace clustering for hyperspectral remote sensing images IEEE Trans. Geosci. Remote Sens, 54 (6), pp. 3672-3684. , Jun. 2016; Persello, C., Bruzzone, L., Kernel-based domain-invariant feature selection in hyperspectral images for transfer learning (2016) IEEE Transactions on Geoscience and Remote Sensing, 54 (5), pp. 2615-2626. , May; Xia, J., Yokoya, N., Iwasaki, A., Hyperspectral image classification with canonical correlation forests (2017) IEEE Transactions on Geoscience and Remote Sensing, 55 (1), pp. 421-431. , Jan; Xia, J., Chanussot, J., Du, P., He, X., Rotation-based ensemble classifiers for high-dimensional data Fusion in Computer Vision, pp. 135-160. , B.Ionescu, J.Benois-Pineau, T.Piatrik, andG.Quénot,Eds. NewYork, NY, USA: Springer-Verlag, 2014; Xia, J., Liao, W., Chanussot, J., Du, P., Song, G., Philips, W., Improving random forest with ensemble of features and semisupervised feature extraction (2015) IEEEGeosci. Remote Sens. Lett, 12 (7), pp. 1471-1475. , Jul; Xia, J., Falco, N., Benediktsson, J.A., Chanussot, J., Du, P., Classseparation-based rotation forest for hyperspectral image classification (2016) IEEE Geosci. Remote Sensing Lett, 13 (4), pp. 584-588. , Apr; Rodriguez, J.J., Kuncheva, L.I., Rotation forest: A new classifier ensemble method (2009) IEEE Trans. Pattern Anal. Mach. Intell, 28 (10), pp. 1619-1630. , Oct; Camps-Valls, G., Bruzzone, L., Kernel-based methods for hyperspectral image classification (2005) IEEE Trans. Geosci. Remote Sens, 43 (6), pp. 1351-1362. , Jun; Li, J., Bioucas-Dias, J.M., Plaza, A., Semisupervised hyperspectral image segmentation using multinomial logistic regression with active learning (2010) IEEE Trans. Geosci. Remote Sens, 48 (11), pp. 4085-4098. , Nov; Li, J., Zhang, H., Huang, Y., Zhang, L., Hyperspectral image classification by nonlocal joint collaborative representation with a locally adaptive dictionary (2014) IEEE Trans. Geosci. Remote Sens, 52 (6), pp. 3707-3719. , Jun; Guo, J., Zhou, X., Li, J., Plaza, A., Prasad, S., Superpixel-based active learning and online feature importance learning for hyperspectral image analysis (2017) IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 10 (1), pp. 347-359. , Jan; Rajan, S., An active learning approach to hyperspectral data classification (2008) Ieee Transactions on Geoscience and Remote Sensing, 46 (4). , April; Mitra, P., Shankar, B.U., Pal, S.K., Segmentation of multispectral remote sensing images using active support vector machines (2004) Pattern Recognition. Lett, 25 (9), pp. 1067-1074. , Jul; Lewis, D., Gale, W.A., A sequential algorithm for training text classifiers (1994) Proc. 17th Int. ACM SIGIR Conf. Res. Develop. Inf. Retrieval, pp. 3-12; MacKay, D., Information-based objective functions for active data selection (1992) Neural Compute, 4 (4), pp. 590-604. , Jul; Mitra, P., Shankar, B.U., Pal, S.K., Segmentation of multispectral remote sensing images using active support vector machines (2004) Pattern Recognit. Lett, 25 (9), pp. 1067-1074. , Jul; Cohn, D., Gharamani, Z., Jordan, M., Active learning with statistical models (1996) Artif. Intell. Res, 4, pp. 129-145; Lewis, D., Gale, W.A., A sequential algorithm for training text classifiers (1994) Proc. 17th Int. ACM SIGIR Conf. Res. Develop. Inf. Retrieval, pp. 3-12; Ye, Z., Li, H., Song, Y., Benediktsson, J.A., Tang, Y.Y., Hyperspectral image classification using principal components-based smooth ordering and multiple 1-d interpolation (2017) IEEE Transactions on Geoscience and Remote Sensing, 55 (2), pp. 1199-1209. , Feb; Liang, J., Zhou, J., Qian, Y., Wen, L., Bai, X., Gao, Y., On the sampling strategy for evaluation of spectral-spatial methods in hyperspectral image classification (2017) IEEE Transactions on Geoscience and Remote Sensing, 55 (2), pp. 862-880. , Feb; Li, W., Wu, G., Zhang, F., Du, Q., Hyperspectral image classification using deep pixel-pair features (2017) IEEE Transactions on Geoscience and Remote Sensing, 55 (2), pp. 844-853. , Feb; Toksöz, M.A., Ulusoy, Hyperspectral image classification via kernel basic thresholding classifier (2017) IEEE Transactions on Geoscience and Remote Sensing, 55 (2), pp. 715-728. , Feb; Ye, M., Qian, Y., Zhou, J., Tang, Y.Y., Dictionary learning-based feature-level domain adaptation for cross-scene hyperspectral image classification (2017) IEEE Transactions on Geoscience and Remote Sensing, 55 (3), pp. 1544-1562. , March; Sun, B., Kang, X., Li, S., Benediktsson, J.A., Random-walker-based collaborative learning for hyperspectral image classification IEEE Transactions on Geoscience and Remote Sensing, 55 (1), pp. 212-222. , Jan. 2017; Qiao, T., Effective denoising and classification of hyperspectral images using curvelet transform and singular spectrum analysis (2017) IEEE Transactions on Geoscience and Remote Sensing, 55 (1), pp. 119-133. , Jan},
publisher={Institute of Electrical and Electronics Engineers Inc.},
isbn={9781538627457},
language={English},
abbrev_source_title={Proc. Int. Conf. Intell. Comput. Control Syst., ICICCS},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Liu2017,
author={Liu, L. and Yan, R.-J. and Maruvanchery, V. and Kayacan, E. and Chen, I.-M. and Tiong, L.K.},
title={Transfer learning on convolutional activation feature as applied to a building quality assessment robot},
journal={International Journal of Advanced Robotic Systems},
year={2017},
volume={14},
number={3},
doi={10.1177/1729881417712620},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021943207&doi=10.1177%2f1729881417712620&partnerID=40&md5=b8555b4e46019a7371437ebc49047547},
affiliation={Robotics Research Center, Nanyang Technological University, Singapore},
abstract={We propose an automated postconstruction quality assessment robot system for crack, hollowness, and finishing defects in light of a need to speed up the inspection work, a more reliable inspection report, as well as an objective through fully automated inspection. Such an autonomous inspection system has a potential to cut labour cost significantly and achieve better accuracy. In the proposed system, a transfer learning network is employed for visual defect detection; a region proposal network is used for object region proposal, a deep learning network employed as feature extractor, and a linear classifier with supervised learning as object classifier; moreover, active learning of top-N ranking region of interest is undertaken for fine-tuning of the transfer learning on convolutional activation feature network. Extensive experiments are validated in a construction quality assessment system room and constructed test bed. The results are promising in a way that the novel proposed automated assessment method gives satisfactory results for crack, hollowness, and finishing defects assessment. To the best of our knowledge, this study is the first attempt to having an autonomous visual inspection system for postconstruction quality assessment of building sector. We believe the proposed system is going to help to pave the way towards fully autonomous postconstruction quality assessment systems in the future. © 2017, © The Author(s) 2017.},
author_keywords={Active transfer learning;  building quality assessment;  deep learning;  faster R-CNN;  mobile robot},
keywords={Automation;  Chemical activation;  Compensation (personnel);  Convolution;  Cracks;  Defects;  Education;  Inspection;  Inspection equipment;  Learning systems;  Mobile robots;  Robots;  Wages, Automated assessment;  Autonomous inspection systems;  Building quality;  Construction quality;  faster R-CNN;  Linear classifiers;  Transfer learning;  Visual inspection systems, Deep learning},
references={Nashat, S., Abdullah, A., Abdullah, M.Z., Machine vision for crack inspection of biscuits featuring pyramid detection scheme (2014) J Food Eng, 120, pp. 233-247; Jahanshahi, M.R., Masri, S.F., Adaptive vision-based crack detection using 3D scene reconstruction for condition assessment of structures (2012) Automat Constr, 22, pp. 567-576; Maierhofer, C., Arndt, R., Rollig, M., Application of impulse-thermography for non-destructive assessment of concrete structures (2006) Cement Concrete Comp, 28 (4), pp. 393-401; Hung, Y.Y., Chen, Y.S., Ng, S.P., Review and comparison of shearography and active thermography for nondestructive evaluation (2009) Mat Sci Eng R, 64 (5-6), pp. 73-112; Le, M., Lee, J., Jun, J., Hall sensor array based validation of estimation of crack size in metals using magnetic dipole models (2013) NDT and E Int, 53, pp. 18-25; Brown, J.R., Hamilton, H.R., Quantitative infrared thermography inspection for FRP applied to concrete using single pixel analysis (2013) Constr Build Mater, 38, pp. 1292-1302; Prasanna, P., Dana, K.J., Gucunski, N., Automated crack detection on concrete bridges (2016) IEEE Transactions on Automation Science and Engineering, 13 (2), pp. 591-599; AL-Marakeby, A., Aly, A.A., Salem, F.A., Fast quality inspection of food products using computer vision (2013) Adv Res Comp Commun Eng, 2 (11), pp. 4168-4171; Bu, G., Chanda, S., Guan, H., Crack detection using a texture analysis-based technique for visual bridge inspection (2015) Electr J Struct Eng, 14 (1), pp. 41-48; Chen, Z., Derakhshani, R., Halmen, C., A texture-based method for classifying cracked concrete surfaces from digital images using neural networks Neural networks (IJCNN), The 2011 international joint conference, pp. 2632-2637. , San Jose, CA, USA, IEEE,. In; Ahmed, R., El Sayed, M., Gadsden, S.A., Automotive internal-combustion-engine fault detection and classification using artificial neural network techniques (2015) IEEE Trans Vehicular Technol, 64 (1), pp. 21-33; Shafi’i, M.A., Hamzah, N., Internal fault classification using artificial neural network, pp. 352-357. , Proceedings of 2010 4th international power engineering and optimization conference, Shah Alam, Selangor, Malaysia,. In; Li, B., Zhu, X., Zhao, S., HV power equipment diagnosis based on infrared imaging analyzing, pp. 1-4. , Proceedings of international conference on power system technology, Chongqing, China,. In; Rahmani, A., Haddadnia, J., Seryasat, O., Intelligent fault detection of electrical equipment in ground substations using thermo vision technique, pp. 150-154. , Proceedings of 2010 2nd international conference on mechanical and electronics engineering,. 2, Kyoto, Japan,. In; Almeida, C.A.L., Braga, A.P., Nascimento, S., Intelligent thermographic diagnostic applied to surge arresters: a new approach (2009) IEEE Trans Power Deliv, 24 (2), pp. 751-757; Chou, Y.C., Yao, L., Automatic diagnostic system of electrical equipment using infrared thermography, pp. 155-160. , International conference of soft computing and pattern recognition, Malacca, Malaysia,. In; de Oliveira, J.H.E., Lages, W.F., Robotized inspection of power lines with infrared vision, pp. 1-6. , Alied robotics for the power industry (CARPI), 2010 1st international conference, Montreal, QC, Caa,. In; Lim, R.S., La, H.M., Shan, Z., Developing a crack inspection robot for bridge maintenance, pp. 6288-6293. , 2011 IEEE international conference on robotics and automation (ICRA), Shanghai, China,. In; Sharifi, M., Fathy, M., Mahmoudi, M.T., A classified and comparative study of edge detection algorithms, pp. 117-120. , Proceedings of international conference on information technology: coding and computing, Las Vegas, NV, USA, IEEE,. In; Girshick, R., Donahue, J., Darrell, T., Rich feature hierarchies for accurate object detection and semantic segmentation, pp. 580-587. , Proceedings of the IEEE conference on computer vision and pattern recognition,. In; Uijlings, J.R.R., van de Sande, K.E.A., Gevers, T., Selective search for object recognition (2013) Int J Comput Vis, 104 (2), pp. 154-171; Girshick, R., Fast R-CNN, pp. 1440-1448. , Proceedings of the IEEE international conference on computer vision,. In; Alexe, B., Deselaers, T., Ferrari, V., Measuring the objectness of image windows (2012) IEEE Trans Pattern Anal Mach Intell, 34 (11), pp. 2189-2202; Zitnick, C.L., Dollár, P., Edge boxes: locating object proposals from edges (2014) Computer vision – ECCV 2014. Lecture Notes in Computer Science, 8693, pp. 391-405. , Fleet, Pajdla, Schiele, (eds), Cham, Springer,. In:,. (eds); Arbeláez, P., Pont-Tuset, J., Barron, J., Multiscale combinatorial grouping, pp. 328-335. , Proceedings of the IEEE conference on computer vision and pattern recognition, 24 June 2014,. In; Carreira, J., Sminchisescu, C., CPMC: automatic object segmentation using constrained parametric min-cuts (2012) IEEE Trans Pattern Anal Mach Intell, 34 (7), pp. 1312-1328; Wang, A., Lu, J., Cai, J., Large-margin multi-modal deep learning for RGB-D object recognition (2015) IEEE Trans Multimedia, 17 (11), pp. 1887-1898; He, K., Zhang, X., Ren, S., Spatial pyramid pooling in deep convolutional networks for visual recognition (2015) IEEE Trans Pattern Anal Mach Intell, 37 (9), pp. 1904-1916; Hosang, J., Benenson, R., Dollár, P., What makes for effective detection proposals? IEEE Transactions on Pattern Analysis and Machine Intelligence, 38 (4), pp. 814-830; Ren, S., He, K., Girshick, R., Faster R-CNN: towards real-time object detection with region proposal networks (2015) Advances in neural information processing systems, pp. 91-99. , Cortes, Lawrence, Lee; Liu, W., Anguelov, D., Erhan, D., SSD: single shot multibox detector (2016) European conference on computer vision, pp. 21-37. , Springer,. In; Torrey, L., Shavlik, J., Transfer learning (2009) Handbook of research on machine learning applications and trends: algorithms, methods, and techniques, 1, p. 242. , Olivas, Guerrero, Sober, (eds),. In:,. (eds),; Pan, S.J., Yang, Q., A survey on transfer learning (2010) IEEE Trans Knowl Data Eng, 22 (10), pp. 1345-1359; Tai, L., Ye, Q., Liu, M., PCA-aided fully convolutional networks for semantic segmentation of multi-channel fMRI (2016) arXiv preprint arXiv:1610.01732; Chorowski, J.K., Bahdanau, D., Serdyuk, D., Attention-based models for speech recognition (2015) Advances in neural information processing systems, pp. 577-585. , Cortes, Lawrence, Lee; Szegedy, C., Reed, S., Erhan, D., Scalable, high-quality object detection (2014) arXiv preprint arXiv:1412.1441; Zeiler, M.D., Fergus, R., Visualizing and understanding convolutional networks (2014) Computer vision–ECCV 2014, pp. 818-833. , Fleet, Pajdla, Schiele, (eds), Springer; Ren, S., He, K., Girshick, R., Object detection networks on convolutional feature maps (2015) arXiv preprint arXiv:1504.06066, 2015; Sokolova, M., Japkowicz, N., Szpakowicz, S., Beyond accuracy, f-score and ROC: a family of discriminant measures for performance evaluation (2006) AI 2006: advances in artificial intelligence, pp. 1015-1021. , Sattar, Kang, (eds), Berlin, Heidelberg, Springer},
correspondence_address1={Kayacan, E.; Nanyang Technological UniversitySingapore; email: erdal@ntu.edu.sg},
publisher={SAGE Publications Inc.},
issn={17298806},
language={English},
abbrev_source_title={Int. J. Adv. Rob. Syst.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Peter2017655,
author={Peter, L. and Mateus, D. and Chatelain, P. and Declara, D. and Schworm, N. and Stangl, S. and Multhoff, G. and Navab, N.},
title={Assisting the examination of large histopathological slides with adaptive forests},
journal={Medical Image Analysis},
year={2017},
volume={35},
pages={655-668},
doi={10.1016/j.media.2016.09.009},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991688368&doi=10.1016%2fj.media.2016.09.009&partnerID=40&md5=9c9b27a41e7f948e304fbb6c36b8b81a},
affiliation={Computer Aided Medical Procedures, Technische Universität München, Germany; Institute of Computational Biology, Helmholtz Zentrum München, Germany; Université de Rennes 1, IRISA, France; Department of Radiation Oncology, Technische Universität München, Germany; Institute of Innovative Radiotherapy (iRT), Department of Radiation Sciences, Helmholtz Zentrum München, Germany; Computer Aided Medical Procedures, Johns Hopkins University, United States},
abstract={The examination of biopsy samples plays a central role in the diagnosis and staging of numerous diseases, including most cancer types. However, because of the large size of the acquired images, the localization and quantification of diseased portions of a tissue is usually time-consuming, as pathologists must scroll through the whole slide to look for objects of interest which are often only scarcely distributed. In this work, we introduce an approach to facilitate the visual inspection of large digital histopathological slides. Our method builds on a random forest classifier trained to segment the structures sought by the pathologist. However, moving beyond the pixelwise segmentation task, our main contribution is an interactive exploration framework including: (i) a region scoring function which is used to rank and sequentially display regions of interest to the user, and (ii) a relevance feedback capability which leverages human annotations collected on each suggested region. Thereby, an online domain adaptation of the learned pixelwise segmentation model is performed, so that the region scores adapt on-the-fly to possible discrepancies between the original training data and the slide at hand. Three real-time update strategies are compared, including a novel approach based on online gradient descent which supports faster user interaction than an accurate delineation of objects. Our method is evaluated on the task of extramedullary hematopoiesis quantification within mouse liver slides. We assess quantitatively the retrieval abilities of our approach and the benefit of the interactive adaptation scheme. Moreover, we demonstrate the possibility of extrapolating, after a partial exploration of the slide, the surface covered by hematopoietic cells within the whole tissue. © 2016},
author_keywords={Active learning;  Domain adaptation;  Histopathology;  Online learning;  Random forests},
keywords={Artificial intelligence;  Decision trees;  Tissue, Active Learning;  Domain adaptation;  Histopathology;  Online learning;  Random forests, Diagnosis, Article;  extramedullary hematopoiesis;  hematopoietic cell;  histopathology;  human;  information retrieval;  learning;  nonhuman;  pathologist;  priority journal;  quantitative study;  random forest;  tissue section;  algorithm;  animal;  devices;  hematopoiesis;  liver;  mouse;  pathology;  procedures, Algorithms;  Animals;  Hematopoiesis;  Liver;  Mice;  Pathology},
references={Al-Janabi, S., Huisman, A., Van Diest, P.J., Digital pathology: current status and future perspectives (2012) Histopathology, 61 (1), pp. 1-9; Bahlmann, C., Patel, A., Johnson, J., Ni, J., Chekkoury, A., Khurd, P., Kamen, A., Graham, A., Automated detection of diagnostically relevant regions in H&E stained digital pathology slides (2012) SPIE Medical Imaging, 8315, pp. 831504-831504–8. , International Society for Optics and Photonics; Balermpas, P., Rödel, F., Rödel, C., Krause, M., Linge, A., Lohaus, F., Baumann, M., Fokas, E., CD8+ Tumour-infiltrating lymphocytes in relation to HPV status and clinical outcome in patients with head and neck cancer after postoperative chemoradiotherapy: A multicentre study of the german cancer consortium radiation oncology group (DKTK-ROG) (2016) Int. J. Cancer, 138 (1), pp. 171-181; Bauer, T.W., Schoenfield, L., Slaw, R.J., Yerian, L., Sun, Z., Henricks, W.H., Validation of whole slide imaging for primary diagnosis in surgical pathology (2013) Arch. Pathol. Lab. Med., 137 (4), pp. 518-524; Bautista, P.A., Yagi, Y., Staining correction in digital pathology by utilizing a dye amount table (2015) J. Digit. Imag., pp. 1-12; Breiman, L., Friedman, J., Stone, C., Olshen, R., Classification and regression trees (1984); Carpenter, A.E., Jones, T.R., Lamprecht, M.R., Clarke, C., Kang, I.H., Friman, O., Guertin, D.A., Moffat, J., Cellprofiler: image analysis software for identifying and quantifying cell phenotypes (2006) Genome Biol., 7 (10), p. R100; Chatelain, P., Pauly, O., Peter, L., Ahmadi, S.-A., Plate, A., Bötzel, K., Navab, N., Learning from multiple experts with random forests: application to the segmentation of the midbrain in 3D ultrasound (2013) Medical Image Computing and Computer Assisted Intervention (MICCAI), pp. 230-237. , Springer; Cooper, L.A., Carter, A.B., Farris, A.B., Wang, F., Kong, J., Gutman, D.A., Widener, P., Sharma, A., Digital pathology: data-intensive frontier in medical imaging (2012) Proc. IEEE, 100 (4), pp. 991-1003; Criminisi, A., Shotton, J., Bucciarelli, S., Decision forests with long-range spatial context for organ localization in CT volumes (2009) In: MICCAI Workshop on Probabilistic Models for Medical Image Analysis; Criminisi, A., Shotton, J., Konukoglu, E., Decision forests: a unified framework for classification, regression, density estimation, manifold learning and semi-supervised learning (2012) Found. Trends Comput. Graph. Vis., 7, pp. 81-227; Doyle, S., Feldman, M., Tomaszewski, J., Madabhushi, A., A boosted bayesian multiresolution classifier for prostate cancer detection from digitized needle biopsies (2012) IEEE Trans. Biomed. Eng., 59 (5), pp. 1205-1218; Ebner, T., Stern, D., Donner, R., Bischof, H., Urschler, M., Towards automatic bone age estimation from MRI: localization of 3D anatomical landmarks (2014) Medical Image Computing and Computer Assisted Intervention (MICCAI), pp. 429-437. , Springer; Eefting, D., Schrage, Y.M., Geirnaerdt, M.J., Le Cessie, S., Taminiau, A.H., Bovée, J.V., Hogendoorn, P.C., Assessment of interobserver variability and histologic parameters to improve reliability in classification and grading of central cartilaginous tumors (2009) Am. J. Surg. Pathol., 33 (1), pp. 50-57; Farahani, N., Parwani, A., Pantanowitz, L., Whole slide imaging in pathology: Advantages, limitations, and emerging perspectives (2015) Pathol. Lab. Med. Int., 7, pp. 23-33; Fiaschi, L., Köthe, U., Nair, R., Hamprecht, F.A., Learning to count with regression forest and structured labels (2012) International Conference on Pattern Recognition (ICPR), pp. 2685-2688. , IEEE; Gauriau, R., Cuingnet, R., Lesage, D., Bloch, I., Multi-organ localization combining global-to-local regression and confidence maps (2014) Medical Image Computing and Computer Assisted Intervention (MICCAI), pp. 337-344. , Springer; Gilles, F.H., Tavaré, C.J., Becker, L.E., Burger, P.C., Yates, A.J., Pollack, I.F., Finlay, J.L., Pathologist interobserver variability of histologic features in childhood brain tumors: Results from the ccg-945 study (2007) Pediatric Dev. Pathol., 11 (2), pp. 108-117; Gonul, I.I., Poyraz, A., Unsal, C., Acar, C., Alkibay, T., Comparison of 1998 w ho/isup and 1973 who classifications for interobserver variability in grading of papillary urothelial neoplasms of the bladder. pathological evaluation of 258 cases (2006) Urologia Internationalis, 78 (4), pp. 338-344; Gorelick, L., Veksler, O., Gaed, M., Gomez, J., Moussa, M., Bauman, G., Fenster, A., Ward, A., Prostate histopathology: learning tissue component histograms for cancer detection and classification (2013) IEEE Trans. Med. Imag., 32 (10), pp. 1804-1818; Gurcan, M., Boucheron, L., Can, A., Madabhushi, A., Rajpoot, N., Yener, B., Histopathological image analysis: a review (2009) IEEE Rev. Biomed. Eng., 2, pp. 147-171; Held, M., Schmitz, M.H., Fischer, B., Walter, T., Neumann, B., Olma, M.H., Peter, M., Gerlich, D.W., Cellcognition: time-resolved phenotype annotation in high-throughput live cell imaging (2010) Nat. Methods, 7 (9), pp. 747-754; Homeyer, A., Schenk, A., Arlt, J., Dahmen, U., Dirsch, O., Hahn, H.K., Practical quantification of necrosis in histological whole-slide images (2013) Comput. Med. Imag. Graph., 37 (4), pp. 313-322; Homeyer, A., Schenk, A., Dahmen, U., Dirsch, O., Huang, H., Hahn, H.K., A comparison of sampling strategies for histological image analysis (2011) J. Pathol. Inf., 2; Huang, C.-H., Veillard, A., Roux, L., Loménie, N., Racoceanu, D., Time-efficient sparse analysis of histopathological whole slide images (2011) Comput. Med. Imag. Graph., 35 (7), pp. 579-591; Jaarsma, T., Jarodzka, H., Nap, M., Merrienboer, J.J., Boshuizen, H., Expertise under the microscope: Processing histopathological slides (2014) Med. Edu., 48 (3), pp. 292-300; Jain, V., Learned-Miller, E., Online domain adaptation of a pre-trained cascade of classifiers (2011) IEEE Computer Vision and Pattern Recognition (CVPR), pp. 577-584; Jukić, D.M., Drogowski, L.M., Martina, J., Parwani, A.V., Clinical examination and validation of primary diagnosis in anatomic pathology using whole slide digital images (2011) Arch. Pathol. Lab. Med., 135 (3), pp. 372-378; Khan, A.M., Rajpoot, N., Treanor, D., Magee, D., A non-linear mapping approach to stain normalisation in digital histopathology images using image-specific colour deconvolution (2014) IEEE Trans. Biomed. Eng; Khurd, P., Bahlmann, C., Maday, P., Kamen, A., Gibbs-Strauss, S., Genega, E., Frangioni, J., Computer-aided gleason grading of prostate cancer histopathological images using texton forests (2010) IEEE International Symposium on Biomedical Imaging (ISBI), pp. 636-639; Kong, H., Gurcan, M., Belkacem-Boussaid, K., Partitioning histopathological images: an integrated framework for supervised color-texture segmentation and cell splitting (2011) IEEE Trans. Med. Imag., 30 (9), pp. 1661-1677; Kontschieder, P., Dorn, J., Morrison, C., Corish, R., Zikic, D., Sellen, A., DSouza, M., Tewarie, P., Quantifying progression of multiple sclerosis via classification of depth videos (2014) Medical Image Computing and Computer Assisted Intervention (MICCAI), pp. 429-437. , Springer; Lakshminarayanan, B., Roy, D.M., Teh, Y.W., Mondrian forests: efficient online random forests (2014) Advances in Neural Information Processing Systems (NIPS), pp. 3140-3148. , Ghahramani Z. Welling M. Cortes C. Lawrence N. Weinberger K; Macenko, M., Niethammer, M., Marron, J., Borland, D., Woosley, J., Guan, X., Schmitt, C., Thomas, N., A method for normalizing histology slides for quantitative analysis (2009) IEEE International Symposium on Biomedical Imaging (ISBI), pp. 1107-1110; Mercan, E., Aksoy, S., Shapiro, L.G., Weaver, D.L., Brunye, T., Elmore, J.G., Localization of diagnostically relevant regions of interest in whole slide images (2014) IEEE International Conference on Pattern Recognition (ICPR), pp. 1179-1184; Meyer, J.S., Alvarez, C., Milikowski, C., Olson, N., Russo, I., Russo, J., Glass, A., Parwaresch, R., Breast carcinoma malignancy grading by bloom-richardson system vs proliferation index: Reproducibility of grade and advantages of proliferation index (2005) Modern Pathol., 18 (8), pp. 1067-1078; Montillo, A., Shotton, J., Winn, J., Iglesias, J., Metaxas, D., Criminisi, A., Entangled decision forests and their application for semantic segmentation of CT images (2011) Information Processing in Medical Imaging (IPMI), pp. 184-196. , Springer; Nemirovski, A., Juditsky, A., Lan, G., Shapiro, A., Robust stochastic approximation approach to stochastic programming (2009) SIAM J. Optim., 19 (4), pp. 1574-1609; Nguyen, K., Sarkar, A., Jain, A., Prostate cancer grading: Use of graph cut and spatial arrangement of nuclei (2014) IEEE Trans. Med. Imag., 33 (12), p. 2254; Onder, D., Zengin, S., Sarioglu, S., A review on color normalization and color deconvolution methods in histopathology (2014) Appl. Immunohistochem. Mole. Morphol., 22 (10), pp. 713-719; Pauly, O., Glocker, B., Criminisi, A., Mateus, D., Möller, A., Nekolla, S., Navab, N., Fast multiple organ detection and localization in whole-body MR dixon sequences (2011) Medical Image Computing and Computer Assisted Intervention (MICCAI), pp. 239-247. , Springer; Peter, L., Mateus, D., Chatelain, P., Schworm, N., Stangl, S., Multhoff, G., Navab, N., Leveraging random forests for interactive exploration of large histological images (2014) Medical Image Computing and Computer Assisted Intervention (MICCAI), pp. 1-8. , Springer; Peter, L., Pauly, O., Chatelain, P., Mateus, D., Navab, N., Scale-adaptive forest training via an efficient feature sampling scheme (2015) Medical Image Computing and Computer Assisted Intervention (MICCAI), pp. 637-644. , Springer; Rabinovich, A., Agarwal, S., Laris, C., Price, J.H., Belongie, S.J., Unsupervised color decomposition of histologically stained tissue samples (2003) Advances in Neural Information Processing Systems (NIPS), pp. 667-674; Roullier, V., Lézoray, O., Ta, V.-T., Elmoataz, A., Multi-resolution graph-based analysis of histopathological whole slide images: application to mitotic cell extraction and visualization (2011) Comput. Med. Imag. Graph., 35 (7), pp. 603-615; Saffari, A., Leistner, C., Santner, J., Godec, M., Bischof, H., On-line random forests (2009) IEEE International Conference on Computer Vision Workshops, pp. 1393-1400; Sertel, O., Kong, J., Shimada, H., Catalyurek, U., Saltz, J.H., Gurcan, M.N., Computer-aided prognosis of neuroblastoma on whole-slide images: Classification of stromal development (2009) Pattern Recognit., 42 (6), pp. 1093-1103; Settles, B., Active learning literature survey (2010) Comput. Sci. Tech. Rep., 1648 (55-66); Shalev-Shwartz, S., Online learning and online convex optimization (2012) Found. Trends Mach. Learn., 4 (2), pp. 107-194; Shotton, J., Winn, J., Rother, C., Criminisi, A., Textonboost: joint appearance, shape and context modeling for multi-class object recognition and segmentation (2006) European Conference on Computer Vision (ECCV), pp. 1-15. , Springer; Sommer, C., Straehle, C., Köthe, U., Hamprecht, F.A., Ilastik: interactive learning and segmentation toolkit (2011) 2011 IEEE International Symposium on Biomedical Imaging, pp. 230-233; Su, H., Xing, F., Kong, X., Xie, Y., Zhang, S., Yang, L., Robust cell detection and segmentation in histopathological images using sparse reconstruction and stacked denoising autoencoders (2015) Medical Image Computing and Computer-Assisted Intervention (MICCAI), pp. 383-390. , Springer; Tao, K., Fang, M., Alroy, J., Sahagian, G., Imagable 4t1 model for the study of late stage breast cancer (2008) BMC Cancer, 8 (1); Tommasi, T., Orabona, F., Kaboli, M., Caputo, B., Leveraging over prior knowledge for online learning of visual categories (2012) British Machine Vision Conference, pp. 87.1-87.11; Vahadane, A., Peng, T., Albarqouni, S., Baust, M., Steiger, K., Schlitter, A., Sethi, A., Navab, N., Structure-preserved color normalization for histological images (2015) IEEE International Symposium on Biomedical Imaging (ISBI), pp. 1012-1015; Veta, M., Pluim, J., van Diest, P., Viergever, M., Breast cancer histopathology image analysis: a review (2014) IEEE Trans. Biomed. Eng; Viola, P., Jones, M.J., Robust real-time face detection (2004) Int. J. Comput. Vis; Xu, Y., Zhu, J.-Y., Eric, I., Chang, C., Lai, M., Tu, Z., Weakly supervised histopathology cancer image segmentation and classification (2014) Med. Image Anal., 18 (3), pp. 591-604; Zhao, P., Hoi, S.C., OTL: a framework of online transfer learning (2010) International Conference on Machine Learning, pp. 1231-1238; Zikic, D., Glocker, B., Criminisi, A., Encoding atlases by randomized classification forests for efficient multi-atlas label propagation (2014) Med. Image Anal., 18 (8), pp. 1262-1273; Zinkevich, M., Online convex programming and generalized infinitesimal gradient ascent (2003) Int. Conf. Mach. Learn},
correspondence_address1={Peter, L.; Computer Aided Medical Procedures, Germany; email: loic.peter@gmail.com},
publisher={Elsevier B.V.},
issn={13618415},
coden={MIAEC},
pubmed_id={27750189},
language={English},
abbrev_source_title={Med. Image Anal.},
document_type={Article},
source={Scopus},
}
